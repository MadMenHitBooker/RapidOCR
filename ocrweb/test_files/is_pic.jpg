2022-10-16 13:13:49.945354: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory
2022-10-16 13:13:49.945464: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory
2022-10-16 13:13:49.945476: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.
[16-10-2022 13:13:55] INFO: Namespace(bert_hidden_dim=768, bert_pretrain='bert-base-chinese', cuda=True, dropout=0.6, eval_step=500, evi_num=5, evidence_type='cossim', gradient_accumulation_steps=8, kernel=21, layer=1, learning_rate=5e-05, max_len=128, no_cuda=False, num_labels=3, num_train_epochs=16.0, outdir='checkpoint/kgat', patience=20, pool='att', postpretrain=None, threshold=0.0, train_batch_size=8, train_path='../data/chef/CHEF_train.json', valid_batch_size=8, valid_path='../data/chef/CHEF_test.json', warmup_proportion=0.1, weight_decay=0.0005)
[16-10-2022 13:13:55] INFO: Start training!
[16-10-2022 13:13:55] DEBUG: Starting new HTTPS connection (1): huggingface.co:443
[16-10-2022 13:13:56] DEBUG: https://huggingface.co:443 "HEAD /bert-base-chinese/resolve/main/vocab.txt HTTP/1.1" 200 0
[16-10-2022 13:13:56] DEBUG: Starting new HTTPS connection (1): huggingface.co:443
[16-10-2022 13:13:57] DEBUG: https://huggingface.co:443 "HEAD /bert-base-chinese/resolve/main/added_tokens.json HTTP/1.1" 404 0
[16-10-2022 13:13:57] DEBUG: Starting new HTTPS connection (1): huggingface.co:443
[16-10-2022 13:13:58] DEBUG: https://huggingface.co:443 "HEAD /bert-base-chinese/resolve/main/special_tokens_map.json HTTP/1.1" 404 0
[16-10-2022 13:13:58] DEBUG: Starting new HTTPS connection (1): huggingface.co:443
[16-10-2022 13:13:59] DEBUG: https://huggingface.co:443 "HEAD /bert-base-chinese/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
[16-10-2022 13:13:59] DEBUG: Starting new HTTPS connection (1): huggingface.co:443
[16-10-2022 13:14:00] DEBUG: https://huggingface.co:443 "HEAD /bert-base-chinese/resolve/main/tokenizer.json HTTP/1.1" 200 0
[16-10-2022 13:14:00] INFO: loading training set
Traceback (most recent call last):
  File "train.py", line 190, in <module>
    args, batch_size=args.train_batch_size)
  File "/home/jiahaoran2022/CHEF/Pipeline/KernelGAT/data_loader.py", line 313, in __init__
    super(CHEFDataLoader, self).__init__(data_path, label_map, tokenizer, args, test, cuda, batch_size)
  File "/home/jiahaoran2022/CHEF/Pipeline/KernelGAT/data_loader.py", line 103, in __init__
    examples = self.read_file(data_path)
  File "/home/jiahaoran2022/CHEF/Pipeline/KernelGAT/data_loader.py", line 317, in read_file
    dataList = json.load(open(data_path, 'r', encoding='utf-8'))
FileNotFoundError: [Errno 2] No such file or directory: '../data/chef/CHEF_train.json'
2022-10-16 13:16:05.133898: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory
2022-10-16 13:16:05.134009: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory
2022-10-16 13:16:05.134023: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.
2022-10-16 13:16:20.147431: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory
2022-10-16 13:16:20.147561: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory
2022-10-16 13:16:20.147574: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.
[16-10-2022 13:16:24] INFO: Namespace(bert_hidden_dim=768, bert_pretrain='bert-base-chinese', cuda=True, dropout=0.6, eval_step=500, evi_num=5, evidence_type='cossim', gradient_accumulation_steps=8, kernel=21, layer=1, learning_rate=5e-05, max_len=128, no_cuda=False, num_labels=3, num_train_epochs=16.0, outdir='checkpoint/kgat', patience=20, pool='att', postpretrain=None, threshold=0.0, train_batch_size=8, train_path='../Data/chef/CHEF_train.json', valid_batch_size=8, valid_path='../Data/chef/CHEF_test.json', warmup_proportion=0.1, weight_decay=0.0005)
[16-10-2022 13:16:24] INFO: Start training!
[16-10-2022 13:16:24] DEBUG: Starting new HTTPS connection (1): huggingface.co:443
[16-10-2022 13:16:25] DEBUG: https://huggingface.co:443 "HEAD /bert-base-chinese/resolve/main/vocab.txt HTTP/1.1" 200 0
[16-10-2022 13:16:25] DEBUG: Starting new HTTPS connection (1): huggingface.co:443
[16-10-2022 13:16:26] DEBUG: https://huggingface.co:443 "HEAD /bert-base-chinese/resolve/main/added_tokens.json HTTP/1.1" 404 0
[16-10-2022 13:16:26] DEBUG: Starting new HTTPS connection (1): huggingface.co:443
[16-10-2022 13:16:27] DEBUG: https://huggingface.co:443 "HEAD /bert-base-chinese/resolve/main/special_tokens_map.json HTTP/1.1" 404 0
[16-10-2022 13:16:27] DEBUG: Starting new HTTPS connection (1): huggingface.co:443
[16-10-2022 13:16:28] DEBUG: https://huggingface.co:443 "HEAD /bert-base-chinese/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
[16-10-2022 13:16:28] DEBUG: Starting new HTTPS connection (1): huggingface.co:443
[16-10-2022 13:16:29] DEBUG: https://huggingface.co:443 "HEAD /bert-base-chinese/resolve/main/tokenizer.json HTTP/1.1" 200 0
[16-10-2022 13:16:29] INFO: loading training set
Traceback (most recent call last):
  File "train.py", line 190, in <module>
    args, batch_size=args.train_batch_size)
  File "/home/jiahaoran2022/CHEF/Pipeline/KernelGAT/data_loader.py", line 313, in __init__
    super(CHEFDataLoader, self).__init__(data_path, label_map, tokenizer, args, test, cuda, batch_size)
  File "/home/jiahaoran2022/CHEF/Pipeline/KernelGAT/data_loader.py", line 103, in __init__
    examples = self.read_file(data_path)
  File "/home/jiahaoran2022/CHEF/Pipeline/KernelGAT/data_loader.py", line 329, in read_file
    evs = row['sim']
KeyError: 'sim'
2022-10-16 14:01:09.824773: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory
2022-10-16 14:01:09.824887: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory
2022-10-16 14:01:09.824900: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.
[16-10-2022 14:01:14] INFO: Namespace(bert_hidden_dim=768, bert_pretrain='bert-base-chinese', cuda=True, dropout=0.6, eval_step=500, evi_num=5, evidence_type='cossim', gradient_accumulation_steps=8, kernel=21, layer=1, learning_rate=5e-05, max_len=128, no_cuda=False, num_labels=3, num_train_epochs=16.0, outdir='checkpoint/kgat', patience=20, pool='att', postpretrain=None, threshold=0.0, train_batch_size=8, train_path='../Data/chef/CHEF_train.json', valid_batch_size=8, valid_path='../Data/chef/CHEF_test.json', warmup_proportion=0.1, weight_decay=0.0005)
[16-10-2022 14:01:14] INFO: Start training!
[16-10-2022 14:01:14] DEBUG: Starting new HTTPS connection (1): huggingface.co:443
[16-10-2022 14:01:15] DEBUG: https://huggingface.co:443 "HEAD /bert-base-chinese/resolve/main/vocab.txt HTTP/1.1" 200 0
[16-10-2022 14:01:15] DEBUG: Starting new HTTPS connection (1): huggingface.co:443
[16-10-2022 14:01:16] DEBUG: https://huggingface.co:443 "HEAD /bert-base-chinese/resolve/main/added_tokens.json HTTP/1.1" 404 0
[16-10-2022 14:01:16] DEBUG: Starting new HTTPS connection (1): huggingface.co:443
[16-10-2022 14:01:17] DEBUG: https://huggingface.co:443 "HEAD /bert-base-chinese/resolve/main/special_tokens_map.json HTTP/1.1" 404 0
[16-10-2022 14:01:17] DEBUG: Starting new HTTPS connection (1): huggingface.co:443
[16-10-2022 14:01:19] DEBUG: https://huggingface.co:443 "HEAD /bert-base-chinese/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
[16-10-2022 14:01:19] DEBUG: Starting new HTTPS connection (1): huggingface.co:443
[16-10-2022 14:01:20] DEBUG: https://huggingface.co:443 "HEAD /bert-base-chinese/resolve/main/tokenizer.json HTTP/1.1" 200 0
[16-10-2022 14:01:20] INFO: loading training set
[16-10-2022 14:01:21] INFO: loading validation set
[16-10-2022 14:01:21] INFO: initializing estimator model
[16-10-2022 14:01:21] DEBUG: Starting new HTTPS connection (1): s3.amazonaws.com:443
[16-10-2022 14:01:22] DEBUG: https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/bert-base-chinese.tar.gz HTTP/1.1" 200 0
[16-10-2022 14:01:22] INFO: https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese.tar.gz not found in cache, downloading to /tmp/tmpo0fga7_m
[16-10-2022 14:01:22] DEBUG: Starting new HTTPS connection (1): s3.amazonaws.com:443
[16-10-2022 14:01:23] DEBUG: https://s3.amazonaws.com:443 "GET /models.huggingface.co/bert/bert-base-chinese.tar.gz HTTP/1.1" 200 382072689
  0%|          | 0/382072689 [00:00<?, ?B/s]  0%|          | 1024/382072689 [00:00<22:59:05, 4617.42B/s]  0%|          | 35840/382072689 [00:00<1:11:46, 88706.41B/s]  0%|          | 88064/382072689 [00:00<43:24, 146672.09B/s]   0%|          | 192512/382072689 [00:00<24:38, 258270.57B/s]  0%|          | 401408/382072689 [00:01<13:25, 473988.36B/s]  0%|          | 836608/382072689 [00:01<06:55, 918367.91B/s]  0%|          | 1393664/382072689 [00:01<04:39, 1361793.60B/s]  1%|          | 2192384/382072689 [00:01<03:13, 1966377.81B/s]  1%|          | 2814976/382072689 [00:02<02:56, 2143223.21B/s]  1%|          | 3453952/382072689 [00:02<03:01, 2088285.38B/s]  1%|          | 3699712/382072689 [00:02<03:14, 1948360.45B/s]  1%|          | 4191232/382072689 [00:02<03:12, 1966972.13B/s]  1%|          | 4715520/382072689 [00:03<03:07, 2016642.33B/s]  1%|▏         | 5239808/382072689 [00:03<03:03, 2055914.63B/s]  2%|▏         | 5780480/382072689 [00:03<02:59, 2100854.72B/s]  2%|▏         | 6321152/382072689 [00:03<02:24, 2594522.95B/s]  2%|▏         | 6629376/382072689 [00:03<02:50, 2205195.59B/s]  2%|▏         | 6894592/382072689 [00:04<03:04, 2038447.64B/s]  2%|▏         | 7451648/382072689 [00:04<02:56, 2125057.35B/s]  2%|▏         | 8025088/382072689 [00:04<02:50, 2196451.36B/s]  2%|▏         | 8598528/382072689 [00:04<02:34, 2421095.51B/s]  2%|▏         | 8893440/382072689 [00:04<02:36, 2379932.71B/s]  2%|▏         | 9188352/382072689 [00:05<02:49, 2197493.56B/s]  3%|▎         | 9761792/382072689 [00:05<02:19, 2674904.88B/s]  3%|▎         | 10042368/382072689 [00:05<02:22, 2608572.60B/s]  3%|▎         | 10351616/382072689 [00:05<02:25, 2560105.21B/s]  3%|▎         | 10611712/382072689 [00:05<02:51, 2168585.79B/s]  3%|▎         | 10836992/382072689 [00:05<03:16, 1889447.11B/s]  3%|▎         | 11400192/382072689 [00:06<03:00, 2056571.76B/s]  3%|▎         | 11990016/382072689 [00:06<02:49, 2182164.76B/s]  3%|▎         | 12579840/382072689 [00:06<02:19, 2645145.33B/s]  3%|▎         | 12859392/382072689 [00:06<02:22, 2593170.22B/s]  3%|▎         | 13169664/382072689 [00:06<02:24, 2551424.41B/s]  4%|▎         | 13429760/382072689 [00:06<02:28, 2479887.71B/s]  4%|▎         | 13759488/382072689 [00:06<02:27, 2495166.41B/s]  4%|▎         | 14010368/382072689 [00:07<02:32, 2407153.31B/s]  4%|▍         | 14365696/382072689 [00:07<03:02, 2011297.30B/s]  4%|▍         | 14955520/382072689 [00:07<02:49, 2169230.31B/s]  4%|▍         | 15545344/382072689 [00:07<02:42, 2253550.03B/s]  4%|▍         | 16135168/382072689 [00:08<02:38, 2304228.22B/s]  4%|▍         | 16724992/382072689 [00:08<02:23, 2550767.69B/s]  4%|▍         | 17118208/382072689 [00:08<02:19, 2609893.61B/s]  5%|▍         | 17384448/382072689 [00:08<02:38, 2303447.61B/s]  5%|▍         | 17904640/382072689 [00:08<02:15, 2678001.57B/s]  5%|▍         | 18183168/382072689 [00:08<02:19, 2610286.18B/s]  5%|▍         | 18450432/382072689 [00:09<03:01, 2006614.13B/s]  5%|▍         | 18953216/382072689 [00:09<02:58, 2037946.31B/s]  5%|▌         | 19543040/382072689 [00:09<02:47, 2168412.71B/s]  5%|▌         | 20132864/382072689 [00:09<02:41, 2246918.49B/s]  5%|▌         | 20722688/382072689 [00:09<02:15, 2668594.97B/s]  5%|▌         | 21010432/382072689 [00:10<02:18, 2615917.26B/s]  6%|▌         | 21328896/382072689 [00:10<02:47, 2153325.42B/s]  6%|▌         | 21918720/382072689 [00:10<02:40, 2245002.81B/s]  6%|▌         | 22508544/382072689 [00:10<02:13, 2697944.05B/s]  6%|▌         | 22802432/382072689 [00:10<02:15, 2645316.34B/s]  6%|▌         | 23114752/382072689 [00:11<02:46, 2154145.74B/s]  6%|▌         | 23704576/382072689 [00:11<02:34, 2325608.75B/s]  6%|▋         | 24179712/382072689 [00:11<02:09, 2753599.61B/s]  6%|▋         | 24492032/382072689 [00:11<02:25, 2449278.19B/s]  7%|▋         | 24900608/382072689 [00:11<02:16, 2625077.30B/s]  7%|▋         | 25186304/382072689 [00:11<02:19, 2563405.46B/s]  7%|▋         | 25506816/382072689 [00:11<02:19, 2564043.72B/s]  7%|▋         | 25774080/382072689 [00:12<02:23, 2478181.51B/s]  7%|▋         | 26113024/382072689 [00:12<02:20, 2538426.16B/s]  7%|▋         | 26372096/382072689 [00:12<02:26, 2433620.44B/s]  7%|▋         | 26735616/382072689 [00:12<02:45, 2143522.94B/s]  7%|▋         | 27210752/382072689 [00:12<02:10, 2713905.93B/s]  7%|▋         | 27509760/382072689 [00:12<02:31, 2346033.74B/s]  7%|▋         | 27964416/382072689 [00:12<02:11, 2688429.32B/s]  7%|▋         | 28256256/382072689 [00:12<02:16, 2592758.83B/s]  7%|▋         | 28603392/382072689 [00:13<02:38, 2236794.88B/s]  8%|▊         | 29094912/382072689 [00:13<02:06, 2792757.29B/s]  8%|▊         | 29408256/382072689 [00:13<02:25, 2429132.69B/s]  8%|▊         | 29881344/382072689 [00:13<02:28, 2365687.49B/s]  8%|▊         | 30389248/382072689 [00:13<02:01, 2896463.24B/s]  8%|▊         | 30717952/382072689 [00:13<02:18, 2537853.52B/s]  8%|▊         | 31208448/382072689 [00:14<02:22, 2458656.26B/s]  8%|▊         | 31732736/382072689 [00:14<01:56, 2999184.34B/s]  8%|▊         | 32076800/382072689 [00:14<02:12, 2643874.16B/s]  9%|▊         | 32568320/382072689 [00:14<02:17, 2540107.61B/s]  9%|▊         | 33108992/382072689 [00:14<01:53, 3081267.83B/s]  9%|▉         | 33461248/382072689 [00:14<02:08, 2710829.68B/s]  9%|▉         | 33977344/382072689 [00:15<02:12, 2629497.45B/s]  9%|▉         | 34550784/382072689 [00:15<01:48, 3211642.29B/s]  9%|▉         | 34917376/382072689 [00:15<02:02, 2827197.09B/s]  9%|▉         | 35468288/382072689 [00:15<02:05, 2755064.38B/s]  9%|▉         | 36058112/382072689 [00:15<01:43, 3354287.58B/s] 10%|▉         | 36442112/382072689 [00:15<01:57, 2948654.80B/s] 10%|▉         | 37008384/382072689 [00:16<01:59, 2876824.77B/s] 10%|▉         | 37630976/382072689 [00:16<01:37, 3525292.31B/s] 10%|▉         | 38036480/382072689 [00:16<01:51, 3081749.89B/s] 10%|█         | 38646784/382072689 [00:16<01:53, 3032565.14B/s] 10%|█         | 39318528/382072689 [00:16<01:31, 3727989.69B/s] 10%|█         | 39746560/382072689 [00:16<01:44, 3273354.36B/s] 11%|█         | 40383488/382072689 [00:17<01:46, 3202221.93B/s] 11%|█         | 41088000/382072689 [00:17<01:26, 3935703.04B/s] 11%|█         | 41540608/382072689 [00:17<01:38, 3458325.19B/s] 11%|█         | 42218496/382072689 [00:17<01:39, 3402837.40B/s] 11%|█         | 42972160/382072689 [00:17<01:20, 4193072.10B/s] 11%|█▏        | 43453440/382072689 [00:17<01:32, 3665510.05B/s] 12%|█▏        | 44184576/382072689 [00:18<01:33, 3624162.33B/s] 12%|█▏        | 44987392/382072689 [00:18<01:15, 4475573.28B/s] 12%|█▏        | 45503488/382072689 [00:18<01:26, 3906588.94B/s] 12%|█▏        | 46281728/382072689 [00:18<01:26, 3875396.90B/s] 12%|█▏        | 47150080/382072689 [00:18<01:10, 4773743.37B/s] 12%|█▏        | 47696896/382072689 [00:18<01:20, 4172064.80B/s] 13%|█▎        | 48542720/382072689 [00:19<01:20, 4148019.66B/s] 13%|█▎        | 49476608/382072689 [00:19<01:04, 5138551.74B/s] 13%|█▎        | 50067456/382072689 [00:19<01:13, 4495671.32B/s] 13%|█▎        | 50967552/382072689 [00:19<01:17, 4276289.33B/s] 14%|█▎        | 52245504/382072689 [00:19<01:08, 4803518.11B/s] 14%|█▍        | 53286912/382072689 [00:19<00:56, 5820050.04B/s] 14%|█▍        | 53954560/382072689 [00:20<01:04, 5079619.81B/s] 14%|█▍        | 54948864/382072689 [00:20<01:05, 5028769.03B/s] 15%|█▍        | 56062976/382072689 [00:20<00:52, 6182983.85B/s] 15%|█▍        | 56777728/382072689 [00:20<01:00, 5373196.77B/s] 15%|█▌        | 57865216/382072689 [00:20<01:00, 5373631.33B/s] 15%|█▌        | 59077632/382072689 [00:20<00:48, 6636202.71B/s] 16%|█▌        | 59841536/382072689 [00:21<00:55, 5802471.55B/s] 16%|█▌        | 61010944/382072689 [00:21<00:55, 5777198.71B/s] 16%|█▋        | 62321664/382072689 [00:21<00:44, 7174000.11B/s] 17%|█▋        | 63148032/382072689 [00:21<00:50, 6279335.75B/s] 17%|█▋        | 64402432/382072689 [00:21<00:51, 6222040.15B/s] 17%|█▋        | 65811456/382072689 [00:21<00:40, 7751384.34B/s] 17%|█▋        | 66708480/382072689 [00:22<00:46, 6719360.43B/s] 18%|█▊        | 68072448/382072689 [00:22<00:48, 6452739.35B/s] 18%|█▊        | 70005760/382072689 [00:22<00:37, 8371496.60B/s] 19%|█▊        | 70944768/382072689 [00:22<00:38, 8001069.79B/s] 19%|█▉        | 72020992/382072689 [00:22<00:36, 8413248.46B/s] 19%|█▉        | 72921088/382072689 [00:22<00:39, 7918233.58B/s] 19%|█▉        | 74101760/382072689 [00:22<00:35, 8666512.94B/s] 20%|█▉        | 75012096/382072689 [00:23<00:38, 8051274.93B/s] 20%|█▉        | 76280832/382072689 [00:23<00:34, 8963475.61B/s] 20%|██        | 77212672/382072689 [00:23<00:36, 8269615.69B/s] 20%|██        | 78181376/382072689 [00:23<00:35, 8452446.61B/s] 21%|██        | 79049728/382072689 [00:23<00:38, 7808567.21B/s] 21%|██        | 80409600/382072689 [00:23<00:33, 9035214.22B/s] 21%|██▏       | 81340416/382072689 [00:23<00:36, 8284920.86B/s] 22%|██▏       | 82637824/382072689 [00:23<00:32, 9272140.62B/s] 22%|██▏       | 83594240/382072689 [00:24<00:35, 8426782.25B/s] 22%|██▏       | 84866048/382072689 [00:24<00:31, 9425128.93B/s] 22%|██▏       | 85844992/382072689 [00:24<00:34, 8592685.67B/s] 23%|██▎       | 87077888/382072689 [00:24<00:31, 9503963.71B/s] 23%|██▎       | 88068096/382072689 [00:24<00:34, 8630520.01B/s] 23%|██▎       | 89306112/382072689 [00:24<00:30, 9487178.62B/s] 24%|██▎       | 90294272/382072689 [00:24<00:33, 8599034.97B/s] 24%|██▍       | 91304960/382072689 [00:24<00:32, 8909928.43B/s] 24%|██▍       | 92227584/382072689 [00:25<00:35, 8116605.73B/s] 24%|██▍       | 93516800/382072689 [00:25<00:31, 9290214.16B/s] 25%|██▍       | 94487552/382072689 [00:25<00:34, 8309749.05B/s] 25%|██▌       | 95761408/382072689 [00:25<00:38, 7379712.75B/s] 25%|██▌       | 96555008/382072689 [00:25<00:52, 5436643.92B/s] 25%|██▌       | 97198080/382072689 [00:26<01:02, 4528667.29B/s] 26%|██▌       | 98628608/382072689 [00:26<00:47, 6024398.11B/s] 26%|██▌       | 99357696/382072689 [00:26<00:48, 5813962.33B/s] 26%|██▌       | 100185088/382072689 [00:26<00:44, 6275720.13B/s] 26%|██▋       | 100891648/382072689 [00:26<00:47, 5921762.38B/s] 27%|██▋       | 101577728/382072689 [00:26<00:46, 6036175.68B/s] 27%|██▋       | 102222848/382072689 [00:26<00:49, 5600016.76B/s] 27%|██▋       | 103134208/382072689 [00:26<00:43, 6343536.96B/s] 27%|██▋       | 103803904/382072689 [00:26<00:47, 5848332.98B/s] 27%|██▋       | 104690688/382072689 [00:27<00:42, 6499586.73B/s] 28%|██▊       | 105370624/382072689 [00:27<00:46, 5965865.58B/s] 28%|██▊       | 106247168/382072689 [00:27<00:41, 6636206.53B/s] 28%|██▊       | 106941440/382072689 [00:27<00:45, 6026105.28B/s] 28%|██▊       | 107639808/382072689 [00:27<00:56, 4844286.01B/s] 29%|██▊       | 109179904/382072689 [00:27<00:38, 7015127.39B/s] 29%|██▉       | 109983744/382072689 [00:27<00:43, 6227156.98B/s] 29%|██▉       | 110752768/382072689 [00:28<00:41, 6541607.89B/s] 29%|██▉       | 111474688/382072689 [00:28<00:44, 6066869.64B/s] 29%|██▉       | 112325632/382072689 [00:28<00:52, 5179075.13B/s] 30%|██▉       | 113849344/382072689 [00:28<00:36, 7270248.42B/s] 30%|███       | 114706432/382072689 [00:28<00:41, 6471205.25B/s] 30%|███       | 115453952/382072689 [00:28<00:47, 5659996.70B/s] 31%|███       | 116896768/382072689 [00:29<00:36, 7360568.09B/s] 31%|███       | 117746688/382072689 [00:29<00:42, 6257800.60B/s] 31%|███       | 118551552/382072689 [00:29<00:46, 5622043.22B/s] 31%|███▏      | 120009728/382072689 [00:29<00:35, 7389270.69B/s] 32%|███▏      | 120879104/382072689 [00:29<00:41, 6251981.66B/s] 32%|███▏      | 121664512/382072689 [00:29<00:39, 6573098.33B/s] 32%|███▏      | 122415104/382072689 [00:29<00:42, 6142044.69B/s] 32%|███▏      | 123237376/382072689 [00:30<00:48, 5291107.50B/s] 33%|███▎      | 124744704/382072689 [00:30<00:35, 7197081.10B/s] 33%|███▎      | 125581312/382072689 [00:30<00:40, 6378642.84B/s] 33%|███▎      | 126350336/382072689 [00:30<00:45, 5666831.82B/s] 33%|███▎      | 127808512/382072689 [00:30<00:34, 7379151.00B/s] 34%|███▎      | 128656384/382072689 [00:30<00:40, 6226975.05B/s] 34%|███▍      | 129463296/382072689 [00:31<00:44, 5646878.91B/s] 34%|███▍      | 130921472/382072689 [00:31<00:34, 7325399.95B/s] 34%|███▍      | 131770368/382072689 [00:31<00:40, 6199547.02B/s] 35%|███▍      | 132576256/382072689 [00:31<00:40, 6109503.55B/s] 35%|███▍      | 133257216/382072689 [00:31<00:40, 6194854.60B/s] 35%|███▌      | 134132736/382072689 [00:31<00:39, 6206712.69B/s] 35%|███▌      | 134790144/382072689 [00:31<00:39, 6258037.82B/s] 36%|███▌      | 135689216/382072689 [00:32<00:39, 6268241.34B/s] 36%|███▌      | 136335360/382072689 [00:32<00:39, 6258255.09B/s] 36%|███▌      | 137245696/382072689 [00:32<00:38, 6311119.37B/s] 36%|███▌      | 137885696/382072689 [00:32<00:38, 6298567.88B/s] 36%|███▋      | 138802176/382072689 [00:32<00:34, 7019744.81B/s] 37%|███▋      | 139518976/382072689 [00:32<00:38, 6283815.19B/s] 37%|███▋      | 140366848/382072689 [00:32<00:35, 6845594.90B/s] 37%|███▋      | 141075456/382072689 [00:32<00:39, 6167437.35B/s] 37%|███▋      | 141931520/382072689 [00:33<00:43, 5570046.26B/s] 38%|███▊      | 143389696/382072689 [00:33<00:31, 7493031.42B/s] 38%|███▊      | 144204800/382072689 [00:33<00:38, 6188494.39B/s] 38%|███▊      | 145044480/382072689 [00:33<00:38, 6119679.29B/s] 38%|███▊      | 145709056/382072689 [00:33<00:38, 6175820.76B/s] 38%|███▊      | 146600960/382072689 [00:33<00:34, 6832154.08B/s] 39%|███▊      | 147328000/382072689 [00:33<00:37, 6220870.31B/s] 39%|███▉      | 148163584/382072689 [00:33<00:34, 6746589.57B/s] 39%|███▉      | 148875264/382072689 [00:34<00:38, 6095241.12B/s] 39%|███▉      | 149730304/382072689 [00:34<00:44, 5211256.44B/s] 40%|███▉      | 151237632/382072689 [00:34<00:31, 7316646.24B/s] 40%|███▉      | 152080384/382072689 [00:34<00:35, 6439815.14B/s] 40%|████      | 152843264/382072689 [00:34<00:40, 5721450.35B/s] 40%|████      | 154153984/382072689 [00:34<00:32, 7087585.87B/s] 41%|████      | 154949632/382072689 [00:35<00:38, 5878971.05B/s] 41%|████      | 155776000/382072689 [00:35<00:37, 5976361.75B/s] 41%|████      | 156435456/382072689 [00:35<00:37, 5963260.69B/s] 41%|████      | 157332480/382072689 [00:35<00:36, 6175019.46B/s] 41%|████▏     | 157980672/382072689 [00:35<00:36, 6076010.63B/s] 42%|████▏     | 158905344/382072689 [00:35<00:41, 5381364.18B/s] 42%|████▏     | 160429056/382072689 [00:35<00:29, 7510930.59B/s] 42%|████▏     | 161284096/382072689 [00:36<00:33, 6507536.15B/s] 42%|████▏     | 162024448/382072689 [00:36<00:35, 6270743.85B/s] 43%|████▎     | 162711552/382072689 [00:36<00:35, 6234348.38B/s] 43%|████▎     | 163591168/382072689 [00:36<00:40, 5409277.52B/s] 43%|████▎     | 165114880/382072689 [00:36<00:29, 7418969.88B/s] 43%|████▎     | 165961728/382072689 [00:36<00:33, 6512442.27B/s] 44%|████▎     | 166704128/382072689 [00:36<00:34, 6286422.06B/s] 44%|████▍     | 167390208/382072689 [00:37<00:34, 6256636.40B/s] 44%|████▍     | 168276992/382072689 [00:37<00:39, 5439980.31B/s] 44%|████▍     | 169800704/382072689 [00:37<00:28, 7503521.20B/s] 45%|████▍     | 170664960/382072689 [00:37<00:32, 6536249.54B/s] 45%|████▍     | 171413504/382072689 [00:37<00:33, 6290251.61B/s] 45%|████▌     | 172106752/382072689 [00:37<00:33, 6206612.84B/s] 45%|████▌     | 172979200/382072689 [00:37<00:32, 6370364.76B/s] 45%|████▌     | 173647872/382072689 [00:38<00:33, 6274836.12B/s] 46%|████▌     | 174552064/382072689 [00:38<00:32, 6421652.87B/s] 46%|████▌     | 175208448/382072689 [00:38<00:32, 6277440.40B/s] 46%|████▌     | 176124928/382072689 [00:38<00:31, 6478950.98B/s] 46%|████▋     | 176778240/382072689 [00:38<00:32, 6310560.23B/s] 47%|████▋     | 177714176/382072689 [00:38<00:31, 6512117.13B/s] 47%|████▋     | 178365440/382072689 [00:38<00:32, 6324512.89B/s] 47%|████▋     | 179303424/382072689 [00:38<00:31, 6526638.20B/s] 47%|████▋     | 179953664/382072689 [00:39<00:31, 6385490.67B/s] 47%|████▋     | 180827136/382072689 [00:39<00:37, 5383352.48B/s] 48%|████▊     | 182383616/382072689 [00:39<00:26, 7658212.43B/s] 48%|████▊     | 183246848/382072689 [00:39<00:30, 6511252.84B/s] 48%|████▊     | 184005632/382072689 [00:39<00:30, 6391843.90B/s] 48%|████▊     | 184707072/382072689 [00:39<00:31, 6298611.33B/s] 49%|████▊     | 185611264/382072689 [00:39<00:35, 5528104.44B/s] 49%|████▉     | 187184128/382072689 [00:40<00:26, 7348264.82B/s] 49%|████▉     | 187986944/382072689 [00:40<00:29, 6564364.73B/s] 49%|████▉     | 188789760/382072689 [00:40<00:29, 6519587.26B/s] 50%|████▉     | 189478912/382072689 [00:40<00:30, 6364297.88B/s] 50%|████▉     | 190395392/382072689 [00:40<00:33, 5640045.83B/s] 50%|█████     | 191968256/382072689 [00:40<00:24, 7666201.63B/s] 50%|█████     | 192819200/382072689 [00:41<00:28, 6640519.94B/s] 51%|█████     | 193590272/382072689 [00:41<00:33, 5616821.61B/s] 51%|█████     | 195163136/382072689 [00:41<00:24, 7647031.41B/s] 51%|█████▏    | 196069376/382072689 [00:41<00:28, 6629048.23B/s] 52%|█████▏    | 196846592/382072689 [00:41<00:33, 5540215.01B/s] 52%|█████▏    | 198390784/382072689 [00:41<00:28, 6497568.92B/s] 52%|█████▏    | 199299072/382072689 [00:41<00:26, 7002171.87B/s] 52%|█████▏    | 200075264/382072689 [00:42<00:31, 5727639.18B/s] 53%|█████▎    | 201602048/382072689 [00:42<00:25, 7145251.46B/s] 53%|█████▎    | 202399744/382072689 [00:42<00:26, 6746959.12B/s] 53%|█████▎    | 203207680/382072689 [00:42<00:25, 6961823.00B/s] 53%|█████▎    | 203949056/382072689 [00:42<00:27, 6423754.98B/s] 54%|█████▎    | 204829696/382072689 [00:42<00:25, 6938723.58B/s] 54%|█████▍    | 205559808/382072689 [00:42<00:27, 6394185.62B/s] 54%|█████▍    | 206451712/382072689 [00:43<00:25, 6914974.83B/s] 54%|█████▍    | 207172608/382072689 [00:43<00:27, 6371956.64B/s] 54%|█████▍    | 208090112/382072689 [00:43<00:25, 6924499.84B/s] 55%|█████▍    | 208806912/382072689 [00:43<00:27, 6361256.82B/s] 55%|█████▍    | 209728512/382072689 [00:43<00:24, 6953778.17B/s] 55%|█████▌    | 210447360/382072689 [00:43<00:26, 6375422.82B/s] 55%|█████▌    | 211366912/382072689 [00:43<00:24, 6967413.63B/s] 56%|█████▌    | 212085760/382072689 [00:43<00:26, 6386178.29B/s] 56%|█████▌    | 213021696/382072689 [00:44<00:24, 7013092.18B/s] 56%|█████▌    | 213745664/382072689 [00:44<00:26, 6430487.59B/s] 56%|█████▌    | 214692864/382072689 [00:44<00:23, 7072099.58B/s] 56%|█████▋    | 215422976/382072689 [00:44<00:25, 6462737.12B/s] 57%|█████▋    | 216364032/382072689 [00:44<00:23, 7107095.92B/s] 57%|█████▋    | 217099264/382072689 [00:44<00:25, 6531551.36B/s] 57%|█████▋    | 218051584/382072689 [00:44<00:23, 7126528.44B/s] 57%|█████▋    | 218785792/382072689 [00:44<00:25, 6526774.28B/s] 58%|█████▊    | 219755520/382072689 [00:45<00:22, 7203253.73B/s] 58%|█████▊    | 220498944/382072689 [00:45<00:24, 6596144.45B/s] 58%|█████▊    | 221475840/382072689 [00:45<00:22, 7278257.22B/s] 58%|█████▊    | 222227456/382072689 [00:45<00:23, 6689303.76B/s] 58%|█████▊    | 223196160/382072689 [00:45<00:21, 7316468.05B/s] 59%|█████▊    | 223950848/382072689 [00:45<00:23, 6700289.94B/s] 59%|█████▉    | 224949248/382072689 [00:45<00:21, 7402111.87B/s] 59%|█████▉    | 225713152/382072689 [00:45<00:23, 6751279.86B/s] 59%|█████▉    | 226718720/382072689 [00:46<00:20, 7469748.70B/s] 60%|█████▉    | 227491840/382072689 [00:46<00:22, 6854604.34B/s] 60%|█████▉    | 228504576/382072689 [00:46<00:20, 7546365.65B/s] 60%|██████    | 229283840/382072689 [00:46<00:22, 6891886.92B/s] 60%|██████    | 230323200/382072689 [00:46<00:19, 7647218.57B/s] 60%|██████    | 231114752/382072689 [00:46<00:21, 7039924.67B/s] 61%|██████    | 232141824/382072689 [00:46<00:19, 7739317.63B/s] 61%|██████    | 232941568/382072689 [00:46<00:21, 7070590.25B/s] 61%|██████    | 233993216/382072689 [00:47<00:18, 7813262.77B/s] 61%|██████▏   | 234801152/382072689 [00:47<00:20, 7160541.07B/s] 62%|██████▏   | 235877376/382072689 [00:47<00:18, 7935927.51B/s] 62%|██████▏   | 236697600/382072689 [00:47<00:20, 7258816.89B/s] 62%|██████▏   | 237777920/382072689 [00:47<00:17, 8033225.82B/s] 62%|██████▏   | 238609408/382072689 [00:47<00:19, 7308278.93B/s] 63%|██████▎   | 239711232/382072689 [00:47<00:17, 8187601.54B/s] 63%|██████▎   | 240563200/382072689 [00:47<00:18, 7457862.28B/s] 63%|██████▎   | 241677312/382072689 [00:47<00:16, 8270338.08B/s] 63%|██████▎   | 242537472/382072689 [00:48<00:18, 7589225.24B/s] 64%|██████▍   | 243676160/382072689 [00:48<00:16, 8409218.73B/s] 64%|██████▍   | 244547584/382072689 [00:48<00:17, 7672214.69B/s] 64%|██████▍   | 245707776/382072689 [00:48<00:15, 8563259.83B/s] 65%|██████▍   | 246597632/382072689 [00:48<00:17, 7829143.04B/s] 65%|██████▍   | 247772160/382072689 [00:48<00:15, 8747074.11B/s] 65%|██████▌   | 248682496/382072689 [00:48<00:16, 7967879.68B/s] 65%|██████▌   | 249885696/382072689 [00:48<00:14, 8846893.03B/s] 66%|██████▌   | 250805248/382072689 [00:49<00:16, 8146639.40B/s] 66%|██████▌   | 252015616/382072689 [00:49<00:14, 9032303.33B/s] 66%|██████▌   | 252951552/382072689 [00:49<00:15, 8195721.88B/s] 66%|██████▋   | 253804544/382072689 [00:49<00:19, 6449819.21B/s] 67%|██████▋   | 255898624/382072689 [00:49<00:13, 9180287.58B/s] 67%|██████▋   | 256913408/382072689 [00:49<00:15, 8255073.41B/s] 68%|██████▊   | 258077696/382072689 [00:49<00:13, 8974890.23B/s] 68%|██████▊   | 259050496/382072689 [00:50<00:14, 8256917.85B/s] 68%|██████▊   | 260240384/382072689 [00:50<00:13, 9118015.05B/s] 68%|██████▊   | 261214208/382072689 [00:50<00:14, 8352096.02B/s] 69%|██████▊   | 262403072/382072689 [00:50<00:13, 9182564.26B/s] 69%|██████▉   | 263373824/382072689 [00:50<00:14, 8346580.01B/s] 69%|██████▉   | 264565760/382072689 [00:50<00:12, 9228834.56B/s] 69%|██████▉   | 265538560/382072689 [00:50<00:13, 8381932.38B/s] 70%|██████▉   | 266728448/382072689 [00:50<00:13, 8333539.96B/s] 70%|███████   | 267593728/382072689 [00:51<00:13, 8387787.10B/s] 70%|███████   | 268891136/382072689 [00:51<00:13, 8591288.47B/s] 71%|███████   | 269764608/382072689 [00:51<00:13, 8618962.23B/s] 71%|███████   | 271053824/382072689 [00:51<00:11, 9703345.44B/s] 71%|███████   | 272047104/382072689 [00:51<00:12, 8650153.97B/s] 72%|███████▏  | 273232896/382072689 [00:51<00:13, 8244697.18B/s] 72%|███████▏  | 274508800/382072689 [00:51<00:11, 9333729.38B/s] 72%|███████▏  | 275488768/382072689 [00:52<00:14, 7543571.32B/s] 73%|███████▎  | 277525504/382072689 [00:52<00:10, 10201698.37B/s] 73%|███████▎  | 278662144/382072689 [00:52<00:11, 8962544.00B/s]  73%|███████▎  | 279737344/382072689 [00:52<00:12, 8331682.13B/s] 74%|███████▎  | 281673728/382072689 [00:52<00:09, 10797981.30B/s] 74%|███████▍  | 282888192/382072689 [00:52<00:11, 8378633.47B/s]  74%|███████▍  | 284095488/382072689 [00:52<00:11, 8203718.76B/s] 75%|███████▍  | 285727744/382072689 [00:53<00:09, 9903994.66B/s] 75%|███████▌  | 286873600/382072689 [00:53<00:11, 7974107.54B/s] 75%|███████▌  | 288388096/382072689 [00:53<00:10, 9357794.40B/s] 76%|███████▌  | 289494016/382072689 [00:53<00:10, 8625912.33B/s] 76%|███████▌  | 290599936/382072689 [00:53<00:11, 8259182.02B/s] 76%|███████▋  | 292040704/382072689 [00:53<00:09, 9619872.16B/s] 77%|███████▋  | 293110784/382072689 [00:54<00:11, 7658831.23B/s] 77%|███████▋  | 294974464/382072689 [00:54<00:08, 9763109.29B/s] 78%|███████▊  | 296110080/382072689 [00:54<00:09, 8960126.01B/s] 78%|███████▊  | 297186304/382072689 [00:54<00:10, 8410528.19B/s] 78%|███████▊  | 298874880/382072689 [00:54<00:08, 10297495.91B/s] 79%|███████▊  | 300026880/382072689 [00:54<00:10, 8055057.86B/s]  79%|███████▉  | 301577216/382072689 [00:54<00:09, 8534472.80B/s] 79%|███████▉  | 303077376/382072689 [00:55<00:07, 9883986.38B/s] 80%|███████▉  | 304199680/382072689 [00:55<00:09, 7931507.81B/s] 80%|████████  | 305951744/382072689 [00:55<00:07, 9811918.05B/s] 80%|████████  | 307115008/382072689 [00:55<00:08, 9101236.53B/s] 81%|████████  | 308163584/382072689 [00:55<00:08, 8409235.26B/s] 81%|████████  | 309749760/382072689 [00:55<00:07, 10053210.65B/s] 81%|████████▏ | 310878208/382072689 [00:55<00:08, 7930932.81B/s]  82%|████████▏ | 312570880/382072689 [00:56<00:08, 8646925.73B/s] 82%|████████▏ | 314176512/382072689 [00:56<00:06, 10184334.16B/s] 83%|████████▎ | 315334656/382072689 [00:56<00:08, 8114970.74B/s]  83%|████████▎ | 316978176/382072689 [00:56<00:07, 8719498.88B/s] 83%|████████▎ | 318602240/382072689 [00:56<00:06, 10254189.30B/s] 84%|████████▎ | 319775744/382072689 [00:56<00:07, 8177164.61B/s]  84%|████████▍ | 321401856/382072689 [00:57<00:06, 9065203.36B/s] 84%|████████▍ | 322432000/382072689 [00:57<00:06, 9062536.55B/s] 85%|████████▍ | 323630080/382072689 [00:57<00:06, 8741118.31B/s] 85%|████████▌ | 325015552/382072689 [00:57<00:05, 9886629.14B/s] 85%|████████▌ | 326085632/382072689 [00:57<00:07, 7849342.81B/s] 86%|████████▌ | 328070144/382072689 [00:57<00:05, 10156072.09B/s] 86%|████████▌ | 329233408/382072689 [00:57<00:05, 9257422.42B/s]  86%|████████▋ | 330331136/382072689 [00:58<00:05, 9024050.31B/s] 87%|████████▋ | 331308032/382072689 [00:58<00:05, 8930768.36B/s] 87%|████████▋ | 332592128/382072689 [00:58<00:05, 8795954.67B/s] 87%|████████▋ | 333952000/382072689 [00:58<00:04, 9925466.04B/s] 88%|████████▊ | 335001600/382072689 [00:58<00:05, 7862046.93B/s] 88%|████████▊ | 337081344/382072689 [00:58<00:04, 10602836.72B/s] 89%|████████▊ | 338299904/382072689 [00:58<00:04, 9378390.15B/s]  89%|████████▉ | 339407872/382072689 [00:59<00:04, 9145329.71B/s] 89%|████████▉ | 340409344/382072689 [00:59<00:04, 9062228.36B/s] 89%|████████▉ | 341701632/382072689 [00:59<00:04, 9310111.78B/s] 90%|████████▉ | 342675456/382072689 [00:59<00:04, 9035450.15B/s] 90%|█████████ | 344011776/382072689 [00:59<00:04, 9426607.22B/s] 90%|█████████ | 344973312/382072689 [00:59<00:04, 9136546.76B/s] 91%|█████████ | 346338304/382072689 [00:59<00:03, 9575267.10B/s] 91%|█████████ | 347302912/382072689 [00:59<00:03, 9235487.03B/s] 91%|█████████▏| 348681216/382072689 [01:00<00:03, 9624332.68B/s] 92%|█████████▏| 349643776/382072689 [01:00<00:03, 9297008.47B/s] 92%|█████████▏| 351040512/382072689 [01:00<00:03, 9756538.33B/s] 92%|█████████▏| 352013312/382072689 [01:00<00:03, 9438794.95B/s] 92%|█████████▏| 353416192/382072689 [01:00<00:02, 9806107.01B/s] 93%|█████████▎| 354392064/382072689 [01:00<00:02, 9466118.18B/s] 93%|█████████▎| 355824640/382072689 [01:00<00:02, 9872205.37B/s] 93%|█████████▎| 356805632/382072689 [01:00<00:02, 9571830.96B/s] 94%|█████████▍| 358249472/382072689 [01:01<00:02, 9969549.17B/s] 94%|█████████▍| 359238656/382072689 [01:01<00:02, 9580013.20B/s] 94%|█████████▍| 360707072/382072689 [01:01<00:02, 10077825.18B/s] 95%|█████████▍| 361707520/382072689 [01:01<00:02, 9778422.15B/s]  95%|█████████▌| 363181056/382072689 [01:01<00:01, 10170312.36B/s] 95%|█████████▌| 364189696/382072689 [01:01<00:01, 9834048.92B/s]  96%|█████████▌| 365671424/382072689 [01:01<00:01, 10332513.76B/s] 96%|█████████▌| 366696448/382072689 [01:01<00:01, 9868328.11B/s]  96%|█████████▋| 368210944/382072689 [01:02<00:01, 10405748.09B/s] 97%|█████████▋| 369244160/382072689 [01:02<00:01, 10058625.95B/s] 97%|█████████▋| 370537472/382072689 [01:02<00:01, 10012106.32B/s] 97%|█████████▋| 371533824/382072689 [01:02<00:01, 9539925.24B/s]  98%|█████████▊| 373093376/382072689 [01:02<00:00, 10410018.64B/s] 98%|█████████▊| 374129664/382072689 [01:02<00:00, 9892191.42B/s]  98%|█████████▊| 375649280/382072689 [01:02<00:00, 10470451.16B/s] 99%|█████████▊| 376691712/382072689 [01:02<00:00, 10010466.29B/s] 99%|█████████▉| 378188800/382072689 [01:02<00:00, 10639293.81B/s] 99%|█████████▉| 379248640/382072689 [01:03<00:00, 10153199.43B/s]100%|█████████▉| 380744704/382072689 [01:03<00:00, 10651507.51B/s]100%|█████████▉| 381805568/382072689 [01:03<00:00, 10170517.03B/s]100%|██████████| 382072689/382072689 [01:03<00:00, 6030092.21B/s] 
[16-10-2022 14:02:27] INFO: copying /tmp/tmpo0fga7_m to cache at /home/jiahaoran2022/.pytorch_pretrained_bert/42d4a64dda3243ffeca7ec268d5544122e67d9d06b971608796b483925716512.02ac7d664cff08d793eb00d6aac1d04368a1322435e5fe0a27c70b0b3a85327f
[16-10-2022 14:02:27] INFO: creating metadata file for /home/jiahaoran2022/.pytorch_pretrained_bert/42d4a64dda3243ffeca7ec268d5544122e67d9d06b971608796b483925716512.02ac7d664cff08d793eb00d6aac1d04368a1322435e5fe0a27c70b0b3a85327f
[16-10-2022 14:02:27] INFO: removing temp file /tmp/tmpo0fga7_m
[16-10-2022 14:02:27] INFO: loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese.tar.gz from cache at /home/jiahaoran2022/.pytorch_pretrained_bert/42d4a64dda3243ffeca7ec268d5544122e67d9d06b971608796b483925716512.02ac7d664cff08d793eb00d6aac1d04368a1322435e5fe0a27c70b0b3a85327f
[16-10-2022 14:02:27] INFO: extracting archive file /home/jiahaoran2022/.pytorch_pretrained_bert/42d4a64dda3243ffeca7ec268d5544122e67d9d06b971608796b483925716512.02ac7d664cff08d793eb00d6aac1d04368a1322435e5fe0a27c70b0b3a85327f to temp dir /tmp/tmpikkmc004
[16-10-2022 14:02:30] INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 21128
}

[16-10-2022 14:02:33] INFO: Weights from pretrained model not used in BertForSequenceEncoder: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
/home/jiahaoran2022/anaconda3/envs/chef/lib/python3.6/site-packages/pytorch_pretrained_bert/optimization.py:275: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:1005.)
  next_m.mul_(beta1).add_(1 - beta1, grad)
[16-10-2022 14:02:49] INFO: Epoch: 0, Step: 8, Loss: 1.5379403233528137
[16-10-2022 14:02:52] INFO: Epoch: 0, Step: 16, Loss: 1.5352708771824837
[16-10-2022 14:02:54] INFO: Epoch: 0, Step: 24, Loss: 1.5297614137331645
[16-10-2022 14:02:57] INFO: Epoch: 0, Step: 32, Loss: 1.502405934035778
[16-10-2022 14:03:00] INFO: Epoch: 0, Step: 40, Loss: 1.4659219682216644
[16-10-2022 14:03:03] INFO: Epoch: 0, Step: 48, Loss: 1.4109267542759578
[16-10-2022 14:03:06] INFO: Epoch: 0, Step: 56, Loss: 1.3364966873611723
[16-10-2022 14:03:09] INFO: Epoch: 0, Step: 64, Loss: 1.2703849282115698
[16-10-2022 14:03:12] INFO: Epoch: 0, Step: 72, Loss: 1.2095351806945271
[16-10-2022 14:03:14] INFO: Epoch: 0, Step: 80, Loss: 1.1401463091373443
[16-10-2022 14:03:17] INFO: Epoch: 0, Step: 88, Loss: 1.0706216008825735
[16-10-2022 14:03:20] INFO: Epoch: 0, Step: 96, Loss: 0.9998256006898979
[16-10-2022 14:03:23] INFO: Epoch: 0, Step: 104, Loss: 0.9323078205522436
[16-10-2022 14:03:26] INFO: Epoch: 0, Step: 112, Loss: 0.8711633918407772
[16-10-2022 14:03:29] INFO: Epoch: 0, Step: 120, Loss: 0.8160357357623677
[16-10-2022 14:03:32] INFO: Epoch: 0, Step: 128, Loss: 0.7667690436792327
[16-10-2022 14:03:34] INFO: Epoch: 0, Step: 136, Loss: 0.7226688277373529
[16-10-2022 14:03:37] INFO: Epoch: 0, Step: 144, Loss: 0.6831094654690888
[16-10-2022 14:03:40] INFO: Epoch: 0, Step: 152, Loss: 0.6475869072202937
[16-10-2022 14:03:43] INFO: Epoch: 0, Step: 160, Loss: 0.6155281005834695
[16-10-2022 14:03:46] INFO: Epoch: 0, Step: 168, Loss: 0.586432620292596
[16-10-2022 14:03:49] INFO: Epoch: 0, Step: 176, Loss: 0.5599318335867296
[16-10-2022 14:03:52] INFO: Epoch: 0, Step: 184, Loss: 0.5356933568153813
[16-10-2022 14:03:55] INFO: Epoch: 0, Step: 192, Loss: 0.5134395535624208
[16-10-2022 14:03:58] INFO: Epoch: 0, Step: 200, Loss: 0.49295202538021843
[16-10-2022 14:04:00] INFO: Epoch: 0, Step: 208, Loss: 0.4740354640570541
[16-10-2022 14:04:03] INFO: Epoch: 0, Step: 216, Loss: 0.456511845282404
[16-10-2022 14:04:06] INFO: Epoch: 0, Step: 224, Loss: 0.44023433172229226
[16-10-2022 14:04:09] INFO: Epoch: 0, Step: 232, Loss: 0.4250752514056111
[16-10-2022 14:04:12] INFO: Epoch: 0, Step: 240, Loss: 0.41092442154016073
[16-10-2022 14:04:15] INFO: Epoch: 0, Step: 248, Loss: 0.3976854020505515
[16-10-2022 14:04:18] INFO: Epoch: 0, Step: 256, Loss: 0.38527187717670586
[16-10-2022 14:04:20] INFO: Epoch: 0, Step: 264, Loss: 0.37360911574477074
[16-10-2022 14:04:23] INFO: Epoch: 0, Step: 272, Loss: 0.3626310878795159
[16-10-2022 14:04:26] INFO: Epoch: 0, Step: 280, Loss: 0.3522794899234473
[16-10-2022 14:04:29] INFO: Epoch: 0, Step: 288, Loss: 0.34250217026510654
[16-10-2022 14:04:32] INFO: Epoch: 0, Step: 296, Loss: 0.3332528436066413
[16-10-2022 14:04:35] INFO: Epoch: 0, Step: 304, Loss: 0.3244896747726575
[16-10-2022 14:04:37] INFO: Epoch: 0, Step: 312, Loss: 0.31617547712308947
[16-10-2022 14:04:40] INFO: Epoch: 0, Step: 320, Loss: 0.3082766987401101
[16-10-2022 14:04:43] INFO: Epoch: 0, Step: 328, Loss: 0.30076295915746526
[16-10-2022 14:04:46] INFO: Epoch: 0, Step: 336, Loss: 0.29360677366145993
[16-10-2022 14:04:49] INFO: Epoch: 0, Step: 344, Loss: 0.286783084838621
[16-10-2022 14:04:52] INFO: Epoch: 0, Step: 352, Loss: 0.2802694450509245
[16-10-2022 14:04:54] INFO: Epoch: 0, Step: 360, Loss: 0.3538146362679577
[16-10-2022 14:04:57] INFO: Epoch: 0, Step: 368, Loss: 0.5298658090419137
[16-10-2022 14:05:00] INFO: Epoch: 0, Step: 376, Loss: 0.6678549443766199
[16-10-2022 14:05:03] INFO: Epoch: 0, Step: 384, Loss: 0.7592913023485531
[16-10-2022 14:05:06] INFO: Epoch: 0, Step: 392, Loss: 0.7974338451797904
[16-10-2022 14:05:09] INFO: Epoch: 0, Step: 400, Loss: 0.792949250427846
[16-10-2022 14:05:12] INFO: Epoch: 0, Step: 408, Loss: 0.7790153490359623
[16-10-2022 14:05:14] INFO: Epoch: 0, Step: 416, Loss: 0.764512704518613
[16-10-2022 14:05:17] INFO: Epoch: 0, Step: 424, Loss: 0.7503683105636776
[16-10-2022 14:05:20] INFO: Epoch: 0, Step: 432, Loss: 0.7366467064508065
[16-10-2022 14:05:23] INFO: Epoch: 0, Step: 440, Loss: 0.7233565709543737
[16-10-2022 14:05:26] INFO: Epoch: 0, Step: 448, Loss: 0.710500629413543
[16-10-2022 14:05:29] INFO: Epoch: 0, Step: 456, Loss: 0.698076391133662
[16-10-2022 14:05:31] INFO: Epoch: 0, Step: 464, Loss: 0.6860746259885516
[16-10-2022 14:05:34] INFO: Epoch: 0, Step: 472, Loss: 0.6744701102457006
[16-10-2022 14:05:37] INFO: Epoch: 0, Step: 480, Loss: 0.6632449001496449
[16-10-2022 14:05:40] INFO: Epoch: 0, Step: 488, Loss: 0.652382177414602
[16-10-2022 14:05:43] INFO: Epoch: 0, Step: 496, Loss: 0.6418665832978502
[16-10-2022 14:05:46] INFO: Epoch: 0, Step: 504, Loss: 0.6316831074024473
[16-10-2022 14:05:48] INFO: Epoch: 0, Step: 512, Loss: 0.6218168854993849
[16-10-2022 14:05:51] INFO: Epoch: 0, Step: 520, Loss: 0.6122536079465555
[16-10-2022 14:05:54] INFO: Epoch: 0, Step: 528, Loss: 0.6029796793377913
[16-10-2022 14:05:57] INFO: Epoch: 0, Step: 536, Loss: 0.5939822803259753
[16-10-2022 14:06:00] INFO: Epoch: 0, Step: 544, Loss: 0.5852493029542262
[16-10-2022 14:06:02] INFO: Epoch: 0, Step: 552, Loss: 0.5767692357965749
[16-10-2022 14:06:05] INFO: Epoch: 0, Step: 560, Loss: 0.5685312780485869
[16-10-2022 14:06:08] INFO: Epoch: 0, Step: 568, Loss: 0.5605252911873065
[16-10-2022 14:06:11] INFO: Epoch: 0, Step: 576, Loss: 0.5527415735768071
[16-10-2022 14:06:14] INFO: Epoch: 0, Step: 584, Loss: 0.5451710103227314
[16-10-2022 14:06:17] INFO: Epoch: 0, Step: 592, Loss: 0.5378049746331812
[16-10-2022 14:06:19] INFO: Epoch: 0, Step: 600, Loss: 0.5306353034255396
[16-10-2022 14:06:22] INFO: Epoch: 0, Step: 608, Loss: 0.5236542664268822
[16-10-2022 14:06:25] INFO: Epoch: 0, Step: 616, Loss: 0.5168545079506374
[16-10-2022 14:06:28] INFO: Epoch: 0, Step: 624, Loss: 0.5102290616449141
[16-10-2022 14:06:31] INFO: Epoch: 0, Step: 632, Loss: 0.5037713110430536
[16-10-2022 14:06:34] INFO: Epoch: 0, Step: 640, Loss: 0.49747498488002295
[16-10-2022 14:06:37] INFO: Epoch: 0, Step: 648, Loss: 0.49133409172101195
[16-10-2022 14:06:39] INFO: Epoch: 0, Step: 656, Loss: 0.4853429382574177
[16-10-2022 14:06:42] INFO: Epoch: 0, Step: 664, Loss: 0.4794961336776385
[16-10-2022 14:06:45] INFO: Epoch: 0, Step: 672, Loss: 0.4737885174199673
[16-10-2022 14:06:48] INFO: Epoch: 0, Step: 680, Loss: 0.4682151740626871
[16-10-2022 14:06:51] INFO: Epoch: 0, Step: 688, Loss: 0.46277143938868376
[16-10-2022 14:06:54] INFO: Epoch: 0, Step: 696, Loss: 0.4574528243065758
[16-10-2022 14:06:57] INFO: Epoch: 0, Step: 704, Loss: 0.4522550718639671
[16-10-2022 14:06:59] INFO: Epoch: 0, Step: 712, Loss: 0.44717412135056356
[16-10-2022 14:07:02] INFO: Epoch: 0, Step: 720, Loss: 0.44220607332518336
[16-10-2022 14:07:05] INFO: Epoch: 0, Step: 728, Loss: 0.4373472001497708
[16-10-2022 14:07:08] INFO: Epoch: 0, Step: 736, Loss: 0.43259394857795996
[16-10-2022 14:07:11] INFO: Epoch: 0, Step: 744, Loss: 0.4279429024480426
[16-10-2022 14:07:13] INFO: Epoch: 0, Step: 752, Loss: 0.4233907971693333
[16-10-2022 14:07:16] INFO: Epoch: 0, Step: 760, Loss: 0.4189345307839942
[16-10-2022 14:07:19] INFO: Epoch: 0, Step: 768, Loss: 0.41457110141894304
[16-10-2022 14:07:22] INFO: Epoch: 0, Step: 776, Loss: 0.41029762367322486
[16-10-2022 14:07:25] INFO: Epoch: 0, Step: 784, Loss: 0.4061113544179794
[16-10-2022 14:07:28] INFO: Epoch: 0, Step: 792, Loss: 0.40200964873263895
[16-10-2022 14:07:31] INFO: Epoch: 0, Step: 800, Loss: 0.3979899688066826
[16-10-2022 14:07:33] INFO: Epoch: 0, Step: 808, Loss: 0.39404988237183175
[16-10-2022 14:07:36] INFO: Epoch: 0, Step: 816, Loss: 0.3901870548073636
[16-10-2022 14:07:39] INFO: Epoch: 0, Step: 824, Loss: 0.38639922401849724
[16-10-2022 14:07:42] INFO: Epoch: 0, Step: 832, Loss: 0.38268423059496226
[16-10-2022 14:07:45] INFO: Epoch: 0, Step: 840, Loss: 0.37903999773573865
[16-10-2022 14:07:48] INFO: Epoch: 0, Step: 848, Loss: 0.37546452012983933
[16-10-2022 14:07:50] INFO: Epoch: 0, Step: 856, Loss: 0.37195586015440457
[16-10-2022 14:07:53] INFO: Epoch: 0, Step: 864, Loss: 0.3685121776144679
[16-10-2022 14:07:56] INFO: Epoch: 0, Step: 872, Loss: 0.36513168091040815
[16-10-2022 14:07:59] INFO: Epoch: 0, Step: 880, Loss: 0.3618126447431512
[16-10-2022 14:08:02] INFO: Epoch: 0, Step: 888, Loss: 0.3585534054915803
[16-10-2022 14:08:05] INFO: Epoch: 0, Step: 896, Loss: 0.35535235445077057
[16-10-2022 14:08:07] INFO: Epoch: 0, Step: 904, Loss: 0.44100904842059363
[16-10-2022 14:08:10] INFO: Epoch: 0, Step: 912, Loss: 0.5060749337096296
[16-10-2022 14:08:13] INFO: Epoch: 0, Step: 920, Loss: 0.5188723979585397
[16-10-2022 14:08:16] INFO: Epoch: 0, Step: 928, Loss: 0.5168273804599682
[16-10-2022 14:08:19] INFO: Epoch: 0, Step: 936, Loss: 0.5124499035391986
[16-10-2022 14:08:22] INFO: Epoch: 0, Step: 944, Loss: 0.5081197193124284
[16-10-2022 14:08:25] INFO: Epoch: 0, Step: 952, Loss: 0.5038567436435791
[16-10-2022 14:08:27] INFO: Epoch: 0, Step: 960, Loss: 0.49966277939249343
[16-10-2022 14:08:30] INFO: Epoch: 0, Step: 968, Loss: 0.4955369739039435
[16-10-2022 14:08:33] INFO: Epoch: 0, Step: 976, Loss: 0.4914782168119607
[16-10-2022 14:08:36] INFO: Epoch: 0, Step: 984, Loss: 0.4874849599099863
[16-10-2022 14:08:38] INFO: Start eval!
       F1 (micro): 32.76%
/home/jiahaoran2022/anaconda3/envs/chef/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Precision (macro): 10.92%
   Recall (macro): 33.33%
       F1 (macro): 16.45%
[16-10-2022 14:08:58] INFO: Dev total acc: 0.3275686673448627
[16-10-2022 14:08:58] INFO: Saved best epoch 0, best f1 0.16449553001277137
[16-10-2022 14:08:59] INFO: Epoch: 1, Step: 992, Loss: 0.4965553441904354
[16-10-2022 14:09:02] INFO: Epoch: 1, Step: 1000, Loss: 0.5541015762873758
[16-10-2022 14:09:05] INFO: Epoch: 1, Step: 1008, Loss: 0.5781132961616737
[16-10-2022 14:09:08] INFO: Epoch: 1, Step: 1016, Loss: 0.5858580166966064
[16-10-2022 14:09:10] INFO: Epoch: 1, Step: 1024, Loss: 0.588569142757553
[16-10-2022 14:09:13] INFO: Epoch: 1, Step: 1032, Loss: 0.5924929295696134
[16-10-2022 14:09:16] INFO: Epoch: 1, Step: 1040, Loss: 0.597504535163468
[16-10-2022 14:09:19] INFO: Epoch: 1, Step: 1048, Loss: 0.6014967595640133
[16-10-2022 14:09:22] INFO: Epoch: 1, Step: 1056, Loss: 0.6045787666508748
[16-10-2022 14:09:25] INFO: Epoch: 1, Step: 1064, Loss: 0.6074566794805163
[16-10-2022 14:09:28] INFO: Epoch: 1, Step: 1072, Loss: 0.6108047639319357
[16-10-2022 14:09:30] INFO: Epoch: 1, Step: 1080, Loss: 0.6128087300566492
[16-10-2022 14:09:33] INFO: Epoch: 1, Step: 1088, Loss: 0.6149111247300325
[16-10-2022 14:09:36] INFO: Epoch: 1, Step: 1096, Loss: 0.6166008351554935
[16-10-2022 14:09:39] INFO: Epoch: 1, Step: 1104, Loss: 0.6194020158956114
[16-10-2022 14:09:42] INFO: Epoch: 1, Step: 1112, Loss: 0.622854843752514
[16-10-2022 14:09:45] INFO: Epoch: 1, Step: 1120, Loss: 0.6251746084708072
[16-10-2022 14:09:47] INFO: Epoch: 1, Step: 1128, Loss: 0.62674069453817
[16-10-2022 14:09:50] INFO: Epoch: 1, Step: 1136, Loss: 0.6298720964303415
[16-10-2022 14:09:53] INFO: Epoch: 1, Step: 1144, Loss: 0.6322709379451353
[16-10-2022 14:09:56] INFO: Epoch: 1, Step: 1152, Loss: 0.6338603536553775
[16-10-2022 14:09:59] INFO: Epoch: 1, Step: 1160, Loss: 0.6354431580014158
[16-10-2022 14:10:02] INFO: Epoch: 1, Step: 1168, Loss: 0.6377118674509422
[16-10-2022 14:10:04] INFO: Epoch: 1, Step: 1176, Loss: 0.6398439400918722
[16-10-2022 14:10:07] INFO: Epoch: 1, Step: 1184, Loss: 0.6424803094139867
[16-10-2022 14:10:10] INFO: Epoch: 1, Step: 1192, Loss: 0.6448625489826261
[16-10-2022 14:10:13] INFO: Epoch: 1, Step: 1200, Loss: 0.6462722974178087
[16-10-2022 14:10:16] INFO: Epoch: 1, Step: 1208, Loss: 0.6481976894113491
[16-10-2022 14:10:19] INFO: Epoch: 1, Step: 1216, Loss: 0.6501030273105058
[16-10-2022 14:10:22] INFO: Epoch: 1, Step: 1224, Loss: 0.6523216560246207
[16-10-2022 14:10:24] INFO: Epoch: 1, Step: 1232, Loss: 0.6545029987624027
[16-10-2022 14:10:27] INFO: Epoch: 1, Step: 1240, Loss: 0.6561208527565859
[16-10-2022 14:10:30] INFO: Epoch: 1, Step: 1248, Loss: 0.6578496047564892
[16-10-2022 14:10:33] INFO: Epoch: 1, Step: 1256, Loss: 0.659505333695147
[16-10-2022 14:10:36] INFO: Epoch: 1, Step: 1264, Loss: 0.6612814546628175
[16-10-2022 14:10:39] INFO: Epoch: 1, Step: 1272, Loss: 0.6629814618185716
[16-10-2022 14:10:42] INFO: Epoch: 1, Step: 1280, Loss: 0.664416356119969
[16-10-2022 14:10:44] INFO: Epoch: 1, Step: 1288, Loss: 0.6659229707974168
[16-10-2022 14:10:47] INFO: Epoch: 1, Step: 1296, Loss: 0.667456400859585
[16-10-2022 14:10:50] INFO: Epoch: 1, Step: 1304, Loss: 0.6698712404572242
[16-10-2022 14:10:53] INFO: Epoch: 1, Step: 1312, Loss: 0.6712266787484007
[16-10-2022 14:10:56] INFO: Epoch: 1, Step: 1320, Loss: 0.6728734468110484
[16-10-2022 14:10:59] INFO: Epoch: 1, Step: 1328, Loss: 0.6743257699832222
[16-10-2022 14:11:01] INFO: Epoch: 1, Step: 1336, Loss: 0.6762367920298143
[16-10-2022 14:11:04] INFO: Epoch: 1, Step: 1344, Loss: 0.6780588203027216
[16-10-2022 14:11:07] INFO: Epoch: 1, Step: 1352, Loss: 0.6797724361917756
[16-10-2022 14:11:10] INFO: Epoch: 1, Step: 1360, Loss: 0.6812244273421423
[16-10-2022 14:11:13] INFO: Epoch: 1, Step: 1368, Loss: 0.6827648848606211
[16-10-2022 14:11:16] INFO: Epoch: 1, Step: 1376, Loss: 0.6848070878064988
[16-10-2022 14:11:18] INFO: Epoch: 1, Step: 1384, Loss: 0.6864468280167327
[16-10-2022 14:11:21] INFO: Epoch: 1, Step: 1392, Loss: 0.6875313809597022
[16-10-2022 14:11:24] INFO: Epoch: 1, Step: 1400, Loss: 0.6885583225451956
[16-10-2022 14:11:27] INFO: Epoch: 1, Step: 1408, Loss: 0.6897129471631289
[16-10-2022 14:11:30] INFO: Epoch: 1, Step: 1416, Loss: 0.6912796931041912
[16-10-2022 14:11:33] INFO: Epoch: 1, Step: 1424, Loss: 0.6923484897393265
[16-10-2022 14:11:35] INFO: Epoch: 1, Step: 1432, Loss: 0.693309037267237
[16-10-2022 14:11:38] INFO: Epoch: 1, Step: 1440, Loss: 0.6943491528561455
[16-10-2022 14:11:41] INFO: Epoch: 1, Step: 1448, Loss: 0.6955135073744865
[16-10-2022 14:11:44] INFO: Epoch: 1, Step: 1456, Loss: 0.6963898461072074
[16-10-2022 14:11:47] INFO: Epoch: 1, Step: 1464, Loss: 0.6978399979658539
[16-10-2022 14:11:50] INFO: Epoch: 1, Step: 1472, Loss: 0.6992658371151863
[16-10-2022 14:11:52] INFO: Epoch: 1, Step: 1480, Loss: 0.7007145721491036
[16-10-2022 14:11:55] INFO: Epoch: 1, Step: 1488, Loss: 0.7020684696699415
[16-10-2022 14:11:58] INFO: Epoch: 1, Step: 1496, Loss: 0.7027321171917452
[16-10-2022 14:12:01] INFO: Epoch: 1, Step: 1504, Loss: 0.7043464491862638
[16-10-2022 14:12:04] INFO: Epoch: 1, Step: 1512, Loss: 0.705624079078033
[16-10-2022 14:12:07] INFO: Epoch: 1, Step: 1520, Loss: 0.7074524719979333
[16-10-2022 14:12:09] INFO: Epoch: 1, Step: 1528, Loss: 0.7081988219157634
[16-10-2022 14:12:12] INFO: Epoch: 1, Step: 1536, Loss: 0.7092457627611305
[16-10-2022 14:12:15] INFO: Epoch: 1, Step: 1544, Loss: 0.710935412035156
[16-10-2022 14:12:18] INFO: Epoch: 1, Step: 1552, Loss: 0.7124180864932066
[16-10-2022 14:12:21] INFO: Epoch: 1, Step: 1560, Loss: 0.7135048757116681
[16-10-2022 14:12:24] INFO: Epoch: 1, Step: 1568, Loss: 0.7144983077198944
[16-10-2022 14:12:27] INFO: Epoch: 1, Step: 1576, Loss: 0.7155601143350525
[16-10-2022 14:12:29] INFO: Epoch: 1, Step: 1584, Loss: 0.716302807445244
[16-10-2022 14:12:32] INFO: Epoch: 1, Step: 1592, Loss: 0.7177115617502942
[16-10-2022 14:12:35] INFO: Epoch: 1, Step: 1600, Loss: 0.7189153771591851
[16-10-2022 14:12:38] INFO: Epoch: 1, Step: 1608, Loss: 0.7199570894431779
[16-10-2022 14:12:41] INFO: Epoch: 1, Step: 1616, Loss: 0.7213426623424748
[16-10-2022 14:12:44] INFO: Epoch: 1, Step: 1624, Loss: 0.7224025748087921
[16-10-2022 14:12:46] INFO: Epoch: 1, Step: 1632, Loss: 0.7235653555390948
[16-10-2022 14:12:49] INFO: Epoch: 1, Step: 1640, Loss: 0.7242385070612438
[16-10-2022 14:12:52] INFO: Epoch: 1, Step: 1648, Loss: 0.7249558874817793
[16-10-2022 14:12:55] INFO: Epoch: 1, Step: 1656, Loss: 0.7260982643044003
[16-10-2022 14:12:58] INFO: Epoch: 1, Step: 1664, Loss: 0.7272779774033171
[16-10-2022 14:13:00] INFO: Epoch: 1, Step: 1672, Loss: 0.7280679618311906
[16-10-2022 14:13:03] INFO: Epoch: 1, Step: 1680, Loss: 0.7294590484284852
[16-10-2022 14:13:06] INFO: Epoch: 1, Step: 1688, Loss: 0.7305013564000826
[16-10-2022 14:13:09] INFO: Epoch: 1, Step: 1696, Loss: 0.7315143001780259
[16-10-2022 14:13:12] INFO: Epoch: 1, Step: 1704, Loss: 0.7326760186875434
[16-10-2022 14:13:15] INFO: Epoch: 1, Step: 1712, Loss: 0.7335419557123047
[16-10-2022 14:13:17] INFO: Epoch: 1, Step: 1720, Loss: 0.7344810687980604
[16-10-2022 14:13:20] INFO: Epoch: 1, Step: 1728, Loss: 0.7351291887225438
[16-10-2022 14:13:23] INFO: Epoch: 1, Step: 1736, Loss: 0.7359823167843815
[16-10-2022 14:13:26] INFO: Epoch: 1, Step: 1744, Loss: 0.7373874699547812
[16-10-2022 14:13:29] INFO: Epoch: 1, Step: 1752, Loss: 0.7382044963407252
[16-10-2022 14:13:32] INFO: Epoch: 1, Step: 1760, Loss: 0.7384886462347677
[16-10-2022 14:13:34] INFO: Epoch: 1, Step: 1768, Loss: 0.739201198987352
[16-10-2022 14:13:37] INFO: Epoch: 1, Step: 1776, Loss: 0.7393451885903802
[16-10-2022 14:13:40] INFO: Epoch: 1, Step: 1784, Loss: 0.7400389693013817
[16-10-2022 14:13:43] INFO: Epoch: 1, Step: 1792, Loss: 0.7408918329352839
[16-10-2022 14:13:46] INFO: Epoch: 1, Step: 1800, Loss: 0.7420838819382516
[16-10-2022 14:13:49] INFO: Epoch: 1, Step: 1808, Loss: 0.743027518093381
[16-10-2022 14:13:51] INFO: Epoch: 1, Step: 1816, Loss: 0.7441779317084448
[16-10-2022 14:13:54] INFO: Epoch: 1, Step: 1824, Loss: 0.7449794216020648
[16-10-2022 14:13:57] INFO: Epoch: 1, Step: 1832, Loss: 0.7455859790174261
[16-10-2022 14:14:00] INFO: Epoch: 1, Step: 1840, Loss: 0.7465289093331727
[16-10-2022 14:14:03] INFO: Epoch: 1, Step: 1848, Loss: 0.7473982729409223
[16-10-2022 14:14:06] INFO: Epoch: 1, Step: 1856, Loss: 0.7480371860117292
[16-10-2022 14:14:09] INFO: Epoch: 1, Step: 1864, Loss: 0.748826677045654
[16-10-2022 14:14:11] INFO: Epoch: 1, Step: 1872, Loss: 0.7500793700262071
[16-10-2022 14:14:14] INFO: Epoch: 1, Step: 1880, Loss: 0.7505135305800902
[16-10-2022 14:14:17] INFO: Epoch: 1, Step: 1888, Loss: 0.7518874170136711
[16-10-2022 14:14:20] INFO: Epoch: 1, Step: 1896, Loss: 0.7522768334658897
[16-10-2022 14:14:23] INFO: Epoch: 1, Step: 1904, Loss: 0.753368916359825
[16-10-2022 14:14:26] INFO: Epoch: 1, Step: 1912, Loss: 0.7541776201688153
[16-10-2022 14:14:28] INFO: Epoch: 1, Step: 1920, Loss: 0.7551840550984499
[16-10-2022 14:14:31] INFO: Epoch: 1, Step: 1928, Loss: 0.756020658717171
[16-10-2022 14:14:34] INFO: Epoch: 1, Step: 1936, Loss: 0.7563630422319811
[16-10-2022 14:14:37] INFO: Epoch: 1, Step: 1944, Loss: 0.7571670879158029
[16-10-2022 14:14:40] INFO: Epoch: 1, Step: 1952, Loss: 0.7580591481519094
[16-10-2022 14:14:43] INFO: Epoch: 1, Step: 1960, Loss: 0.7589706203254444
[16-10-2022 14:14:46] INFO: Epoch: 1, Step: 1968, Loss: 0.7597557720709678
[16-10-2022 14:14:49] INFO: Epoch: 1, Step: 1976, Loss: 0.760545896111766
[16-10-2022 14:14:50] INFO: Start eval!
       F1 (micro): 33.67%
/home/jiahaoran2022/anaconda3/envs/chef/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Precision (macro): 11.22%
   Recall (macro): 33.33%
       F1 (macro): 16.79%
[16-10-2022 14:15:10] INFO: Dev total acc: 0.33672431332655134
[16-10-2022 14:15:11] INFO: Saved best epoch 1, best f1 0.16793505834601727
[16-10-2022 14:15:12] INFO: Epoch: 2, Step: 1984, Loss: 0.7615387517031698
[16-10-2022 14:15:15] INFO: Epoch: 2, Step: 1992, Loss: 0.7621444202305377
[16-10-2022 14:15:18] INFO: Epoch: 2, Step: 2000, Loss: 0.762893302479797
[16-10-2022 14:15:21] INFO: Epoch: 2, Step: 2008, Loss: 0.763224510655988
[16-10-2022 14:15:23] INFO: Epoch: 2, Step: 2016, Loss: 0.763792415912715
[16-10-2022 14:15:26] INFO: Epoch: 2, Step: 2024, Loss: 0.7647405556631707
[16-10-2022 14:15:29] INFO: Epoch: 2, Step: 2032, Loss: 0.7654545191386137
[16-10-2022 14:15:32] INFO: Epoch: 2, Step: 2040, Loss: 0.7661204758027541
[16-10-2022 14:15:35] INFO: Epoch: 2, Step: 2048, Loss: 0.7666062836160936
[16-10-2022 14:15:38] INFO: Epoch: 2, Step: 2056, Loss: 0.76767536514562
[16-10-2022 14:15:41] INFO: Epoch: 2, Step: 2064, Loss: 0.7683129475015593
[16-10-2022 14:15:43] INFO: Epoch: 2, Step: 2072, Loss: 0.7689935984503861
[16-10-2022 14:15:46] INFO: Epoch: 2, Step: 2080, Loss: 0.7700132596181499
[16-10-2022 14:15:49] INFO: Epoch: 2, Step: 2088, Loss: 0.7703037752477654
[16-10-2022 14:15:52] INFO: Epoch: 2, Step: 2096, Loss: 0.7713885253085941
[16-10-2022 14:15:55] INFO: Epoch: 2, Step: 2104, Loss: 0.7719673290937624
[16-10-2022 14:15:58] INFO: Epoch: 2, Step: 2112, Loss: 0.772666732761269
[16-10-2022 14:16:01] INFO: Epoch: 2, Step: 2120, Loss: 0.7731526571150596
[16-10-2022 14:16:03] INFO: Epoch: 2, Step: 2128, Loss: 0.7736393227364835
[16-10-2022 14:16:06] INFO: Epoch: 2, Step: 2136, Loss: 0.774358230425004
[16-10-2022 14:16:09] INFO: Epoch: 2, Step: 2144, Loss: 0.7747065220115396
[16-10-2022 14:16:12] INFO: Epoch: 2, Step: 2152, Loss: 0.775206103043313
[16-10-2022 14:16:15] INFO: Epoch: 2, Step: 2160, Loss: 0.7758987721832202
[16-10-2022 14:16:18] INFO: Epoch: 2, Step: 2168, Loss: 0.776463633927301
[16-10-2022 14:16:21] INFO: Epoch: 2, Step: 2176, Loss: 0.7768052431621584
[16-10-2022 14:16:23] INFO: Epoch: 2, Step: 2184, Loss: 0.7773783292174825
[16-10-2022 14:16:26] INFO: Epoch: 2, Step: 2192, Loss: 0.7784842282999656
[16-10-2022 14:16:29] INFO: Epoch: 2, Step: 2200, Loss: 0.7787636667033158
[16-10-2022 14:16:32] INFO: Epoch: 2, Step: 2208, Loss: 0.7792005077952973
[16-10-2022 14:16:35] INFO: Epoch: 2, Step: 2216, Loss: 0.7794225055149795
[16-10-2022 14:16:38] INFO: Epoch: 2, Step: 2224, Loss: 0.7798717041054696
[16-10-2022 14:16:40] INFO: Epoch: 2, Step: 2232, Loss: 0.7803571036563173
[16-10-2022 14:16:43] INFO: Epoch: 2, Step: 2240, Loss: 0.7808784312519054
[16-10-2022 14:16:46] INFO: Epoch: 2, Step: 2248, Loss: 0.7817516947957592
[16-10-2022 14:16:49] INFO: Epoch: 2, Step: 2256, Loss: 0.782195883659442
[16-10-2022 14:16:52] INFO: Epoch: 2, Step: 2264, Loss: 0.7823344416498764
[16-10-2022 14:16:55] INFO: Epoch: 2, Step: 2272, Loss: 0.7825160002759273
[16-10-2022 14:16:58] INFO: Epoch: 2, Step: 2280, Loss: 0.7833271307201182
[16-10-2022 14:17:00] INFO: Epoch: 2, Step: 2288, Loss: 0.7840302433717965
[16-10-2022 14:17:03] INFO: Epoch: 2, Step: 2296, Loss: 0.7844597043661338
[16-10-2022 14:17:06] INFO: Epoch: 2, Step: 2304, Loss: 0.7850648776916214
[16-10-2022 14:17:09] INFO: Epoch: 2, Step: 2312, Loss: 0.7855387543341327
[16-10-2022 14:17:12] INFO: Epoch: 2, Step: 2320, Loss: 0.7860156174444377
[16-10-2022 14:17:15] INFO: Epoch: 2, Step: 2328, Loss: 0.7865667043660561
[16-10-2022 14:17:18] INFO: Epoch: 2, Step: 2336, Loss: 0.7870519427433044
[16-10-2022 14:17:21] INFO: Epoch: 2, Step: 2344, Loss: 0.78765876182603
[16-10-2022 14:17:23] INFO: Epoch: 2, Step: 2352, Loss: 0.7879699754044358
[16-10-2022 14:17:26] INFO: Epoch: 2, Step: 2360, Loss: 0.7886436623616183
[16-10-2022 14:17:29] INFO: Epoch: 2, Step: 2368, Loss: 0.7890967965406386
[16-10-2022 14:17:32] INFO: Epoch: 2, Step: 2376, Loss: 0.7894698226972106
[16-10-2022 14:17:35] INFO: Epoch: 2, Step: 2384, Loss: 0.7896514052991145
[16-10-2022 14:17:38] INFO: Epoch: 2, Step: 2392, Loss: 0.7901474200391895
[16-10-2022 14:17:40] INFO: Epoch: 2, Step: 2400, Loss: 0.7905300223656938
[16-10-2022 14:17:43] INFO: Epoch: 2, Step: 2408, Loss: 0.7908853603437538
[16-10-2022 14:17:46] INFO: Epoch: 2, Step: 2416, Loss: 0.7917423954199921
[16-10-2022 14:17:49] INFO: Epoch: 2, Step: 2424, Loss: 0.7922589188340519
[16-10-2022 14:17:52] INFO: Epoch: 2, Step: 2432, Loss: 0.7928919239830858
[16-10-2022 14:17:55] INFO: Epoch: 2, Step: 2440, Loss: 0.7934897849138101
[16-10-2022 14:17:58] INFO: Epoch: 2, Step: 2448, Loss: 0.7940292748047679
[16-10-2022 14:18:00] INFO: Epoch: 2, Step: 2456, Loss: 0.7949133301138922
[16-10-2022 14:18:03] INFO: Epoch: 2, Step: 2464, Loss: 0.7951643121347456
[16-10-2022 14:18:06] INFO: Epoch: 2, Step: 2472, Loss: 0.7955318452884123
[16-10-2022 14:18:09] INFO: Epoch: 2, Step: 2480, Loss: 0.795931142624198
[16-10-2022 14:18:12] INFO: Epoch: 2, Step: 2488, Loss: 0.7962849787316949
[16-10-2022 14:18:15] INFO: Epoch: 2, Step: 2496, Loss: 0.7965386847156788
[16-10-2022 14:18:18] INFO: Epoch: 2, Step: 2504, Loss: 0.7968568394195963
[16-10-2022 14:18:20] INFO: Epoch: 2, Step: 2512, Loss: 0.7970951810126515
[16-10-2022 14:18:23] INFO: Epoch: 2, Step: 2520, Loss: 0.797620287970744
[16-10-2022 14:18:26] INFO: Epoch: 2, Step: 2528, Loss: 0.7981711678469525
[16-10-2022 14:18:29] INFO: Epoch: 2, Step: 2536, Loss: 0.798475840662222
[16-10-2022 14:18:32] INFO: Epoch: 2, Step: 2544, Loss: 0.7986634522515691
[16-10-2022 14:18:35] INFO: Epoch: 2, Step: 2552, Loss: 0.7989339657598197
[16-10-2022 14:18:38] INFO: Epoch: 2, Step: 2560, Loss: 0.7993743473271323
[16-10-2022 14:18:40] INFO: Epoch: 2, Step: 2568, Loss: 0.8000683252108102
[16-10-2022 14:18:43] INFO: Epoch: 2, Step: 2576, Loss: 0.8004450581300004
[16-10-2022 14:18:46] INFO: Epoch: 2, Step: 2584, Loss: 0.801271700806334
[16-10-2022 14:18:49] INFO: Epoch: 2, Step: 2592, Loss: 0.8015563212361274
[16-10-2022 14:18:52] INFO: Epoch: 2, Step: 2600, Loss: 0.8018325220005738
[16-10-2022 14:18:55] INFO: Epoch: 2, Step: 2608, Loss: 0.8022360775714313
[16-10-2022 14:18:58] INFO: Epoch: 2, Step: 2616, Loss: 0.8024597582265184
[16-10-2022 14:19:00] INFO: Epoch: 2, Step: 2624, Loss: 0.802905833310329
[16-10-2022 14:19:03] INFO: Epoch: 2, Step: 2632, Loss: 0.8031259393418855
[16-10-2022 14:19:06] INFO: Epoch: 2, Step: 2640, Loss: 0.8040765114199434
[16-10-2022 14:19:09] INFO: Epoch: 2, Step: 2648, Loss: 0.8043795743538215
[16-10-2022 14:19:12] INFO: Epoch: 2, Step: 2656, Loss: 0.8049480615545868
[16-10-2022 14:19:14] INFO: Epoch: 2, Step: 2664, Loss: 0.8052036477709
[16-10-2022 14:19:17] INFO: Epoch: 2, Step: 2672, Loss: 0.805637306936705
[16-10-2022 14:19:20] INFO: Epoch: 2, Step: 2680, Loss: 0.8058321985583203
[16-10-2022 14:19:23] INFO: Epoch: 2, Step: 2688, Loss: 0.8060550157360773
[16-10-2022 14:19:26] INFO: Epoch: 2, Step: 2696, Loss: 0.8064989122225238
[16-10-2022 14:19:29] INFO: Epoch: 2, Step: 2704, Loss: 0.8066538826978811
[16-10-2022 14:19:32] INFO: Epoch: 2, Step: 2712, Loss: 0.8071986294055096
[16-10-2022 14:19:34] INFO: Epoch: 2, Step: 2720, Loss: 0.8078189089305651
[16-10-2022 14:19:37] INFO: Epoch: 2, Step: 2728, Loss: 0.8080282723954736
[16-10-2022 14:19:40] INFO: Epoch: 2, Step: 2736, Loss: 0.8085087472913598
[16-10-2022 14:19:43] INFO: Epoch: 2, Step: 2744, Loss: 0.8086531530732008
[16-10-2022 14:19:46] INFO: Epoch: 2, Step: 2752, Loss: 0.8089748029556771
[16-10-2022 14:19:49] INFO: Epoch: 2, Step: 2760, Loss: 0.8092506681299249
[16-10-2022 14:19:52] INFO: Epoch: 2, Step: 2768, Loss: 0.8098727431366594
[16-10-2022 14:19:54] INFO: Epoch: 2, Step: 2776, Loss: 0.8100473023696356
[16-10-2022 14:19:57] INFO: Epoch: 2, Step: 2784, Loss: 0.8102967369854832
[16-10-2022 14:20:00] INFO: Epoch: 2, Step: 2792, Loss: 0.8104743235371213
[16-10-2022 14:20:03] INFO: Epoch: 2, Step: 2800, Loss: 0.8107908406494724
[16-10-2022 14:20:06] INFO: Epoch: 2, Step: 2808, Loss: 0.8111578989044592
[16-10-2022 14:20:09] INFO: Epoch: 2, Step: 2816, Loss: 0.8117473040011834
[16-10-2022 14:20:12] INFO: Epoch: 2, Step: 2824, Loss: 0.8119606216406725
[16-10-2022 14:20:15] INFO: Epoch: 2, Step: 2832, Loss: 0.8123319841103404
[16-10-2022 14:20:17] INFO: Epoch: 2, Step: 2840, Loss: 0.8122736702568468
[16-10-2022 14:20:20] INFO: Epoch: 2, Step: 2848, Loss: 0.812821255396461
[16-10-2022 14:20:23] INFO: Epoch: 2, Step: 2856, Loss: 0.8132248060107603
[16-10-2022 14:20:26] INFO: Epoch: 2, Step: 2864, Loss: 0.8133062600488807
[16-10-2022 14:20:29] INFO: Epoch: 2, Step: 2872, Loss: 0.8136956142871531
[16-10-2022 14:20:32] INFO: Epoch: 2, Step: 2880, Loss: 0.8139751613205046
[16-10-2022 14:20:34] INFO: Epoch: 2, Step: 2888, Loss: 0.8141913967390507
[16-10-2022 14:20:37] INFO: Epoch: 2, Step: 2896, Loss: 0.8146465687938196
[16-10-2022 14:20:40] INFO: Epoch: 2, Step: 2904, Loss: 0.8152091316224824
[16-10-2022 14:20:43] INFO: Epoch: 2, Step: 2912, Loss: 0.8155481585334983
[16-10-2022 14:20:46] INFO: Epoch: 2, Step: 2920, Loss: 0.8157103275663596
[16-10-2022 14:20:49] INFO: Epoch: 2, Step: 2928, Loss: 0.8158879135417519
[16-10-2022 14:20:52] INFO: Epoch: 2, Step: 2936, Loss: 0.8160759160303002
[16-10-2022 14:20:54] INFO: Epoch: 2, Step: 2944, Loss: 0.8163522093863304
[16-10-2022 14:20:57] INFO: Epoch: 2, Step: 2952, Loss: 0.8168034677767532
[16-10-2022 14:21:00] INFO: Epoch: 2, Step: 2960, Loss: 0.8173281850910223
[16-10-2022 14:21:03] INFO: Epoch: 2, Step: 2968, Loss: 0.8174741818881136
[16-10-2022 14:21:04] INFO: Start eval!
       F1 (micro): 33.57%
/home/jiahaoran2022/anaconda3/envs/chef/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Precision (macro): 11.19%
   Recall (macro): 33.33%
       F1 (macro): 16.76%
[16-10-2022 14:21:24] INFO: Dev total acc: 0.33570701932858593
[16-10-2022 14:21:26] INFO: Epoch: 3, Step: 2976, Loss: 0.8177148715245184
[16-10-2022 14:21:28] INFO: Epoch: 3, Step: 2984, Loss: 0.8180895100033352
[16-10-2022 14:21:31] INFO: Epoch: 3, Step: 2992, Loss: 0.8183041258234747
[16-10-2022 14:21:34] INFO: Epoch: 3, Step: 3000, Loss: 0.8186943449241675
[16-10-2022 14:21:37] INFO: Epoch: 3, Step: 3008, Loss: 0.8189270468490908
[16-10-2022 14:21:40] INFO: Epoch: 3, Step: 3016, Loss: 0.8192625667378857
[16-10-2022 14:21:43] INFO: Epoch: 3, Step: 3024, Loss: 0.819500659081233
[16-10-2022 14:21:46] INFO: Epoch: 3, Step: 3032, Loss: 0.8199166261841916
[16-10-2022 14:21:48] INFO: Epoch: 3, Step: 3040, Loss: 0.8201220376576598
[16-10-2022 14:21:51] INFO: Epoch: 3, Step: 3048, Loss: 0.8205805273880832
[16-10-2022 14:21:54] INFO: Epoch: 3, Step: 3056, Loss: 0.8209499794836479
[16-10-2022 14:21:57] INFO: Epoch: 3, Step: 3064, Loss: 0.8212488261611005
[16-10-2022 14:22:00] INFO: Epoch: 3, Step: 3072, Loss: 0.8214908946017149
[16-10-2022 14:22:03] INFO: Epoch: 3, Step: 3080, Loss: 0.8217629204770532
[16-10-2022 14:22:06] INFO: Epoch: 3, Step: 3088, Loss: 0.8219258712153704
[16-10-2022 14:22:09] INFO: Epoch: 3, Step: 3096, Loss: 0.8221340455964589
[16-10-2022 14:22:11] INFO: Epoch: 3, Step: 3104, Loss: 0.8227015877990106
[16-10-2022 14:22:14] INFO: Epoch: 3, Step: 3112, Loss: 0.822890120834989
[16-10-2022 14:22:17] INFO: Epoch: 3, Step: 3120, Loss: 0.8235073683795597
[16-10-2022 14:22:20] INFO: Epoch: 3, Step: 3128, Loss: 0.8238915780719014
[16-10-2022 14:22:23] INFO: Epoch: 3, Step: 3136, Loss: 0.8238817361452176
[16-10-2022 14:22:26] INFO: Epoch: 3, Step: 3144, Loss: 0.8241578566003123
[16-10-2022 14:22:29] INFO: Epoch: 3, Step: 3152, Loss: 0.8242389695012362
[16-10-2022 14:22:31] INFO: Epoch: 3, Step: 3160, Loss: 0.8245724246908174
[16-10-2022 14:22:34] INFO: Epoch: 3, Step: 3168, Loss: 0.8250107678521497
[16-10-2022 14:22:37] INFO: Epoch: 3, Step: 3176, Loss: 0.8253481901809344
[16-10-2022 14:22:40] INFO: Epoch: 3, Step: 3184, Loss: 0.8255497618594995
[16-10-2022 14:22:43] INFO: Epoch: 3, Step: 3192, Loss: 0.8256665698887744
[16-10-2022 14:22:46] INFO: Epoch: 3, Step: 3200, Loss: 0.8258770158014034
[16-10-2022 14:22:48] INFO: Epoch: 3, Step: 3208, Loss: 0.8259821442429892
[16-10-2022 14:22:51] INFO: Epoch: 3, Step: 3216, Loss: 0.8262276825048175
[16-10-2022 14:22:54] INFO: Epoch: 3, Step: 3224, Loss: 0.8264368864818813
[16-10-2022 14:22:57] INFO: Epoch: 3, Step: 3232, Loss: 0.8268180021539216
[16-10-2022 14:23:00] INFO: Epoch: 3, Step: 3240, Loss: 0.8270460735742284
[16-10-2022 14:23:03] INFO: Epoch: 3, Step: 3248, Loss: 0.8270419111964183
[16-10-2022 14:23:06] INFO: Epoch: 3, Step: 3256, Loss: 0.8272693255557215
[16-10-2022 14:23:08] INFO: Epoch: 3, Step: 3264, Loss: 0.8277584007980225
[16-10-2022 14:23:11] INFO: Epoch: 3, Step: 3272, Loss: 0.828453367895955
[16-10-2022 14:23:14] INFO: Epoch: 3, Step: 3280, Loss: 0.8288413052572307
[16-10-2022 14:23:17] INFO: Epoch: 3, Step: 3288, Loss: 0.8291284342482466
[16-10-2022 14:23:20] INFO: Epoch: 3, Step: 3296, Loss: 0.8293984074889489
[16-10-2022 14:23:23] INFO: Epoch: 3, Step: 3304, Loss: 0.8296049106336423
[16-10-2022 14:23:26] INFO: Epoch: 3, Step: 3312, Loss: 0.8296799892301178
[16-10-2022 14:23:28] INFO: Epoch: 3, Step: 3320, Loss: 0.8300378643840512
[16-10-2022 14:23:31] INFO: Epoch: 3, Step: 3328, Loss: 0.8302004093073914
[16-10-2022 14:23:34] INFO: Epoch: 3, Step: 3336, Loss: 0.8305107794704516
[16-10-2022 14:23:37] INFO: Epoch: 3, Step: 3344, Loss: 0.8306536272259738
[16-10-2022 14:23:40] INFO: Epoch: 3, Step: 3352, Loss: 0.8310744129977281
[16-10-2022 14:23:43] INFO: Epoch: 3, Step: 3360, Loss: 0.8315815222460915
[16-10-2022 14:23:46] INFO: Epoch: 3, Step: 3368, Loss: 0.8318473183364345
[16-10-2022 14:23:48] INFO: Epoch: 3, Step: 3376, Loss: 0.8322958950344169
[16-10-2022 14:23:51] INFO: Epoch: 3, Step: 3384, Loss: 0.8325644177803225
[16-10-2022 14:23:54] INFO: Epoch: 3, Step: 3392, Loss: 0.8328100089038912
[16-10-2022 14:23:57] INFO: Epoch: 3, Step: 3400, Loss: 0.8328130355006418
[16-10-2022 14:24:00] INFO: Epoch: 3, Step: 3408, Loss: 0.8333443621044739
[16-10-2022 14:24:03] INFO: Epoch: 3, Step: 3416, Loss: 0.8338975296246953
[16-10-2022 14:24:05] INFO: Epoch: 3, Step: 3424, Loss: 0.8344602396365949
[16-10-2022 14:24:08] INFO: Epoch: 3, Step: 3432, Loss: 0.8345937179086956
[16-10-2022 14:24:11] INFO: Epoch: 3, Step: 3440, Loss: 0.8351073186639052
[16-10-2022 14:24:14] INFO: Epoch: 3, Step: 3448, Loss: 0.8352036240052766
[16-10-2022 14:24:17] INFO: Epoch: 3, Step: 3456, Loss: 0.8355550357643132
[16-10-2022 14:24:20] INFO: Epoch: 3, Step: 3464, Loss: 0.8356578985227204
[16-10-2022 14:24:23] INFO: Epoch: 3, Step: 3472, Loss: 0.8358583706849763
[16-10-2022 14:24:25] INFO: Epoch: 3, Step: 3480, Loss: 0.8358816527312134
[16-10-2022 14:24:28] INFO: Epoch: 3, Step: 3488, Loss: 0.8362451425610636
[16-10-2022 14:24:31] INFO: Epoch: 3, Step: 3496, Loss: 0.8363519431202885
[16-10-2022 14:24:34] INFO: Epoch: 3, Step: 3504, Loss: 0.836525624257547
[16-10-2022 14:24:37] INFO: Epoch: 3, Step: 3512, Loss: 0.8368024249913512
[16-10-2022 14:24:40] INFO: Epoch: 3, Step: 3520, Loss: 0.837029236204817
[16-10-2022 14:24:43] INFO: Epoch: 3, Step: 3528, Loss: 0.8373272035518231
[16-10-2022 14:24:45] INFO: Epoch: 3, Step: 3536, Loss: 0.8375259451115323
[16-10-2022 14:24:48] INFO: Epoch: 3, Step: 3544, Loss: 0.8375622735623881
[16-10-2022 14:24:51] INFO: Epoch: 3, Step: 3552, Loss: 0.8377124761023799
[16-10-2022 14:24:54] INFO: Epoch: 3, Step: 3560, Loss: 0.8376582112425127
[16-10-2022 14:24:57] INFO: Epoch: 3, Step: 3568, Loss: 0.8383665015062974
[16-10-2022 14:25:00] INFO: Epoch: 3, Step: 3576, Loss: 0.8384771019072638
[16-10-2022 14:25:03] INFO: Epoch: 3, Step: 3584, Loss: 0.8390034988874068
[16-10-2022 14:25:05] INFO: Epoch: 3, Step: 3592, Loss: 0.8390291093305414
[16-10-2022 14:25:08] INFO: Epoch: 3, Step: 3600, Loss: 0.8392093124540941
[16-10-2022 14:25:11] INFO: Epoch: 3, Step: 3608, Loss: 0.8393287838482305
[16-10-2022 14:25:14] INFO: Epoch: 3, Step: 3616, Loss: 0.8394570732953041
[16-10-2022 14:25:17] INFO: Epoch: 3, Step: 3624, Loss: 0.8395103770328967
[16-10-2022 14:25:19] INFO: Epoch: 3, Step: 3632, Loss: 0.8395178268678155
[16-10-2022 14:25:22] INFO: Epoch: 3, Step: 3640, Loss: 0.8395837229410662
[16-10-2022 14:25:25] INFO: Epoch: 3, Step: 3648, Loss: 0.8396377827565951
[16-10-2022 14:25:28] INFO: Epoch: 3, Step: 3656, Loss: 0.8400891792707974
[16-10-2022 14:25:31] INFO: Epoch: 3, Step: 3664, Loss: 0.8398935922745043
[16-10-2022 14:25:34] INFO: Epoch: 3, Step: 3672, Loss: 0.8402114550680666
[16-10-2022 14:25:37] INFO: Epoch: 3, Step: 3680, Loss: 0.840453937120311
[16-10-2022 14:25:39] INFO: Epoch: 3, Step: 3688, Loss: 0.8406846993805042
[16-10-2022 14:25:42] INFO: Epoch: 3, Step: 3696, Loss: 0.8409826279833749
[16-10-2022 14:25:45] INFO: Epoch: 3, Step: 3704, Loss: 0.8411102722535925
[16-10-2022 14:25:48] INFO: Epoch: 3, Step: 3712, Loss: 0.841247335948464
[16-10-2022 14:25:51] INFO: Epoch: 3, Step: 3720, Loss: 0.8414051830498407
[16-10-2022 14:25:54] INFO: Epoch: 3, Step: 3728, Loss: 0.841636612968412
[16-10-2022 14:25:56] INFO: Epoch: 3, Step: 3736, Loss: 0.8417091487101394
[16-10-2022 14:25:59] INFO: Epoch: 3, Step: 3744, Loss: 0.8417741614802046
[16-10-2022 14:26:02] INFO: Epoch: 3, Step: 3752, Loss: 0.8419712052942876
[16-10-2022 14:26:05] INFO: Epoch: 3, Step: 3760, Loss: 0.8421214109613823
[16-10-2022 14:26:08] INFO: Epoch: 3, Step: 3768, Loss: 0.8423475135491687
[16-10-2022 14:26:11] INFO: Epoch: 3, Step: 3776, Loss: 0.8422236443562556
[16-10-2022 14:26:14] INFO: Epoch: 3, Step: 3784, Loss: 0.8421884429460125
[16-10-2022 14:26:17] INFO: Epoch: 3, Step: 3792, Loss: 0.8420669589445338
[16-10-2022 14:26:19] INFO: Epoch: 3, Step: 3800, Loss: 0.8420714471891332
[16-10-2022 14:26:22] INFO: Epoch: 3, Step: 3808, Loss: 0.8420219918402081
[16-10-2022 14:26:25] INFO: Epoch: 3, Step: 3816, Loss: 0.8417031251224235
[16-10-2022 14:26:28] INFO: Epoch: 3, Step: 3824, Loss: 0.841985443066319
[16-10-2022 14:26:31] INFO: Epoch: 3, Step: 3832, Loss: 0.8416547440663413
[16-10-2022 14:26:34] INFO: Epoch: 3, Step: 3840, Loss: 0.8414516039939873
[16-10-2022 14:26:37] INFO: Epoch: 3, Step: 3848, Loss: 0.8413743122051167
[16-10-2022 14:26:39] INFO: Epoch: 3, Step: 3856, Loss: 0.8409929487562677
[16-10-2022 14:26:42] INFO: Epoch: 3, Step: 3864, Loss: 0.8407099444398133
[16-10-2022 14:26:45] INFO: Epoch: 3, Step: 3872, Loss: 0.8403634870365413
[16-10-2022 14:26:48] INFO: Epoch: 3, Step: 3880, Loss: 0.8402630283555078
[16-10-2022 14:26:51] INFO: Epoch: 3, Step: 3888, Loss: 0.8399298996041982
[16-10-2022 14:26:54] INFO: Epoch: 3, Step: 3896, Loss: 0.8395787807462791
[16-10-2022 14:26:57] INFO: Epoch: 3, Step: 3904, Loss: 0.8389457628354396
[16-10-2022 14:26:59] INFO: Epoch: 3, Step: 3912, Loss: 0.8385091012806765
[16-10-2022 14:27:02] INFO: Epoch: 3, Step: 3920, Loss: 0.8382022013555342
[16-10-2022 14:27:05] INFO: Epoch: 3, Step: 3928, Loss: 0.8379197023295121
[16-10-2022 14:27:08] INFO: Epoch: 3, Step: 3936, Loss: 0.8374833779578192
[16-10-2022 14:27:11] INFO: Epoch: 3, Step: 3944, Loss: 0.8369253430653625
[16-10-2022 14:27:14] INFO: Epoch: 3, Step: 3952, Loss: 0.836483444732931
[16-10-2022 14:27:16] INFO: Epoch: 3, Step: 3960, Loss: 0.8359825293985247
[16-10-2022 14:27:17] INFO: Start eval!
       F1 (micro): 54.12%
/home/jiahaoran2022/anaconda3/envs/chef/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Precision (macro): 36.26%
   Recall (macro): 53.67%
       F1 (macro): 43.00%
[16-10-2022 14:27:36] INFO: Dev total acc: 0.5412004069175992
[16-10-2022 14:27:37] INFO: Saved best epoch 3, best f1 0.42998333440387504
[16-10-2022 14:27:40] INFO: Epoch: 4, Step: 3968, Loss: 0.8356222661837542
[16-10-2022 14:27:43] INFO: Epoch: 4, Step: 3976, Loss: 0.8353526160220472
[16-10-2022 14:27:45] INFO: Epoch: 4, Step: 3984, Loss: 0.8353616309896618
[16-10-2022 14:27:48] INFO: Epoch: 4, Step: 3992, Loss: 0.8350553262712092
[16-10-2022 14:27:51] INFO: Epoch: 4, Step: 4000, Loss: 0.8344892646083799
[16-10-2022 14:27:54] INFO: Epoch: 4, Step: 4008, Loss: 0.8347765774124245
[16-10-2022 14:27:57] INFO: Epoch: 4, Step: 4016, Loss: 0.8346480099174692
[16-10-2022 14:28:00] INFO: Epoch: 4, Step: 4024, Loss: 0.8347734806931603
[16-10-2022 14:28:03] INFO: Epoch: 4, Step: 4032, Loss: 0.8346678868522096
[16-10-2022 14:28:06] INFO: Epoch: 4, Step: 4040, Loss: 0.8344373379391576
[16-10-2022 14:28:08] INFO: Epoch: 4, Step: 4048, Loss: 0.834380462111394
[16-10-2022 14:28:11] INFO: Epoch: 4, Step: 4056, Loss: 0.8346178391535222
[16-10-2022 14:28:14] INFO: Epoch: 4, Step: 4064, Loss: 0.8359511057657605
[16-10-2022 14:28:17] INFO: Epoch: 4, Step: 4072, Loss: 0.8361594646314826
[16-10-2022 14:28:20] INFO: Epoch: 4, Step: 4080, Loss: 0.8367746692306239
[16-10-2022 14:28:23] INFO: Epoch: 4, Step: 4088, Loss: 0.8369372512082849
[16-10-2022 14:28:26] INFO: Epoch: 4, Step: 4096, Loss: 0.8368955112246299
[16-10-2022 14:28:28] INFO: Epoch: 4, Step: 4104, Loss: 0.8369649144127556
[16-10-2022 14:28:31] INFO: Epoch: 4, Step: 4112, Loss: 0.8367485561225285
[16-10-2022 14:28:34] INFO: Epoch: 4, Step: 4120, Loss: 0.8365205898600843
[16-10-2022 14:28:37] INFO: Epoch: 4, Step: 4128, Loss: 0.8363851131158597
[16-10-2022 14:28:40] INFO: Epoch: 4, Step: 4136, Loss: 0.8362790628181634
[16-10-2022 14:28:43] INFO: Epoch: 4, Step: 4144, Loss: 0.8362430457725342
[16-10-2022 14:28:46] INFO: Epoch: 4, Step: 4152, Loss: 0.8362526963536878
[16-10-2022 14:28:49] INFO: Epoch: 4, Step: 4160, Loss: 0.836013234937761
[16-10-2022 14:28:51] INFO: Epoch: 4, Step: 4168, Loss: 0.835511370679121
[16-10-2022 14:28:54] INFO: Epoch: 4, Step: 4176, Loss: 0.8352450798256899
[16-10-2022 14:28:57] INFO: Epoch: 4, Step: 4184, Loss: 0.8349253032686118
[16-10-2022 14:29:00] INFO: Epoch: 4, Step: 4192, Loss: 0.8351520120623199
[16-10-2022 14:29:03] INFO: Epoch: 4, Step: 4200, Loss: 0.8349591874375767
[16-10-2022 14:29:06] INFO: Epoch: 4, Step: 4208, Loss: 0.834583961324317
[16-10-2022 14:29:08] INFO: Epoch: 4, Step: 4216, Loss: 0.8344271640095553
[16-10-2022 14:29:11] INFO: Epoch: 4, Step: 4224, Loss: 0.8341931593683941
[16-10-2022 14:29:14] INFO: Epoch: 4, Step: 4232, Loss: 0.8338932264288311
[16-10-2022 14:29:17] INFO: Epoch: 4, Step: 4240, Loss: 0.8339580485641364
[16-10-2022 14:29:20] INFO: Epoch: 4, Step: 4248, Loss: 0.8338870013636241
[16-10-2022 14:29:23] INFO: Epoch: 4, Step: 4256, Loss: 0.8337261593258328
[16-10-2022 14:29:26] INFO: Epoch: 4, Step: 4264, Loss: 0.8336537582406824
[16-10-2022 14:29:28] INFO: Epoch: 4, Step: 4272, Loss: 0.8333728378333596
[16-10-2022 14:29:31] INFO: Epoch: 4, Step: 4280, Loss: 0.8332490229169869
[16-10-2022 14:29:34] INFO: Epoch: 4, Step: 4288, Loss: 0.8333006927947024
[16-10-2022 14:29:37] INFO: Epoch: 4, Step: 4296, Loss: 0.8329889093650755
[16-10-2022 14:29:40] INFO: Epoch: 4, Step: 4304, Loss: 0.8327388028141814
[16-10-2022 14:29:43] INFO: Epoch: 4, Step: 4312, Loss: 0.8327278899372921
[16-10-2022 14:29:46] INFO: Epoch: 4, Step: 4320, Loss: 0.8324639795425836
[16-10-2022 14:29:48] INFO: Epoch: 4, Step: 4328, Loss: 0.8321500533646193
[16-10-2022 14:29:51] INFO: Epoch: 4, Step: 4336, Loss: 0.8319519476430852
[16-10-2022 14:29:54] INFO: Epoch: 4, Step: 4344, Loss: 0.8318364016898838
[16-10-2022 14:29:57] INFO: Epoch: 4, Step: 4352, Loss: 0.8311364045238421
[16-10-2022 14:30:00] INFO: Epoch: 4, Step: 4360, Loss: 0.8306111245125776
[16-10-2022 14:30:03] INFO: Epoch: 4, Step: 4368, Loss: 0.8301329530661439
[16-10-2022 14:30:06] INFO: Epoch: 4, Step: 4376, Loss: 0.8298641921011003
[16-10-2022 14:30:08] INFO: Epoch: 4, Step: 4384, Loss: 0.829593174439111
[16-10-2022 14:30:11] INFO: Epoch: 4, Step: 4392, Loss: 0.8294398617788387
[16-10-2022 14:30:14] INFO: Epoch: 4, Step: 4400, Loss: 0.8287286860843108
[16-10-2022 14:30:17] INFO: Epoch: 4, Step: 4408, Loss: 0.8284823436352738
[16-10-2022 14:30:20] INFO: Epoch: 4, Step: 4416, Loss: 0.8281250516555202
[16-10-2022 14:30:23] INFO: Epoch: 4, Step: 4424, Loss: 0.8279743809025792
[16-10-2022 14:30:25] INFO: Epoch: 4, Step: 4432, Loss: 0.8273733408948653
[16-10-2022 14:30:28] INFO: Epoch: 4, Step: 4440, Loss: 0.8272387065941657
[16-10-2022 14:30:31] INFO: Epoch: 4, Step: 4448, Loss: 0.8271729655089967
[16-10-2022 14:30:34] INFO: Epoch: 4, Step: 4456, Loss: 0.8272430818516404
[16-10-2022 14:30:37] INFO: Epoch: 4, Step: 4464, Loss: 0.8266730824841098
[16-10-2022 14:30:40] INFO: Epoch: 4, Step: 4472, Loss: 0.8268791317035263
[16-10-2022 14:30:43] INFO: Epoch: 4, Step: 4480, Loss: 0.826685287298685
[16-10-2022 14:30:45] INFO: Epoch: 4, Step: 4488, Loss: 0.8262993545079054
[16-10-2022 14:30:48] INFO: Epoch: 4, Step: 4496, Loss: 0.8261033500457068
[16-10-2022 14:30:51] INFO: Epoch: 4, Step: 4504, Loss: 0.8257939368461761
[16-10-2022 14:30:54] INFO: Epoch: 4, Step: 4512, Loss: 0.8256699235437951
[16-10-2022 14:30:57] INFO: Epoch: 4, Step: 4520, Loss: 0.8253439762794573
[16-10-2022 14:31:00] INFO: Epoch: 4, Step: 4528, Loss: 0.8250774796106182
[16-10-2022 14:31:03] INFO: Epoch: 4, Step: 4536, Loss: 0.8249531807895504
[16-10-2022 14:31:05] INFO: Epoch: 4, Step: 4544, Loss: 0.824644639475688
[16-10-2022 14:31:08] INFO: Epoch: 4, Step: 4552, Loss: 0.8246952100241355
[16-10-2022 14:31:11] INFO: Epoch: 4, Step: 4560, Loss: 0.824357865676464
[16-10-2022 14:31:14] INFO: Epoch: 4, Step: 4568, Loss: 0.8240284729926914
[16-10-2022 14:31:17] INFO: Epoch: 4, Step: 4576, Loss: 0.8239738850771466
[16-10-2022 14:31:20] INFO: Epoch: 4, Step: 4584, Loss: 0.8240338414558173
[16-10-2022 14:31:23] INFO: Epoch: 4, Step: 4592, Loss: 0.8237579129482315
[16-10-2022 14:31:25] INFO: Epoch: 4, Step: 4600, Loss: 0.8233435843925603
[16-10-2022 14:31:28] INFO: Epoch: 4, Step: 4608, Loss: 0.823132173660286
[16-10-2022 14:31:31] INFO: Epoch: 4, Step: 4616, Loss: 0.8231025324332366
[16-10-2022 14:31:34] INFO: Epoch: 4, Step: 4624, Loss: 0.8233986435156919
[16-10-2022 14:31:37] INFO: Epoch: 4, Step: 4632, Loss: 0.8229909661316216
[16-10-2022 14:31:40] INFO: Epoch: 4, Step: 4640, Loss: 0.822574203012624
[16-10-2022 14:31:42] INFO: Epoch: 4, Step: 4648, Loss: 0.8223901010942514
[16-10-2022 14:31:45] INFO: Epoch: 4, Step: 4656, Loss: 0.8224151105695341
[16-10-2022 14:31:48] INFO: Epoch: 4, Step: 4664, Loss: 0.8220726289438315
[16-10-2022 14:31:51] INFO: Epoch: 4, Step: 4672, Loss: 0.8216418600904485
[16-10-2022 14:31:54] INFO: Epoch: 4, Step: 4680, Loss: 0.8213204742568653
[16-10-2022 14:31:57] INFO: Epoch: 4, Step: 4688, Loss: 0.8208399038204177
[16-10-2022 14:32:00] INFO: Epoch: 4, Step: 4696, Loss: 0.8208686928963055
[16-10-2022 14:32:02] INFO: Epoch: 4, Step: 4704, Loss: 0.8205654034430805
[16-10-2022 14:32:05] INFO: Epoch: 4, Step: 4712, Loss: 0.8204957250267088
[16-10-2022 14:32:08] INFO: Epoch: 4, Step: 4720, Loss: 0.8204384777702995
[16-10-2022 14:32:11] INFO: Epoch: 4, Step: 4728, Loss: 0.8201112669101698
[16-10-2022 14:32:14] INFO: Epoch: 4, Step: 4736, Loss: 0.8196242158057493
[16-10-2022 14:32:17] INFO: Epoch: 4, Step: 4744, Loss: 0.8194345129036755
[16-10-2022 14:32:20] INFO: Epoch: 4, Step: 4752, Loss: 0.8194321327559146
[16-10-2022 14:32:22] INFO: Epoch: 4, Step: 4760, Loss: 0.8192456669612564
[16-10-2022 14:32:25] INFO: Epoch: 4, Step: 4768, Loss: 0.8189889096456658
[16-10-2022 14:32:28] INFO: Epoch: 4, Step: 4776, Loss: 0.8188754323522223
[16-10-2022 14:32:31] INFO: Epoch: 4, Step: 4784, Loss: 0.8187198305641302
[16-10-2022 14:32:34] INFO: Epoch: 4, Step: 4792, Loss: 0.8183410567533266
[16-10-2022 14:32:37] INFO: Epoch: 4, Step: 4800, Loss: 0.8183146064301802
[16-10-2022 14:32:40] INFO: Epoch: 4, Step: 4808, Loss: 0.8177533758263543
[16-10-2022 14:32:42] INFO: Epoch: 4, Step: 4816, Loss: 0.8176734826668476
[16-10-2022 14:32:45] INFO: Epoch: 4, Step: 4824, Loss: 0.8173192266388886
[16-10-2022 14:32:48] INFO: Epoch: 4, Step: 4832, Loss: 0.8172285026502306
[16-10-2022 14:32:51] INFO: Epoch: 4, Step: 4840, Loss: 0.8168386147388469
[16-10-2022 14:32:54] INFO: Epoch: 4, Step: 4848, Loss: 0.8164481901150453
[16-10-2022 14:32:57] INFO: Epoch: 4, Step: 4856, Loss: 0.8161635244368154
[16-10-2022 14:32:59] INFO: Epoch: 4, Step: 4864, Loss: 0.8160664339857885
[16-10-2022 14:33:02] INFO: Epoch: 4, Step: 4872, Loss: 0.8158026747505088
[16-10-2022 14:33:05] INFO: Epoch: 4, Step: 4880, Loss: 0.8155108564678492
[16-10-2022 14:33:08] INFO: Epoch: 4, Step: 4888, Loss: 0.815309808009553
[16-10-2022 14:33:11] INFO: Epoch: 4, Step: 4896, Loss: 0.8151619509752887
[16-10-2022 14:33:14] INFO: Epoch: 4, Step: 4904, Loss: 0.8150577029376028
[16-10-2022 14:33:17] INFO: Epoch: 4, Step: 4912, Loss: 0.8147124933838964
[16-10-2022 14:33:20] INFO: Epoch: 4, Step: 4920, Loss: 0.8146661710425821
[16-10-2022 14:33:22] INFO: Epoch: 4, Step: 4928, Loss: 0.8144908118426242
[16-10-2022 14:33:25] INFO: Epoch: 4, Step: 4936, Loss: 0.8142504558983191
[16-10-2022 14:33:28] INFO: Epoch: 4, Step: 4944, Loss: 0.8138549321679354
[16-10-2022 14:33:30] INFO: Start eval!
       F1 (micro): 55.44%
/home/jiahaoran2022/anaconda3/envs/chef/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Precision (macro): 36.92%
   Recall (macro): 54.97%
       F1 (macro): 44.14%
[16-10-2022 14:33:49] INFO: Dev total acc: 0.5544252288911495
[16-10-2022 14:33:51] INFO: Saved best epoch 4, best f1 0.4414083312224067
[16-10-2022 14:33:51] INFO: Epoch: 5, Step: 4952, Loss: 0.8133551066053918
[16-10-2022 14:33:54] INFO: Epoch: 5, Step: 4960, Loss: 0.8131821428673616
[16-10-2022 14:33:57] INFO: Epoch: 5, Step: 4968, Loss: 0.8131145502083853
[16-10-2022 14:34:00] INFO: Epoch: 5, Step: 4976, Loss: 0.8126920625676893
[16-10-2022 14:34:03] INFO: Epoch: 5, Step: 4984, Loss: 0.8126757493336954
[16-10-2022 14:34:05] INFO: Epoch: 5, Step: 4992, Loss: 0.8123390153804291
[16-10-2022 14:34:08] INFO: Epoch: 5, Step: 5000, Loss: 0.8121083788074706
[16-10-2022 14:34:11] INFO: Epoch: 5, Step: 5008, Loss: 0.8116634133050353
[16-10-2022 14:34:14] INFO: Epoch: 5, Step: 5016, Loss: 0.8113986051528669
[16-10-2022 14:34:17] INFO: Epoch: 5, Step: 5024, Loss: 0.8111807860109431
[16-10-2022 14:34:20] INFO: Epoch: 5, Step: 5032, Loss: 0.8109991770653896
[16-10-2022 14:34:22] INFO: Epoch: 5, Step: 5040, Loss: 0.8107688032512128
[16-10-2022 14:34:25] INFO: Epoch: 5, Step: 5048, Loss: 0.8103435194885978
[16-10-2022 14:34:28] INFO: Epoch: 5, Step: 5056, Loss: 0.8103400090734532
[16-10-2022 14:34:31] INFO: Epoch: 5, Step: 5064, Loss: 0.8102281154251233
[16-10-2022 14:34:34] INFO: Epoch: 5, Step: 5072, Loss: 0.8100738465611325
[16-10-2022 14:34:36] INFO: Epoch: 5, Step: 5080, Loss: 0.8097087209421089
[16-10-2022 14:34:39] INFO: Epoch: 5, Step: 5088, Loss: 0.8095813733855202
[16-10-2022 14:34:42] INFO: Epoch: 5, Step: 5096, Loss: 0.809245738776173
[16-10-2022 14:34:45] INFO: Epoch: 5, Step: 5104, Loss: 0.8086820903086899
[16-10-2022 14:34:48] INFO: Epoch: 5, Step: 5112, Loss: 0.808212739368114
[16-10-2022 14:34:50] INFO: Epoch: 5, Step: 5120, Loss: 0.8076737973613639
[16-10-2022 14:34:53] INFO: Epoch: 5, Step: 5128, Loss: 0.8074657853857099
[16-10-2022 14:34:56] INFO: Epoch: 5, Step: 5136, Loss: 0.8068572820441487
[16-10-2022 14:34:59] INFO: Epoch: 5, Step: 5144, Loss: 0.8065127864817645
[16-10-2022 14:35:02] INFO: Epoch: 5, Step: 5152, Loss: 0.8064868010628411
[16-10-2022 14:35:04] INFO: Epoch: 5, Step: 5160, Loss: 0.8063532548364718
[16-10-2022 14:35:07] INFO: Epoch: 5, Step: 5168, Loss: 0.8067829104799394
[16-10-2022 14:35:10] INFO: Epoch: 5, Step: 5176, Loss: 0.8062796677301686
[16-10-2022 14:35:13] INFO: Epoch: 5, Step: 5184, Loss: 0.8058677750882656
[16-10-2022 14:35:16] INFO: Epoch: 5, Step: 5192, Loss: 0.8058998476583457
[16-10-2022 14:35:19] INFO: Epoch: 5, Step: 5200, Loss: 0.8055394062779704
[16-10-2022 14:35:22] INFO: Epoch: 5, Step: 5208, Loss: 0.8054899005240946
[16-10-2022 14:35:24] INFO: Epoch: 5, Step: 5216, Loss: 0.8050830991963139
[16-10-2022 14:35:27] INFO: Epoch: 5, Step: 5224, Loss: 0.804980953534221
[16-10-2022 14:35:30] INFO: Epoch: 5, Step: 5232, Loss: 0.8048516731824735
[16-10-2022 14:35:33] INFO: Epoch: 5, Step: 5240, Loss: 0.8047356456553866
[16-10-2022 14:35:36] INFO: Epoch: 5, Step: 5248, Loss: 0.8045604796093614
[16-10-2022 14:35:39] INFO: Epoch: 5, Step: 5256, Loss: 0.8044656649312856
[16-10-2022 14:35:42] INFO: Epoch: 5, Step: 5264, Loss: 0.8044846488260682
[16-10-2022 14:35:44] INFO: Epoch: 5, Step: 5272, Loss: 0.8043683568200973
[16-10-2022 14:35:47] INFO: Epoch: 5, Step: 5280, Loss: 0.8042728316638706
[16-10-2022 14:35:50] INFO: Epoch: 5, Step: 5288, Loss: 0.8041202251731919
[16-10-2022 14:35:53] INFO: Epoch: 5, Step: 5296, Loss: 0.8039410354610497
[16-10-2022 14:35:56] INFO: Epoch: 5, Step: 5304, Loss: 0.8036219195679233
[16-10-2022 14:35:59] INFO: Epoch: 5, Step: 5312, Loss: 0.8033132410744428
[16-10-2022 14:36:02] INFO: Epoch: 5, Step: 5320, Loss: 0.8031089005088647
[16-10-2022 14:36:04] INFO: Epoch: 5, Step: 5328, Loss: 0.8029181036249494
[16-10-2022 14:36:07] INFO: Epoch: 5, Step: 5336, Loss: 0.8025378409188211
[16-10-2022 14:36:10] INFO: Epoch: 5, Step: 5344, Loss: 0.802353092773921
[16-10-2022 14:36:13] INFO: Epoch: 5, Step: 5352, Loss: 0.8020712203159792
[16-10-2022 14:36:16] INFO: Epoch: 5, Step: 5360, Loss: 0.8016564277466529
[16-10-2022 14:36:19] INFO: Epoch: 5, Step: 5368, Loss: 0.8013989325569899
[16-10-2022 14:36:22] INFO: Epoch: 5, Step: 5376, Loss: 0.8010405882246591
[16-10-2022 14:36:24] INFO: Epoch: 5, Step: 5384, Loss: 0.8005376692514117
[16-10-2022 14:36:27] INFO: Epoch: 5, Step: 5392, Loss: 0.8003697203374291
[16-10-2022 14:36:30] INFO: Epoch: 5, Step: 5400, Loss: 0.7999889280295348
[16-10-2022 14:36:33] INFO: Epoch: 5, Step: 5408, Loss: 0.8001362044514524
[16-10-2022 14:36:36] INFO: Epoch: 5, Step: 5416, Loss: 0.7995612001441494
[16-10-2022 14:36:39] INFO: Epoch: 5, Step: 5424, Loss: 0.7993174224252786
[16-10-2022 14:36:42] INFO: Epoch: 5, Step: 5432, Loss: 0.7990928941436626
[16-10-2022 14:36:45] INFO: Epoch: 5, Step: 5440, Loss: 0.7988749874543594
[16-10-2022 14:36:48] INFO: Epoch: 5, Step: 5448, Loss: 0.7987800199386808
[16-10-2022 14:36:50] INFO: Epoch: 5, Step: 5456, Loss: 0.798807098446264
[16-10-2022 14:36:53] INFO: Epoch: 5, Step: 5464, Loss: 0.7984337310748666
[16-10-2022 14:36:56] INFO: Epoch: 5, Step: 5472, Loss: 0.798163175131535
[16-10-2022 14:36:59] INFO: Epoch: 5, Step: 5480, Loss: 0.7979842190984368
[16-10-2022 14:37:02] INFO: Epoch: 5, Step: 5488, Loss: 0.797655016857922
[16-10-2022 14:37:05] INFO: Epoch: 5, Step: 5496, Loss: 0.7974350128324335
[16-10-2022 14:37:07] INFO: Epoch: 5, Step: 5504, Loss: 0.7973614601035427
[16-10-2022 14:37:10] INFO: Epoch: 5, Step: 5512, Loss: 0.7971056294897967
[16-10-2022 14:37:13] INFO: Epoch: 5, Step: 5520, Loss: 0.7968154273286222
[16-10-2022 14:37:16] INFO: Epoch: 5, Step: 5528, Loss: 0.7968121763762338
[16-10-2022 14:37:19] INFO: Epoch: 5, Step: 5536, Loss: 0.7966899079993516
[16-10-2022 14:37:22] INFO: Epoch: 5, Step: 5544, Loss: 0.7967346801790903
[16-10-2022 14:37:25] INFO: Epoch: 5, Step: 5552, Loss: 0.7965635565956467
[16-10-2022 14:37:28] INFO: Epoch: 5, Step: 5560, Loss: 0.7963176003630618
[16-10-2022 14:37:30] INFO: Epoch: 5, Step: 5568, Loss: 0.7958626163134692
[16-10-2022 14:37:33] INFO: Epoch: 5, Step: 5576, Loss: 0.7955609224850404
[16-10-2022 14:37:36] INFO: Epoch: 5, Step: 5584, Loss: 0.7951355289066224
[16-10-2022 14:37:39] INFO: Epoch: 5, Step: 5592, Loss: 0.7947342355258751
[16-10-2022 14:37:42] INFO: Epoch: 5, Step: 5600, Loss: 0.7944359665956219
[16-10-2022 14:37:45] INFO: Epoch: 5, Step: 5608, Loss: 0.7940309690384758
[16-10-2022 14:37:48] INFO: Epoch: 5, Step: 5616, Loss: 0.7939272792167578
[16-10-2022 14:37:50] INFO: Epoch: 5, Step: 5624, Loss: 0.79358932537864
[16-10-2022 14:37:53] INFO: Epoch: 5, Step: 5632, Loss: 0.7936177615596339
[16-10-2022 14:37:56] INFO: Epoch: 5, Step: 5640, Loss: 0.7933180730928743
[16-10-2022 14:37:59] INFO: Epoch: 5, Step: 5648, Loss: 0.7931423697194678
[16-10-2022 14:38:02] INFO: Epoch: 5, Step: 5656, Loss: 0.7927235042132424
[16-10-2022 14:38:05] INFO: Epoch: 5, Step: 5664, Loss: 0.7924732318796658
[16-10-2022 14:38:08] INFO: Epoch: 5, Step: 5672, Loss: 0.7921401232577028
[16-10-2022 14:38:11] INFO: Epoch: 5, Step: 5680, Loss: 0.7917964638361815
[16-10-2022 14:38:13] INFO: Epoch: 5, Step: 5688, Loss: 0.7915298724488219
[16-10-2022 14:38:16] INFO: Epoch: 5, Step: 5696, Loss: 0.7915171179377734
[16-10-2022 14:38:19] INFO: Epoch: 5, Step: 5704, Loss: 0.7916648275138053
[16-10-2022 14:38:22] INFO: Epoch: 5, Step: 5712, Loss: 0.7913552900803793
[16-10-2022 14:38:25] INFO: Epoch: 5, Step: 5720, Loss: 0.7910731974110089
[16-10-2022 14:38:28] INFO: Epoch: 5, Step: 5728, Loss: 0.791019699482297
[16-10-2022 14:38:31] INFO: Epoch: 5, Step: 5736, Loss: 0.7905052388340337
[16-10-2022 14:38:33] INFO: Epoch: 5, Step: 5744, Loss: 0.7905210563738011
[16-10-2022 14:38:36] INFO: Epoch: 5, Step: 5752, Loss: 0.7903628323456569
[16-10-2022 14:38:39] INFO: Epoch: 5, Step: 5760, Loss: 0.7899991528551589
[16-10-2022 14:38:42] INFO: Epoch: 5, Step: 5768, Loss: 0.7894862610207494
[16-10-2022 14:38:45] INFO: Epoch: 5, Step: 5776, Loss: 0.7891725537030628
[16-10-2022 14:38:48] INFO: Epoch: 5, Step: 5784, Loss: 0.7888849598631384
[16-10-2022 14:38:51] INFO: Epoch: 5, Step: 5792, Loss: 0.7885034867203592
[16-10-2022 14:38:53] INFO: Epoch: 5, Step: 5800, Loss: 0.7881895769522497
[16-10-2022 14:38:56] INFO: Epoch: 5, Step: 5808, Loss: 0.7880952724469983
[16-10-2022 14:38:59] INFO: Epoch: 5, Step: 5816, Loss: 0.7878498252195679
[16-10-2022 14:39:02] INFO: Epoch: 5, Step: 5824, Loss: 0.7872841269050467
[16-10-2022 14:39:05] INFO: Epoch: 5, Step: 5832, Loss: 0.787281585226822
[16-10-2022 14:39:08] INFO: Epoch: 5, Step: 5840, Loss: 0.7869343908178458
[16-10-2022 14:39:10] INFO: Epoch: 5, Step: 5848, Loss: 0.7867559606646524
[16-10-2022 14:39:13] INFO: Epoch: 5, Step: 5856, Loss: 0.7865645842877464
[16-10-2022 14:39:16] INFO: Epoch: 5, Step: 5864, Loss: 0.786394185469833
[16-10-2022 14:39:19] INFO: Epoch: 5, Step: 5872, Loss: 0.7858955123156125
[16-10-2022 14:39:22] INFO: Epoch: 5, Step: 5880, Loss: 0.7855445698543652
[16-10-2022 14:39:24] INFO: Epoch: 5, Step: 5888, Loss: 0.7853775626819194
[16-10-2022 14:39:27] INFO: Epoch: 5, Step: 5896, Loss: 0.7851840329073559
[16-10-2022 14:39:30] INFO: Epoch: 5, Step: 5904, Loss: 0.7848256691630433
[16-10-2022 14:39:33] INFO: Epoch: 5, Step: 5912, Loss: 0.784602633994388
[16-10-2022 14:39:36] INFO: Epoch: 5, Step: 5920, Loss: 0.7841200540477942
[16-10-2022 14:39:39] INFO: Epoch: 5, Step: 5928, Loss: 0.7839995827934457
[16-10-2022 14:39:42] INFO: Epoch: 5, Step: 5936, Loss: 0.7833383882028051
[16-10-2022 14:39:43] INFO: Start eval!
       F1 (micro): 56.77%
/home/jiahaoran2022/anaconda3/envs/chef/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Precision (macro): 37.82%
   Recall (macro): 56.29%
       F1 (macro): 45.12%
[16-10-2022 14:40:03] INFO: Dev total acc: 0.5676500508646999
[16-10-2022 14:40:04] INFO: Saved best epoch 5, best f1 0.4511716979926696
[16-10-2022 14:40:05] INFO: Epoch: 6, Step: 5944, Loss: 0.7830214807331379
[16-10-2022 14:40:08] INFO: Epoch: 6, Step: 5952, Loss: 0.7826915497482402
[16-10-2022 14:40:11] INFO: Epoch: 6, Step: 5960, Loss: 0.7825925471780062
[16-10-2022 14:40:14] INFO: Epoch: 6, Step: 5968, Loss: 0.7825059014735947
[16-10-2022 14:40:17] INFO: Epoch: 6, Step: 5976, Loss: 0.7824731144481971
[16-10-2022 14:40:20] INFO: Epoch: 6, Step: 5984, Loss: 0.782066440544064
[16-10-2022 14:40:23] INFO: Epoch: 6, Step: 5992, Loss: 0.7817062607541241
[16-10-2022 14:40:25] INFO: Epoch: 6, Step: 6000, Loss: 0.7813186531371253
[16-10-2022 14:40:28] INFO: Epoch: 6, Step: 6008, Loss: 0.7808155414050748
[16-10-2022 14:40:31] INFO: Epoch: 6, Step: 6016, Loss: 0.7803274494245468
[16-10-2022 14:40:34] INFO: Epoch: 6, Step: 6024, Loss: 0.780105426453022
[16-10-2022 14:40:37] INFO: Epoch: 6, Step: 6032, Loss: 0.7800100621840345
[16-10-2022 14:40:40] INFO: Epoch: 6, Step: 6040, Loss: 0.7797517927382145
[16-10-2022 14:40:43] INFO: Epoch: 6, Step: 6048, Loss: 0.7795982368139026
[16-10-2022 14:40:45] INFO: Epoch: 6, Step: 6056, Loss: 0.7793283533247233
[16-10-2022 14:40:48] INFO: Epoch: 6, Step: 6064, Loss: 0.7792033147279516
[16-10-2022 14:40:51] INFO: Epoch: 6, Step: 6072, Loss: 0.7787049589427228
[16-10-2022 14:40:54] INFO: Epoch: 6, Step: 6080, Loss: 0.7781050746948094
[16-10-2022 14:40:57] INFO: Epoch: 6, Step: 6088, Loss: 0.7778112675178476
[16-10-2022 14:41:00] INFO: Epoch: 6, Step: 6096, Loss: 0.7775727852359001
[16-10-2022 14:41:03] INFO: Epoch: 6, Step: 6104, Loss: 0.777503938589326
[16-10-2022 14:41:05] INFO: Epoch: 6, Step: 6112, Loss: 0.7773377169246779
[16-10-2022 14:41:08] INFO: Epoch: 6, Step: 6120, Loss: 0.7770240941839843
[16-10-2022 14:41:11] INFO: Epoch: 6, Step: 6128, Loss: 0.7768753720867005
[16-10-2022 14:41:14] INFO: Epoch: 6, Step: 6136, Loss: 0.7765487763342345
[16-10-2022 14:41:17] INFO: Epoch: 6, Step: 6144, Loss: 0.7764856142027204
[16-10-2022 14:41:20] INFO: Epoch: 6, Step: 6152, Loss: 0.7761937380618309
[16-10-2022 14:41:23] INFO: Epoch: 6, Step: 6160, Loss: 0.775922497171413
[16-10-2022 14:41:26] INFO: Epoch: 6, Step: 6168, Loss: 0.7757515981557979
[16-10-2022 14:41:28] INFO: Epoch: 6, Step: 6176, Loss: 0.7754871854806018
[16-10-2022 14:41:31] INFO: Epoch: 6, Step: 6184, Loss: 0.7754533953710617
[16-10-2022 14:41:34] INFO: Epoch: 6, Step: 6192, Loss: 0.7754408093921492
[16-10-2022 14:41:37] INFO: Epoch: 6, Step: 6200, Loss: 0.7752498342319244
[16-10-2022 14:41:40] INFO: Epoch: 6, Step: 6208, Loss: 0.7750472853508824
[16-10-2022 14:41:43] INFO: Epoch: 6, Step: 6216, Loss: 0.7746939239634067
[16-10-2022 14:41:46] INFO: Epoch: 6, Step: 6224, Loss: 0.7745793178889564
[16-10-2022 14:41:48] INFO: Epoch: 6, Step: 6232, Loss: 0.7743440255079307
[16-10-2022 14:41:51] INFO: Epoch: 6, Step: 6240, Loss: 0.7741569464841311
[16-10-2022 14:41:54] INFO: Epoch: 6, Step: 6248, Loss: 0.773729623848091
[16-10-2022 14:41:57] INFO: Epoch: 6, Step: 6256, Loss: 0.7734112615543576
[16-10-2022 14:42:00] INFO: Epoch: 6, Step: 6264, Loss: 0.7732054281814591
[16-10-2022 14:42:03] INFO: Epoch: 6, Step: 6272, Loss: 0.7730181257446105
[16-10-2022 14:42:06] INFO: Epoch: 6, Step: 6280, Loss: 0.7726635715295535
[16-10-2022 14:42:08] INFO: Epoch: 6, Step: 6288, Loss: 0.772638398083413
[16-10-2022 14:42:11] INFO: Epoch: 6, Step: 6296, Loss: 0.772253754628619
[16-10-2022 14:42:14] INFO: Epoch: 6, Step: 6304, Loss: 0.7720844243531506
[16-10-2022 14:42:17] INFO: Epoch: 6, Step: 6312, Loss: 0.77182202427903
[16-10-2022 14:42:20] INFO: Epoch: 6, Step: 6320, Loss: 0.7716052640188323
[16-10-2022 14:42:23] INFO: Epoch: 6, Step: 6328, Loss: 0.7712868115695269
[16-10-2022 14:42:25] INFO: Epoch: 6, Step: 6336, Loss: 0.771066028129138
[16-10-2022 14:42:28] INFO: Epoch: 6, Step: 6344, Loss: 0.7710293243101403
[16-10-2022 14:42:31] INFO: Epoch: 6, Step: 6352, Loss: 0.7709010256066222
[16-10-2022 14:42:34] INFO: Epoch: 6, Step: 6360, Loss: 0.7707446869562424
[16-10-2022 14:42:37] INFO: Epoch: 6, Step: 6368, Loss: 0.7703724247081812
[16-10-2022 14:42:40] INFO: Epoch: 6, Step: 6376, Loss: 0.7700442805158391
[16-10-2022 14:42:43] INFO: Epoch: 6, Step: 6384, Loss: 0.7699096909377675
[16-10-2022 14:42:46] INFO: Epoch: 6, Step: 6392, Loss: 0.7698579648998132
[16-10-2022 14:42:48] INFO: Epoch: 6, Step: 6400, Loss: 0.7697466034238579
[16-10-2022 14:42:51] INFO: Epoch: 6, Step: 6408, Loss: 0.7695698923136131
[16-10-2022 14:42:54] INFO: Epoch: 6, Step: 6416, Loss: 0.7694421283339973
[16-10-2022 14:42:57] INFO: Epoch: 6, Step: 6424, Loss: 0.7692534662881848
[16-10-2022 14:43:00] INFO: Epoch: 6, Step: 6432, Loss: 0.7690367250296809
[16-10-2022 14:43:03] INFO: Epoch: 6, Step: 6440, Loss: 0.7689465929222012
[16-10-2022 14:43:06] INFO: Epoch: 6, Step: 6448, Loss: 0.768783611867695
[16-10-2022 14:43:08] INFO: Epoch: 6, Step: 6456, Loss: 0.7685126210424517
[16-10-2022 14:43:11] INFO: Epoch: 6, Step: 6464, Loss: 0.7682203672103711
[16-10-2022 14:43:14] INFO: Epoch: 6, Step: 6472, Loss: 0.7678236690792056
[16-10-2022 14:43:17] INFO: Epoch: 6, Step: 6480, Loss: 0.767563366655985
[16-10-2022 14:43:20] INFO: Epoch: 6, Step: 6488, Loss: 0.767417878310441
[16-10-2022 14:43:23] INFO: Epoch: 6, Step: 6496, Loss: 0.7673416205669361
[16-10-2022 14:43:26] INFO: Epoch: 6, Step: 6504, Loss: 0.7670319733521612
[16-10-2022 14:43:28] INFO: Epoch: 6, Step: 6512, Loss: 0.7667693178763351
[16-10-2022 14:43:31] INFO: Epoch: 6, Step: 6520, Loss: 0.7666457562661773
[16-10-2022 14:43:34] INFO: Epoch: 6, Step: 6528, Loss: 0.766635759225168
[16-10-2022 14:43:37] INFO: Epoch: 6, Step: 6536, Loss: 0.766362940095208
[16-10-2022 14:43:40] INFO: Epoch: 6, Step: 6544, Loss: 0.7660569127263221
[16-10-2022 14:43:43] INFO: Epoch: 6, Step: 6552, Loss: 0.7659788221053859
[16-10-2022 14:43:46] INFO: Epoch: 6, Step: 6560, Loss: 0.7657489561072736
[16-10-2022 14:43:48] INFO: Epoch: 6, Step: 6568, Loss: 0.7655390345890886
[16-10-2022 14:43:51] INFO: Epoch: 6, Step: 6576, Loss: 0.7655316432014704
[16-10-2022 14:43:54] INFO: Epoch: 6, Step: 6584, Loss: 0.7651973153410294
[16-10-2022 14:43:57] INFO: Epoch: 6, Step: 6592, Loss: 0.7650594237804285
[16-10-2022 14:44:00] INFO: Epoch: 6, Step: 6600, Loss: 0.7651258903092849
[16-10-2022 14:44:03] INFO: Epoch: 6, Step: 6608, Loss: 0.7647231633873145
[16-10-2022 14:44:06] INFO: Epoch: 6, Step: 6616, Loss: 0.7644191331212201
[16-10-2022 14:44:08] INFO: Epoch: 6, Step: 6624, Loss: 0.7641868615654696
[16-10-2022 14:44:11] INFO: Epoch: 6, Step: 6632, Loss: 0.7640404364524527
[16-10-2022 14:44:14] INFO: Epoch: 6, Step: 6640, Loss: 0.7637620844670787
[16-10-2022 14:44:17] INFO: Epoch: 6, Step: 6648, Loss: 0.7635876186888121
[16-10-2022 14:44:20] INFO: Epoch: 6, Step: 6656, Loss: 0.7634292710399092
[16-10-2022 14:44:23] INFO: Epoch: 6, Step: 6664, Loss: 0.7631545370609121
[16-10-2022 14:44:26] INFO: Epoch: 6, Step: 6672, Loss: 0.7629615828753463
[16-10-2022 14:44:28] INFO: Epoch: 6, Step: 6680, Loss: 0.7626748342764216
[16-10-2022 14:44:31] INFO: Epoch: 6, Step: 6688, Loss: 0.7625316542057595
[16-10-2022 14:44:34] INFO: Epoch: 6, Step: 6696, Loss: 0.7623348501488778
[16-10-2022 14:44:37] INFO: Epoch: 6, Step: 6704, Loss: 0.7619439901874197
[16-10-2022 14:44:40] INFO: Epoch: 6, Step: 6712, Loss: 0.7618891079899113
[16-10-2022 14:44:43] INFO: Epoch: 6, Step: 6720, Loss: 0.7617982756817783
[16-10-2022 14:44:46] INFO: Epoch: 6, Step: 6728, Loss: 0.761639252183782
[16-10-2022 14:44:48] INFO: Epoch: 6, Step: 6736, Loss: 0.761220116670987
[16-10-2022 14:44:51] INFO: Epoch: 6, Step: 6744, Loss: 0.7609360744853088
[16-10-2022 14:44:54] INFO: Epoch: 6, Step: 6752, Loss: 0.7608402246367785
[16-10-2022 14:44:57] INFO: Epoch: 6, Step: 6760, Loss: 0.7606437281308775
[16-10-2022 14:45:00] INFO: Epoch: 6, Step: 6768, Loss: 0.7603616627295511
[16-10-2022 14:45:03] INFO: Epoch: 6, Step: 6776, Loss: 0.7600841646999841
[16-10-2022 14:45:06] INFO: Epoch: 6, Step: 6784, Loss: 0.7599639293396264
[16-10-2022 14:45:08] INFO: Epoch: 6, Step: 6792, Loss: 0.7597968477072489
[16-10-2022 14:45:11] INFO: Epoch: 6, Step: 6800, Loss: 0.7594817368363088
[16-10-2022 14:45:14] INFO: Epoch: 6, Step: 6808, Loss: 0.7593195721639605
[16-10-2022 14:45:17] INFO: Epoch: 6, Step: 6816, Loss: 0.7592068499073437
[16-10-2022 14:45:20] INFO: Epoch: 6, Step: 6824, Loss: 0.7590234606114196
[16-10-2022 14:45:23] INFO: Epoch: 6, Step: 6832, Loss: 0.7590208314103023
[16-10-2022 14:45:26] INFO: Epoch: 6, Step: 6840, Loss: 0.7588683852637352
[16-10-2022 14:45:28] INFO: Epoch: 6, Step: 6848, Loss: 0.7588442621810395
[16-10-2022 14:45:31] INFO: Epoch: 6, Step: 6856, Loss: 0.7585029335287288
[16-10-2022 14:45:34] INFO: Epoch: 6, Step: 6864, Loss: 0.7581880803166898
[16-10-2022 14:45:37] INFO: Epoch: 6, Step: 6872, Loss: 0.7579296813097192
[16-10-2022 14:45:40] INFO: Epoch: 6, Step: 6880, Loss: 0.7578390183322633
[16-10-2022 14:45:43] INFO: Epoch: 6, Step: 6888, Loss: 0.7575096849392254
[16-10-2022 14:45:46] INFO: Epoch: 6, Step: 6896, Loss: 0.7572890726094333
[16-10-2022 14:45:49] INFO: Epoch: 6, Step: 6904, Loss: 0.7568636470213255
[16-10-2022 14:45:51] INFO: Epoch: 6, Step: 6912, Loss: 0.7566478782882206
[16-10-2022 14:45:54] INFO: Epoch: 6, Step: 6920, Loss: 0.7564084240946103
[16-10-2022 14:45:57] INFO: Epoch: 6, Step: 6928, Loss: 0.7563690509411722
[16-10-2022 14:45:58] INFO: Start eval!
       F1 (micro): 57.27%
/home/jiahaoran2022/anaconda3/envs/chef/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Precision (macro): 38.14%
   Recall (macro): 56.79%
       F1 (macro): 45.58%
[16-10-2022 14:46:18] INFO: Dev total acc: 0.572736520854527
[16-10-2022 14:46:19] INFO: Saved best epoch 6, best f1 0.4558142292783078
[16-10-2022 14:46:21] INFO: Epoch: 7, Step: 6936, Loss: 0.7562228317411281
[16-10-2022 14:46:24] INFO: Epoch: 7, Step: 6944, Loss: 0.7559571556434841
[16-10-2022 14:46:27] INFO: Epoch: 7, Step: 6952, Loss: 0.7556553273729798
[16-10-2022 14:46:29] INFO: Epoch: 7, Step: 6960, Loss: 0.755342979340065
[16-10-2022 14:46:32] INFO: Epoch: 7, Step: 6968, Loss: 0.7551202546836261
[16-10-2022 14:46:35] INFO: Epoch: 7, Step: 6976, Loss: 0.7548308201105478
[16-10-2022 14:46:38] INFO: Epoch: 7, Step: 6984, Loss: 0.754738503363515
[16-10-2022 14:46:41] INFO: Epoch: 7, Step: 6992, Loss: 0.7547598920951257
[16-10-2022 14:46:44] INFO: Epoch: 7, Step: 7000, Loss: 0.754484193542717
[16-10-2022 14:46:47] INFO: Epoch: 7, Step: 7008, Loss: 0.7542082557000848
[16-10-2022 14:46:50] INFO: Epoch: 7, Step: 7016, Loss: 0.7540835961322605
[16-10-2022 14:46:52] INFO: Epoch: 7, Step: 7024, Loss: 0.7540561964503197
[16-10-2022 14:46:55] INFO: Epoch: 7, Step: 7032, Loss: 0.754132673685239
[16-10-2022 14:46:58] INFO: Epoch: 7, Step: 7040, Loss: 0.7540301244097489
[16-10-2022 14:47:01] INFO: Epoch: 7, Step: 7048, Loss: 0.7536780744305921
[16-10-2022 14:47:04] INFO: Epoch: 7, Step: 7056, Loss: 0.7534064821811404
[16-10-2022 14:47:07] INFO: Epoch: 7, Step: 7064, Loss: 0.7532353838352069
[16-10-2022 14:47:10] INFO: Epoch: 7, Step: 7072, Loss: 0.753088127775866
[16-10-2022 14:47:12] INFO: Epoch: 7, Step: 7080, Loss: 0.7528544766823264
[16-10-2022 14:47:15] INFO: Epoch: 7, Step: 7088, Loss: 0.7525338102810184
[16-10-2022 14:47:18] INFO: Epoch: 7, Step: 7096, Loss: 0.7522604992595454
[16-10-2022 14:47:21] INFO: Epoch: 7, Step: 7104, Loss: 0.7518845957893826
[16-10-2022 14:47:24] INFO: Epoch: 7, Step: 7112, Loss: 0.7516424039172491
[16-10-2022 14:47:27] INFO: Epoch: 7, Step: 7120, Loss: 0.7516632830855031
[16-10-2022 14:47:30] INFO: Epoch: 7, Step: 7128, Loss: 0.7512962089587156
[16-10-2022 14:47:33] INFO: Epoch: 7, Step: 7136, Loss: 0.7509659559266632
[16-10-2022 14:47:35] INFO: Epoch: 7, Step: 7144, Loss: 0.7509451440445902
[16-10-2022 14:47:38] INFO: Epoch: 7, Step: 7152, Loss: 0.7508215462060864
[16-10-2022 14:47:41] INFO: Epoch: 7, Step: 7160, Loss: 0.7506680142660029
[16-10-2022 14:47:44] INFO: Epoch: 7, Step: 7168, Loss: 0.7505739943137973
[16-10-2022 14:47:47] INFO: Epoch: 7, Step: 7176, Loss: 0.7502054438652285
[16-10-2022 14:47:50] INFO: Epoch: 7, Step: 7184, Loss: 0.7497943025025415
[16-10-2022 14:47:53] INFO: Epoch: 7, Step: 7192, Loss: 0.7497485855452458
[16-10-2022 14:47:55] INFO: Epoch: 7, Step: 7200, Loss: 0.749459520160852
[16-10-2022 14:47:58] INFO: Epoch: 7, Step: 7208, Loss: 0.7491552606147596
[16-10-2022 14:48:01] INFO: Epoch: 7, Step: 7216, Loss: 0.7491943794380186
[16-10-2022 14:48:04] INFO: Epoch: 7, Step: 7224, Loss: 0.7492979934376256
[16-10-2022 14:48:07] INFO: Epoch: 7, Step: 7232, Loss: 0.7490361496951512
[16-10-2022 14:48:10] INFO: Epoch: 7, Step: 7240, Loss: 0.7490085866595647
[16-10-2022 14:48:13] INFO: Epoch: 7, Step: 7248, Loss: 0.7488136118587426
[16-10-2022 14:48:15] INFO: Epoch: 7, Step: 7256, Loss: 0.7486314812234719
[16-10-2022 14:48:18] INFO: Epoch: 7, Step: 7264, Loss: 0.7482604313265465
[16-10-2022 14:48:21] INFO: Epoch: 7, Step: 7272, Loss: 0.7480349684502047
[16-10-2022 14:48:24] INFO: Epoch: 7, Step: 7280, Loss: 0.7477264824093189
[16-10-2022 14:48:27] INFO: Epoch: 7, Step: 7288, Loss: 0.7474261759473759
[16-10-2022 14:48:30] INFO: Epoch: 7, Step: 7296, Loss: 0.7471699832143212
[16-10-2022 14:48:32] INFO: Epoch: 7, Step: 7304, Loss: 0.7471055952553729
[16-10-2022 14:48:35] INFO: Epoch: 7, Step: 7312, Loss: 0.7470063074279062
[16-10-2022 14:48:38] INFO: Epoch: 7, Step: 7320, Loss: 0.7468597895425182
[16-10-2022 14:48:41] INFO: Epoch: 7, Step: 7328, Loss: 0.7467467600777727
[16-10-2022 14:48:44] INFO: Epoch: 7, Step: 7336, Loss: 0.7466036200877931
[16-10-2022 14:48:47] INFO: Epoch: 7, Step: 7344, Loss: 0.7464318459935809
[16-10-2022 14:48:49] INFO: Epoch: 7, Step: 7352, Loss: 0.7463544763455533
[16-10-2022 14:48:52] INFO: Epoch: 7, Step: 7360, Loss: 0.7460130764601816
[16-10-2022 14:48:55] INFO: Epoch: 7, Step: 7368, Loss: 0.7459515532793279
[16-10-2022 14:48:58] INFO: Epoch: 7, Step: 7376, Loss: 0.745960367007652
[16-10-2022 14:49:01] INFO: Epoch: 7, Step: 7384, Loss: 0.7457460665138076
[16-10-2022 14:49:04] INFO: Epoch: 7, Step: 7392, Loss: 0.7456731416443385
[16-10-2022 14:49:07] INFO: Epoch: 7, Step: 7400, Loss: 0.7454764195355513
[16-10-2022 14:49:09] INFO: Epoch: 7, Step: 7408, Loss: 0.7451661316578462
[16-10-2022 14:49:12] INFO: Epoch: 7, Step: 7416, Loss: 0.745016245995764
[16-10-2022 14:49:15] INFO: Epoch: 7, Step: 7424, Loss: 0.744666785429792
[16-10-2022 14:49:18] INFO: Epoch: 7, Step: 7432, Loss: 0.7444377796543089
[16-10-2022 14:49:21] INFO: Epoch: 7, Step: 7440, Loss: 0.7442178724178526
[16-10-2022 14:49:24] INFO: Epoch: 7, Step: 7448, Loss: 0.7439496212240879
[16-10-2022 14:49:27] INFO: Epoch: 7, Step: 7456, Loss: 0.7437756404089904
[16-10-2022 14:49:30] INFO: Epoch: 7, Step: 7464, Loss: 0.7436677353783131
[16-10-2022 14:49:32] INFO: Epoch: 7, Step: 7472, Loss: 0.74336890717401
[16-10-2022 14:49:35] INFO: Epoch: 7, Step: 7480, Loss: 0.7430413114200921
[16-10-2022 14:49:38] INFO: Epoch: 7, Step: 7488, Loss: 0.7429061557000215
[16-10-2022 14:49:41] INFO: Epoch: 7, Step: 7496, Loss: 0.7427710098783084
[16-10-2022 14:49:44] INFO: Epoch: 7, Step: 7504, Loss: 0.7426553275024219
[16-10-2022 14:49:47] INFO: Epoch: 7, Step: 7512, Loss: 0.7425180589517479
[16-10-2022 14:49:49] INFO: Epoch: 7, Step: 7520, Loss: 0.7420965280151096
[16-10-2022 14:49:52] INFO: Epoch: 7, Step: 7528, Loss: 0.7418793878413237
[16-10-2022 14:49:55] INFO: Epoch: 7, Step: 7536, Loss: 0.7418521402859588
[16-10-2022 14:49:58] INFO: Epoch: 7, Step: 7544, Loss: 0.7416901549137835
[16-10-2022 14:50:01] INFO: Epoch: 7, Step: 7552, Loss: 0.7413177348784927
[16-10-2022 14:50:04] INFO: Epoch: 7, Step: 7560, Loss: 0.740976054501784
[16-10-2022 14:50:07] INFO: Epoch: 7, Step: 7568, Loss: 0.7405981916513977
[16-10-2022 14:50:10] INFO: Epoch: 7, Step: 7576, Loss: 0.7405150875989193
[16-10-2022 14:50:12] INFO: Epoch: 7, Step: 7584, Loss: 0.7403638385740339
[16-10-2022 14:50:15] INFO: Epoch: 7, Step: 7592, Loss: 0.7400986904929148
[16-10-2022 14:50:18] INFO: Epoch: 7, Step: 7600, Loss: 0.7397960969751899
[16-10-2022 14:50:21] INFO: Epoch: 7, Step: 7608, Loss: 0.7396459489337197
[16-10-2022 14:50:24] INFO: Epoch: 7, Step: 7616, Loss: 0.7393769572137862
[16-10-2022 14:50:27] INFO: Epoch: 7, Step: 7624, Loss: 0.7391408099020967
[16-10-2022 14:50:30] INFO: Epoch: 7, Step: 7632, Loss: 0.7389788358795519
[16-10-2022 14:50:33] INFO: Epoch: 7, Step: 7640, Loss: 0.7388566285669318
[16-10-2022 14:50:35] INFO: Epoch: 7, Step: 7648, Loss: 0.7388000782938758
[16-10-2022 14:50:38] INFO: Epoch: 7, Step: 7656, Loss: 0.7386649865194935
[16-10-2022 14:50:41] INFO: Epoch: 7, Step: 7664, Loss: 0.7384482441544983
[16-10-2022 14:50:44] INFO: Epoch: 7, Step: 7672, Loss: 0.7382926162244022
[16-10-2022 14:50:47] INFO: Epoch: 7, Step: 7680, Loss: 0.7380880681996838
[16-10-2022 14:50:50] INFO: Epoch: 7, Step: 7688, Loss: 0.7378933729684423
[16-10-2022 14:50:53] INFO: Epoch: 7, Step: 7696, Loss: 0.7378553880244135
[16-10-2022 14:50:56] INFO: Epoch: 7, Step: 7704, Loss: 0.7375445184539735
[16-10-2022 14:50:58] INFO: Epoch: 7, Step: 7712, Loss: 0.7372596898465034
[16-10-2022 14:51:01] INFO: Epoch: 7, Step: 7720, Loss: 0.7370233013304387
[16-10-2022 14:51:04] INFO: Epoch: 7, Step: 7728, Loss: 0.7366089615262333
[16-10-2022 14:51:07] INFO: Epoch: 7, Step: 7736, Loss: 0.7364871216655808
[16-10-2022 14:51:10] INFO: Epoch: 7, Step: 7744, Loss: 0.7363091847818051
[16-10-2022 14:51:13] INFO: Epoch: 7, Step: 7752, Loss: 0.7363109232284135
[16-10-2022 14:51:16] INFO: Epoch: 7, Step: 7760, Loss: 0.7360602172845401
[16-10-2022 14:51:18] INFO: Epoch: 7, Step: 7768, Loss: 0.7358778072382114
[16-10-2022 14:51:21] INFO: Epoch: 7, Step: 7776, Loss: 0.7356612105751432
[16-10-2022 14:51:24] INFO: Epoch: 7, Step: 7784, Loss: 0.7352950904190156
[16-10-2022 14:51:27] INFO: Epoch: 7, Step: 7792, Loss: 0.7350611438256742
[16-10-2022 14:51:30] INFO: Epoch: 7, Step: 7800, Loss: 0.7347786763181579
[16-10-2022 14:51:33] INFO: Epoch: 7, Step: 7808, Loss: 0.7345071787889725
[16-10-2022 14:51:36] INFO: Epoch: 7, Step: 7816, Loss: 0.7342650038991011
[16-10-2022 14:51:38] INFO: Epoch: 7, Step: 7824, Loss: 0.7341631736862618
[16-10-2022 14:51:41] INFO: Epoch: 7, Step: 7832, Loss: 0.7340062961093722
[16-10-2022 14:51:44] INFO: Epoch: 7, Step: 7840, Loss: 0.7340021978859526
[16-10-2022 14:51:47] INFO: Epoch: 7, Step: 7848, Loss: 0.7338420008233334
[16-10-2022 14:51:50] INFO: Epoch: 7, Step: 7856, Loss: 0.7334766835680939
[16-10-2022 14:51:53] INFO: Epoch: 7, Step: 7864, Loss: 0.7333979689002718
[16-10-2022 14:51:56] INFO: Epoch: 7, Step: 7872, Loss: 0.733238559852769
[16-10-2022 14:51:58] INFO: Epoch: 7, Step: 7880, Loss: 0.7329301514095596
[16-10-2022 14:52:01] INFO: Epoch: 7, Step: 7888, Loss: 0.7327330966010733
[16-10-2022 14:52:04] INFO: Epoch: 7, Step: 7896, Loss: 0.7325794694359344
[16-10-2022 14:52:07] INFO: Epoch: 7, Step: 7904, Loss: 0.7324920684925984
[16-10-2022 14:52:10] INFO: Epoch: 7, Step: 7912, Loss: 0.732376510038684
[16-10-2022 14:52:13] INFO: Epoch: 7, Step: 7920, Loss: 0.7322549472031553
[16-10-2022 14:52:13] INFO: Start eval!
       F1 (micro): 57.38%
/home/jiahaoran2022/anaconda3/envs/chef/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Precision (macro): 38.19%
   Recall (macro): 56.89%
       F1 (macro): 45.60%
[16-10-2022 14:52:32] INFO: Dev total acc: 0.5737538148524923
[16-10-2022 14:52:34] INFO: Saved best epoch 7, best f1 0.4560348781802069
[16-10-2022 14:52:36] INFO: Epoch: 8, Step: 7928, Loss: 0.7320606203267764
[16-10-2022 14:52:39] INFO: Epoch: 8, Step: 7936, Loss: 0.7317520751709012
[16-10-2022 14:52:42] INFO: Epoch: 8, Step: 7944, Loss: 0.7316291297716631
[16-10-2022 14:52:45] INFO: Epoch: 8, Step: 7952, Loss: 0.7314476288646233
[16-10-2022 14:52:48] INFO: Epoch: 8, Step: 7960, Loss: 0.7312443929050569
[16-10-2022 14:52:50] INFO: Epoch: 8, Step: 7968, Loss: 0.7312402991324677
[16-10-2022 14:52:53] INFO: Epoch: 8, Step: 7976, Loss: 0.7310980252941294
[16-10-2022 14:52:56] INFO: Epoch: 8, Step: 7984, Loss: 0.7309040777531841
[16-10-2022 14:52:59] INFO: Epoch: 8, Step: 7992, Loss: 0.7305363570274815
[16-10-2022 14:53:02] INFO: Epoch: 8, Step: 8000, Loss: 0.7303321861685349
[16-10-2022 14:53:05] INFO: Epoch: 8, Step: 8008, Loss: 0.7301687438745375
[16-10-2022 14:53:07] INFO: Epoch: 8, Step: 8016, Loss: 0.7299354865002967
[16-10-2022 14:53:10] INFO: Epoch: 8, Step: 8024, Loss: 0.7296976028191409
[16-10-2022 14:53:13] INFO: Epoch: 8, Step: 8032, Loss: 0.7294775725985264
[16-10-2022 14:53:16] INFO: Epoch: 8, Step: 8040, Loss: 0.729290707382054
[16-10-2022 14:53:19] INFO: Epoch: 8, Step: 8048, Loss: 0.7290366326350532
[16-10-2022 14:53:22] INFO: Epoch: 8, Step: 8056, Loss: 0.728751025304611
[16-10-2022 14:53:25] INFO: Epoch: 8, Step: 8064, Loss: 0.7284949694982906
[16-10-2022 14:53:27] INFO: Epoch: 8, Step: 8072, Loss: 0.7283384797672907
[16-10-2022 14:53:30] INFO: Epoch: 8, Step: 8080, Loss: 0.7280380264943616
[16-10-2022 14:53:33] INFO: Epoch: 8, Step: 8088, Loss: 0.7279164310379931
[16-10-2022 14:53:36] INFO: Epoch: 8, Step: 8096, Loss: 0.7277993572523485
[16-10-2022 14:53:39] INFO: Epoch: 8, Step: 8104, Loss: 0.7274262413997683
[16-10-2022 14:53:42] INFO: Epoch: 8, Step: 8112, Loss: 0.7272312840547036
[16-10-2022 14:53:45] INFO: Epoch: 8, Step: 8120, Loss: 0.7270518438298845
[16-10-2022 14:53:48] INFO: Epoch: 8, Step: 8128, Loss: 0.7269156464603896
[16-10-2022 14:53:50] INFO: Epoch: 8, Step: 8136, Loss: 0.7268328160902024
[16-10-2022 14:53:53] INFO: Epoch: 8, Step: 8144, Loss: 0.7265307749342633
[16-10-2022 14:53:56] INFO: Epoch: 8, Step: 8152, Loss: 0.7262410867335122
[16-10-2022 14:53:59] INFO: Epoch: 8, Step: 8160, Loss: 0.7260273254937677
[16-10-2022 14:54:02] INFO: Epoch: 8, Step: 8168, Loss: 0.7257101132715147
[16-10-2022 14:54:05] INFO: Epoch: 8, Step: 8176, Loss: 0.7256587671098774
[16-10-2022 14:54:07] INFO: Epoch: 8, Step: 8184, Loss: 0.725415085170624
[16-10-2022 14:54:10] INFO: Epoch: 8, Step: 8192, Loss: 0.72522093436829
[16-10-2022 14:54:13] INFO: Epoch: 8, Step: 8200, Loss: 0.7248596077916737
[16-10-2022 14:54:16] INFO: Epoch: 8, Step: 8208, Loss: 0.7246908300277665
[16-10-2022 14:54:19] INFO: Epoch: 8, Step: 8216, Loss: 0.7244407960028819
[16-10-2022 14:54:22] INFO: Epoch: 8, Step: 8224, Loss: 0.7244235339773013
[16-10-2022 14:54:25] INFO: Epoch: 8, Step: 8232, Loss: 0.7241850560354623
[16-10-2022 14:54:27] INFO: Epoch: 8, Step: 8240, Loss: 0.7241042216747043
[16-10-2022 14:54:30] INFO: Epoch: 8, Step: 8248, Loss: 0.7237996468433496
[16-10-2022 14:54:33] INFO: Epoch: 8, Step: 8256, Loss: 0.7236525091814698
[16-10-2022 14:54:36] INFO: Epoch: 8, Step: 8264, Loss: 0.7234281225870244
[16-10-2022 14:54:39] INFO: Epoch: 8, Step: 8272, Loss: 0.7233069649671533
[16-10-2022 14:54:42] INFO: Epoch: 8, Step: 8280, Loss: 0.7230765423746557
[16-10-2022 14:54:45] INFO: Epoch: 8, Step: 8288, Loss: 0.7228089035196595
[16-10-2022 14:54:47] INFO: Epoch: 8, Step: 8296, Loss: 0.722690384150218
[16-10-2022 14:54:50] INFO: Epoch: 8, Step: 8304, Loss: 0.7225239195646577
[16-10-2022 14:54:53] INFO: Epoch: 8, Step: 8312, Loss: 0.7223362627204445
[16-10-2022 14:54:56] INFO: Epoch: 8, Step: 8320, Loss: 0.72216629739986
[16-10-2022 14:54:59] INFO: Epoch: 8, Step: 8328, Loss: 0.722041903637577
[16-10-2022 14:55:02] INFO: Epoch: 8, Step: 8336, Loss: 0.7219606952133167
[16-10-2022 14:55:04] INFO: Epoch: 8, Step: 8344, Loss: 0.7216396034920317
[16-10-2022 14:55:07] INFO: Epoch: 8, Step: 8352, Loss: 0.7214025137745385
[16-10-2022 14:55:10] INFO: Epoch: 8, Step: 8360, Loss: 0.7212960841726942
[16-10-2022 14:55:13] INFO: Epoch: 8, Step: 8368, Loss: 0.7211452638921927
[16-10-2022 14:55:16] INFO: Epoch: 8, Step: 8376, Loss: 0.7209633285799818
[16-10-2022 14:55:19] INFO: Epoch: 8, Step: 8384, Loss: 0.7208232866659787
[16-10-2022 14:55:22] INFO: Epoch: 8, Step: 8392, Loss: 0.7205660691510647
[16-10-2022 14:55:25] INFO: Epoch: 8, Step: 8400, Loss: 0.7202916807889852
[16-10-2022 14:55:27] INFO: Epoch: 8, Step: 8408, Loss: 0.7200041315438659
[16-10-2022 14:55:30] INFO: Epoch: 8, Step: 8416, Loss: 0.7197000574769487
[16-10-2022 14:55:33] INFO: Epoch: 8, Step: 8424, Loss: 0.719626969969615
[16-10-2022 14:55:36] INFO: Epoch: 8, Step: 8432, Loss: 0.7194440546538418
[16-10-2022 14:55:39] INFO: Epoch: 8, Step: 8440, Loss: 0.7194522299715607
[16-10-2022 14:55:42] INFO: Epoch: 8, Step: 8448, Loss: 0.719266017875555
[16-10-2022 14:55:45] INFO: Epoch: 8, Step: 8456, Loss: 0.7190405734816556
[16-10-2022 14:55:47] INFO: Epoch: 8, Step: 8464, Loss: 0.7190707575610008
[16-10-2022 14:55:50] INFO: Epoch: 8, Step: 8472, Loss: 0.7190101781083542
[16-10-2022 14:55:53] INFO: Epoch: 8, Step: 8480, Loss: 0.7188867928245072
[16-10-2022 14:55:56] INFO: Epoch: 8, Step: 8488, Loss: 0.7187608678721712
[16-10-2022 14:55:59] INFO: Epoch: 8, Step: 8496, Loss: 0.7185657299198335
[16-10-2022 14:56:02] INFO: Epoch: 8, Step: 8504, Loss: 0.7183905890538348
[16-10-2022 14:56:04] INFO: Epoch: 8, Step: 8512, Loss: 0.7180805634037696
[16-10-2022 14:56:07] INFO: Epoch: 8, Step: 8520, Loss: 0.7180239553598365
[16-10-2022 14:56:10] INFO: Epoch: 8, Step: 8528, Loss: 0.7178384989782328
[16-10-2022 14:56:13] INFO: Epoch: 8, Step: 8536, Loss: 0.717651078330437
[16-10-2022 14:56:16] INFO: Epoch: 8, Step: 8544, Loss: 0.717566057332898
[16-10-2022 14:56:19] INFO: Epoch: 8, Step: 8552, Loss: 0.7174358655519217
[16-10-2022 14:56:22] INFO: Epoch: 8, Step: 8560, Loss: 0.7174020547589602
[16-10-2022 14:56:24] INFO: Epoch: 8, Step: 8568, Loss: 0.7174451179105972
[16-10-2022 14:56:27] INFO: Epoch: 8, Step: 8576, Loss: 0.7172708224236825
[16-10-2022 14:56:30] INFO: Epoch: 8, Step: 8584, Loss: 0.7171254200216052
[16-10-2022 14:56:33] INFO: Epoch: 8, Step: 8592, Loss: 0.716966346998446
[16-10-2022 14:56:36] INFO: Epoch: 8, Step: 8600, Loss: 0.7168109091141804
[16-10-2022 14:56:39] INFO: Epoch: 8, Step: 8608, Loss: 0.7165398533732223
[16-10-2022 14:56:42] INFO: Epoch: 8, Step: 8616, Loss: 0.7163808385464612
[16-10-2022 14:56:45] INFO: Epoch: 8, Step: 8624, Loss: 0.7161673281772983
[16-10-2022 14:56:47] INFO: Epoch: 8, Step: 8632, Loss: 0.7159681061159414
[16-10-2022 14:56:50] INFO: Epoch: 8, Step: 8640, Loss: 0.715703195729733
[16-10-2022 14:56:53] INFO: Epoch: 8, Step: 8648, Loss: 0.7154592296016508
[16-10-2022 14:56:56] INFO: Epoch: 8, Step: 8656, Loss: 0.7152482639071267
[16-10-2022 14:56:59] INFO: Epoch: 8, Step: 8664, Loss: 0.7149821777246802
[16-10-2022 14:57:02] INFO: Epoch: 8, Step: 8672, Loss: 0.7147223292175611
[16-10-2022 14:57:04] INFO: Epoch: 8, Step: 8680, Loss: 0.7146320427905358
[16-10-2022 14:57:07] INFO: Epoch: 8, Step: 8688, Loss: 0.7144999011822002
[16-10-2022 14:57:10] INFO: Epoch: 8, Step: 8696, Loss: 0.7142438487005923
[16-10-2022 14:57:13] INFO: Epoch: 8, Step: 8704, Loss: 0.7139905214430475
[16-10-2022 14:57:16] INFO: Epoch: 8, Step: 8712, Loss: 0.7139804155319586
[16-10-2022 14:57:19] INFO: Epoch: 8, Step: 8720, Loss: 0.7136728107352581
[16-10-2022 14:57:22] INFO: Epoch: 8, Step: 8728, Loss: 0.7135550466316689
[16-10-2022 14:57:24] INFO: Epoch: 8, Step: 8736, Loss: 0.7133583003256878
[16-10-2022 14:57:27] INFO: Epoch: 8, Step: 8744, Loss: 0.7131715911501988
[16-10-2022 14:57:30] INFO: Epoch: 8, Step: 8752, Loss: 0.7128948092769741
[16-10-2022 14:57:33] INFO: Epoch: 8, Step: 8760, Loss: 0.7127652671626222
[16-10-2022 14:57:36] INFO: Epoch: 8, Step: 8768, Loss: 0.7127604607546306
[16-10-2022 14:57:39] INFO: Epoch: 8, Step: 8776, Loss: 0.7125841001377323
[16-10-2022 14:57:42] INFO: Epoch: 8, Step: 8784, Loss: 0.7125243919147588
[16-10-2022 14:57:44] INFO: Epoch: 8, Step: 8792, Loss: 0.7123520944248107
[16-10-2022 14:57:47] INFO: Epoch: 8, Step: 8800, Loss: 0.7121517996087926
[16-10-2022 14:57:50] INFO: Epoch: 8, Step: 8808, Loss: 0.7118921037496989
[16-10-2022 14:57:53] INFO: Epoch: 8, Step: 8816, Loss: 0.7117260439771934
[16-10-2022 14:57:56] INFO: Epoch: 8, Step: 8824, Loss: 0.7114173153846873
[16-10-2022 14:57:58] INFO: Epoch: 8, Step: 8832, Loss: 0.7111824056411256
[16-10-2022 14:58:01] INFO: Epoch: 8, Step: 8840, Loss: 0.710978740469321
[16-10-2022 14:58:04] INFO: Epoch: 8, Step: 8848, Loss: 0.7109788108510211
[16-10-2022 14:58:07] INFO: Epoch: 8, Step: 8856, Loss: 0.7108785648714221
[16-10-2022 14:58:10] INFO: Epoch: 8, Step: 8864, Loss: 0.7107503440837203
[16-10-2022 14:58:13] INFO: Epoch: 8, Step: 8872, Loss: 0.710651128265236
[16-10-2022 14:58:16] INFO: Epoch: 8, Step: 8880, Loss: 0.7104081739617077
[16-10-2022 14:58:18] INFO: Epoch: 8, Step: 8888, Loss: 0.7103105945421366
[16-10-2022 14:58:21] INFO: Epoch: 8, Step: 8896, Loss: 0.7101243289724487
[16-10-2022 14:58:24] INFO: Epoch: 8, Step: 8904, Loss: 0.7099666211470506
[16-10-2022 14:58:26] INFO: Start eval!
       F1 (micro): 58.60%
/home/jiahaoran2022/anaconda3/envs/chef/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Precision (macro): 39.16%
   Recall (macro): 58.10%
       F1 (macro): 46.77%
[16-10-2022 14:58:46] INFO: Dev total acc: 0.5859613428280773
[16-10-2022 14:58:47] INFO: Saved best epoch 8, best f1 0.4677064267281124
[16-10-2022 14:58:47] INFO: Epoch: 9, Step: 8912, Loss: 0.7099944902019731
[16-10-2022 14:58:50] INFO: Epoch: 9, Step: 8920, Loss: 0.709755489521255
[16-10-2022 14:58:53] INFO: Epoch: 9, Step: 8928, Loss: 0.709643018188708
[16-10-2022 14:58:56] INFO: Epoch: 9, Step: 8936, Loss: 0.7093660180563744
[16-10-2022 14:58:59] INFO: Epoch: 9, Step: 8944, Loss: 0.709285825016552
[16-10-2022 14:59:02] INFO: Epoch: 9, Step: 8952, Loss: 0.7091157923309489
[16-10-2022 14:59:05] INFO: Epoch: 9, Step: 8960, Loss: 0.7088801342000371
[16-10-2022 14:59:07] INFO: Epoch: 9, Step: 8968, Loss: 0.7086411802323386
[16-10-2022 14:59:10] INFO: Epoch: 9, Step: 8976, Loss: 0.7084082332302847
[16-10-2022 14:59:13] INFO: Epoch: 9, Step: 8984, Loss: 0.7080636136967837
[16-10-2022 14:59:16] INFO: Epoch: 9, Step: 8992, Loss: 0.707908483035291
[16-10-2022 14:59:19] INFO: Epoch: 9, Step: 9000, Loss: 0.7078565455364769
[16-10-2022 14:59:22] INFO: Epoch: 9, Step: 9008, Loss: 0.7076361734411047
[16-10-2022 14:59:25] INFO: Epoch: 9, Step: 9016, Loss: 0.7075325733314402
[16-10-2022 14:59:27] INFO: Epoch: 9, Step: 9024, Loss: 0.7072606951279934
[16-10-2022 14:59:30] INFO: Epoch: 9, Step: 9032, Loss: 0.707015265918125
[16-10-2022 14:59:33] INFO: Epoch: 9, Step: 9040, Loss: 0.7067961113828327
[16-10-2022 14:59:36] INFO: Epoch: 9, Step: 9048, Loss: 0.7065672514952843
[16-10-2022 14:59:39] INFO: Epoch: 9, Step: 9056, Loss: 0.7064046227285236
[16-10-2022 14:59:42] INFO: Epoch: 9, Step: 9064, Loss: 0.7060786934157742
[16-10-2022 14:59:45] INFO: Epoch: 9, Step: 9072, Loss: 0.7058516323991119
[16-10-2022 14:59:47] INFO: Epoch: 9, Step: 9080, Loss: 0.7056999032525225
[16-10-2022 14:59:50] INFO: Epoch: 9, Step: 9088, Loss: 0.7054889306371204
[16-10-2022 14:59:53] INFO: Epoch: 9, Step: 9096, Loss: 0.7052778746157137
[16-10-2022 14:59:56] INFO: Epoch: 9, Step: 9104, Loss: 0.70508687478419
[16-10-2022 14:59:59] INFO: Epoch: 9, Step: 9112, Loss: 0.7049266213115432
[16-10-2022 15:00:02] INFO: Epoch: 9, Step: 9120, Loss: 0.7048661467549884
[16-10-2022 15:00:04] INFO: Epoch: 9, Step: 9128, Loss: 0.704639913574258
[16-10-2022 15:00:07] INFO: Epoch: 9, Step: 9136, Loss: 0.7046262203905841
[16-10-2022 15:00:10] INFO: Epoch: 9, Step: 9144, Loss: 0.7044123255286029
[16-10-2022 15:00:13] INFO: Epoch: 9, Step: 9152, Loss: 0.7043235127751513
[16-10-2022 15:00:16] INFO: Epoch: 9, Step: 9160, Loss: 0.7039927013995266
[16-10-2022 15:00:19] INFO: Epoch: 9, Step: 9168, Loss: 0.7037625018093675
[16-10-2022 15:00:22] INFO: Epoch: 9, Step: 9176, Loss: 0.7036234577082557
[16-10-2022 15:00:24] INFO: Epoch: 9, Step: 9184, Loss: 0.7035373301916265
[16-10-2022 15:00:27] INFO: Epoch: 9, Step: 9192, Loss: 0.7035268398550616
[16-10-2022 15:00:30] INFO: Epoch: 9, Step: 9200, Loss: 0.7032989264696757
[16-10-2022 15:00:33] INFO: Epoch: 9, Step: 9208, Loss: 0.703156083679445
[16-10-2022 15:00:36] INFO: Epoch: 9, Step: 9216, Loss: 0.7028989035748643
[16-10-2022 15:00:39] INFO: Epoch: 9, Step: 9224, Loss: 0.7026266972469822
[16-10-2022 15:00:42] INFO: Epoch: 9, Step: 9232, Loss: 0.7024714062583637
[16-10-2022 15:00:44] INFO: Epoch: 9, Step: 9240, Loss: 0.702244604317262
[16-10-2022 15:00:47] INFO: Epoch: 9, Step: 9248, Loss: 0.7019607116767227
[16-10-2022 15:00:50] INFO: Epoch: 9, Step: 9256, Loss: 0.7017586081201903
[16-10-2022 15:00:53] INFO: Epoch: 9, Step: 9264, Loss: 0.7016670702902814
[16-10-2022 15:00:56] INFO: Epoch: 9, Step: 9272, Loss: 0.7014329836083574
[16-10-2022 15:00:59] INFO: Epoch: 9, Step: 9280, Loss: 0.7012828966261548
[16-10-2022 15:01:02] INFO: Epoch: 9, Step: 9288, Loss: 0.7010894365553425
[16-10-2022 15:01:04] INFO: Epoch: 9, Step: 9296, Loss: 0.7009965892101395
[16-10-2022 15:01:07] INFO: Epoch: 9, Step: 9304, Loss: 0.7007013184838528
[16-10-2022 15:01:10] INFO: Epoch: 9, Step: 9312, Loss: 0.7006440791041477
[16-10-2022 15:01:13] INFO: Epoch: 9, Step: 9320, Loss: 0.7004297245577731
[16-10-2022 15:01:16] INFO: Epoch: 9, Step: 9328, Loss: 0.7002515870431683
[16-10-2022 15:01:19] INFO: Epoch: 9, Step: 9336, Loss: 0.7000961634801381
[16-10-2022 15:01:22] INFO: Epoch: 9, Step: 9344, Loss: 0.6998562475850677
[16-10-2022 15:01:25] INFO: Epoch: 9, Step: 9352, Loss: 0.6996383560583287
[16-10-2022 15:01:27] INFO: Epoch: 9, Step: 9360, Loss: 0.6995288176840236
[16-10-2022 15:01:30] INFO: Epoch: 9, Step: 9368, Loss: 0.6993545627473664
[16-10-2022 15:01:33] INFO: Epoch: 9, Step: 9376, Loss: 0.6992362439406024
[16-10-2022 15:01:36] INFO: Epoch: 9, Step: 9384, Loss: 0.6990019716302655
[16-10-2022 15:01:39] INFO: Epoch: 9, Step: 9392, Loss: 0.6988291775016909
[16-10-2022 15:01:42] INFO: Epoch: 9, Step: 9400, Loss: 0.6986084923778365
[16-10-2022 15:01:45] INFO: Epoch: 9, Step: 9408, Loss: 0.6983500220191264
[16-10-2022 15:01:47] INFO: Epoch: 9, Step: 9416, Loss: 0.6979564264010856
[16-10-2022 15:01:50] INFO: Epoch: 9, Step: 9424, Loss: 0.6978261662273257
[16-10-2022 15:01:53] INFO: Epoch: 9, Step: 9432, Loss: 0.6977200217563282
[16-10-2022 15:01:56] INFO: Epoch: 9, Step: 9440, Loss: 0.6974739832326188
[16-10-2022 15:01:59] INFO: Epoch: 9, Step: 9448, Loss: 0.6973424853546552
[16-10-2022 15:02:02] INFO: Epoch: 9, Step: 9456, Loss: 0.6971767252502656
[16-10-2022 15:02:05] INFO: Epoch: 9, Step: 9464, Loss: 0.6970880914724411
[16-10-2022 15:02:07] INFO: Epoch: 9, Step: 9472, Loss: 0.6968979934302107
[16-10-2022 15:02:10] INFO: Epoch: 9, Step: 9480, Loss: 0.6967521519329527
[16-10-2022 15:02:13] INFO: Epoch: 9, Step: 9488, Loss: 0.6964530175466259
[16-10-2022 15:02:16] INFO: Epoch: 9, Step: 9496, Loss: 0.6961906374112109
[16-10-2022 15:02:19] INFO: Epoch: 9, Step: 9504, Loss: 0.6959268141844507
[16-10-2022 15:02:22] INFO: Epoch: 9, Step: 9512, Loss: 0.6958649526146627
[16-10-2022 15:02:25] INFO: Epoch: 9, Step: 9520, Loss: 0.6956414041442078
[16-10-2022 15:02:27] INFO: Epoch: 9, Step: 9528, Loss: 0.6955344587041413
[16-10-2022 15:02:30] INFO: Epoch: 9, Step: 9536, Loss: 0.695290471042355
[16-10-2022 15:02:33] INFO: Epoch: 9, Step: 9544, Loss: 0.695076265051104
[16-10-2022 15:02:36] INFO: Epoch: 9, Step: 9552, Loss: 0.6949508420891447
[16-10-2022 15:02:39] INFO: Epoch: 9, Step: 9560, Loss: 0.6948537878672746
[16-10-2022 15:02:42] INFO: Epoch: 9, Step: 9568, Loss: 0.6946361852373018
[16-10-2022 15:02:45] INFO: Epoch: 9, Step: 9576, Loss: 0.6945380116252771
[16-10-2022 15:02:48] INFO: Epoch: 9, Step: 9584, Loss: 0.694506168484817
[16-10-2022 15:02:50] INFO: Epoch: 9, Step: 9592, Loss: 0.6944205504935392
[16-10-2022 15:02:53] INFO: Epoch: 9, Step: 9600, Loss: 0.6941255940213724
[16-10-2022 15:02:56] INFO: Epoch: 9, Step: 9608, Loss: 0.6939936824430707
[16-10-2022 15:02:59] INFO: Epoch: 9, Step: 9616, Loss: 0.6938234881436789
[16-10-2022 15:03:02] INFO: Epoch: 9, Step: 9624, Loss: 0.6935612846840274
[16-10-2022 15:03:05] INFO: Epoch: 9, Step: 9632, Loss: 0.6934406590501879
[16-10-2022 15:03:08] INFO: Epoch: 9, Step: 9640, Loss: 0.6932335164239594
[16-10-2022 15:03:10] INFO: Epoch: 9, Step: 9648, Loss: 0.6930172239869733
[16-10-2022 15:03:13] INFO: Epoch: 9, Step: 9656, Loss: 0.6927568245561164
[16-10-2022 15:03:16] INFO: Epoch: 9, Step: 9664, Loss: 0.6924931078356005
[16-10-2022 15:03:19] INFO: Epoch: 9, Step: 9672, Loss: 0.6923289466922838
[16-10-2022 15:03:22] INFO: Epoch: 9, Step: 9680, Loss: 0.6923083089611549
[16-10-2022 15:03:25] INFO: Epoch: 9, Step: 9688, Loss: 0.6919577925429166
[16-10-2022 15:03:28] INFO: Epoch: 9, Step: 9696, Loss: 0.6918880628739338
[16-10-2022 15:03:30] INFO: Epoch: 9, Step: 9704, Loss: 0.6919208693537734
[16-10-2022 15:03:33] INFO: Epoch: 9, Step: 9712, Loss: 0.6918084779313247
[16-10-2022 15:03:36] INFO: Epoch: 9, Step: 9720, Loss: 0.691840555341424
[16-10-2022 15:03:39] INFO: Epoch: 9, Step: 9728, Loss: 0.6917093563254383
[16-10-2022 15:03:42] INFO: Epoch: 9, Step: 9736, Loss: 0.6915520683015969
[16-10-2022 15:03:45] INFO: Epoch: 9, Step: 9744, Loss: 0.6914144503728875
[16-10-2022 15:03:48] INFO: Epoch: 9, Step: 9752, Loss: 0.6911759449469372
[16-10-2022 15:03:51] INFO: Epoch: 9, Step: 9760, Loss: 0.6910185486318805
[16-10-2022 15:03:54] INFO: Epoch: 9, Step: 9768, Loss: 0.6908686881428121
[16-10-2022 15:03:56] INFO: Epoch: 9, Step: 9776, Loss: 0.6908350297262889
[16-10-2022 15:03:59] INFO: Epoch: 9, Step: 9784, Loss: 0.690582006752045
[16-10-2022 15:04:02] INFO: Epoch: 9, Step: 9792, Loss: 0.6904736133197285
[16-10-2022 15:04:05] INFO: Epoch: 9, Step: 9800, Loss: 0.6903265931681637
[16-10-2022 15:04:08] INFO: Epoch: 9, Step: 9808, Loss: 0.6902725206635709
[16-10-2022 15:04:11] INFO: Epoch: 9, Step: 9816, Loss: 0.6901200422732588
[16-10-2022 15:04:14] INFO: Epoch: 9, Step: 9824, Loss: 0.6899971450441701
[16-10-2022 15:04:16] INFO: Epoch: 9, Step: 9832, Loss: 0.6898817380991114
[16-10-2022 15:04:19] INFO: Epoch: 9, Step: 9840, Loss: 0.6898195754066642
[16-10-2022 15:04:22] INFO: Epoch: 9, Step: 9848, Loss: 0.6896053516324218
[16-10-2022 15:04:25] INFO: Epoch: 9, Step: 9856, Loss: 0.6894532912195429
[16-10-2022 15:04:28] INFO: Epoch: 9, Step: 9864, Loss: 0.6893543301362528
[16-10-2022 15:04:31] INFO: Epoch: 9, Step: 9872, Loss: 0.6891788697512551
[16-10-2022 15:04:34] INFO: Epoch: 9, Step: 9880, Loss: 0.6889792585342084
[16-10-2022 15:04:36] INFO: Epoch: 9, Step: 9888, Loss: 0.6888341600370059
[16-10-2022 15:04:39] INFO: Epoch: 9, Step: 9896, Loss: 0.6887371167491689
[16-10-2022 15:04:41] INFO: Start eval!
       F1 (micro): 59.00%
Precision (macro): 72.57%
   Recall (macro): 58.51%
       F1 (macro): 47.07%
[16-10-2022 15:05:00] INFO: Dev total acc: 0.590030518819939
[16-10-2022 15:05:01] INFO: Saved best epoch 9, best f1 0.47072711812499035
[16-10-2022 15:05:03] INFO: Epoch: 10, Step: 9904, Loss: 0.6885240437362949
[16-10-2022 15:05:05] INFO: Epoch: 10, Step: 9912, Loss: 0.6882780842341054
[16-10-2022 15:05:08] INFO: Epoch: 10, Step: 9920, Loss: 0.6882042037740036
[16-10-2022 15:05:11] INFO: Epoch: 10, Step: 9928, Loss: 0.6880836048543284
[16-10-2022 15:05:14] INFO: Epoch: 10, Step: 9936, Loss: 0.6880439346241609
[16-10-2022 15:05:17] INFO: Epoch: 10, Step: 9944, Loss: 0.6879133177094826
[16-10-2022 15:05:20] INFO: Epoch: 10, Step: 9952, Loss: 0.687747718005335
[16-10-2022 15:05:23] INFO: Epoch: 10, Step: 9960, Loss: 0.6877371659356594
[16-10-2022 15:05:25] INFO: Epoch: 10, Step: 9968, Loss: 0.6876898373953363
[16-10-2022 15:05:28] INFO: Epoch: 10, Step: 9976, Loss: 0.6875343968880491
[16-10-2022 15:05:31] INFO: Epoch: 10, Step: 9984, Loss: 0.6873375454254208
[16-10-2022 15:05:34] INFO: Epoch: 10, Step: 9992, Loss: 0.6871361930987422
[16-10-2022 15:05:37] INFO: Epoch: 10, Step: 10000, Loss: 0.6869487693827676
[16-10-2022 15:05:40] INFO: Epoch: 10, Step: 10008, Loss: 0.6867166509316621
[16-10-2022 15:05:43] INFO: Epoch: 10, Step: 10016, Loss: 0.6865416610990682
[16-10-2022 15:05:45] INFO: Epoch: 10, Step: 10024, Loss: 0.6861967326220757
[16-10-2022 15:05:48] INFO: Epoch: 10, Step: 10032, Loss: 0.6859546436611164
[16-10-2022 15:05:51] INFO: Epoch: 10, Step: 10040, Loss: 0.6857349713496287
[16-10-2022 15:05:54] INFO: Epoch: 10, Step: 10048, Loss: 0.68554569062352
[16-10-2022 15:05:57] INFO: Epoch: 10, Step: 10056, Loss: 0.6853664610375687
[16-10-2022 15:06:00] INFO: Epoch: 10, Step: 10064, Loss: 0.6851724754957579
[16-10-2022 15:06:03] INFO: Epoch: 10, Step: 10072, Loss: 0.6850916668598936
[16-10-2022 15:06:05] INFO: Epoch: 10, Step: 10080, Loss: 0.6849984466397678
[16-10-2022 15:06:08] INFO: Epoch: 10, Step: 10088, Loss: 0.6849313390021813
[16-10-2022 15:06:11] INFO: Epoch: 10, Step: 10096, Loss: 0.684697001772127
[16-10-2022 15:06:14] INFO: Epoch: 10, Step: 10104, Loss: 0.6845091320961488
[16-10-2022 15:06:17] INFO: Epoch: 10, Step: 10112, Loss: 0.684317817933249
[16-10-2022 15:06:20] INFO: Epoch: 10, Step: 10120, Loss: 0.6840446651420031
[16-10-2022 15:06:23] INFO: Epoch: 10, Step: 10128, Loss: 0.6837789406532888
[16-10-2022 15:06:26] INFO: Epoch: 10, Step: 10136, Loss: 0.6835047855459512
[16-10-2022 15:06:28] INFO: Epoch: 10, Step: 10144, Loss: 0.6832351963610936
[16-10-2022 15:06:31] INFO: Epoch: 10, Step: 10152, Loss: 0.6832593552415298
[16-10-2022 15:06:34] INFO: Epoch: 10, Step: 10160, Loss: 0.6831350443609808
[16-10-2022 15:06:37] INFO: Epoch: 10, Step: 10168, Loss: 0.6829189553437061
[16-10-2022 15:06:40] INFO: Epoch: 10, Step: 10176, Loss: 0.6826606366359528
[16-10-2022 15:06:43] INFO: Epoch: 10, Step: 10184, Loss: 0.6825699554584433
[16-10-2022 15:06:46] INFO: Epoch: 10, Step: 10192, Loss: 0.6824028555042913
[16-10-2022 15:06:48] INFO: Epoch: 10, Step: 10200, Loss: 0.6821954857452172
[16-10-2022 15:06:51] INFO: Epoch: 10, Step: 10208, Loss: 0.6820491526343827
[16-10-2022 15:06:54] INFO: Epoch: 10, Step: 10216, Loss: 0.6819074028230018
[16-10-2022 15:06:57] INFO: Epoch: 10, Step: 10224, Loss: 0.6816652789336729
[16-10-2022 15:07:00] INFO: Epoch: 10, Step: 10232, Loss: 0.6813400769544413
[16-10-2022 15:07:03] INFO: Epoch: 10, Step: 10240, Loss: 0.68131880177062
[16-10-2022 15:07:06] INFO: Epoch: 10, Step: 10248, Loss: 0.6810672543437719
[16-10-2022 15:07:09] INFO: Epoch: 10, Step: 10256, Loss: 0.6808750039375608
[16-10-2022 15:07:11] INFO: Epoch: 10, Step: 10264, Loss: 0.6807707207511956
[16-10-2022 15:07:14] INFO: Epoch: 10, Step: 10272, Loss: 0.6805771345528776
[16-10-2022 15:07:17] INFO: Epoch: 10, Step: 10280, Loss: 0.6802756495320889
[16-10-2022 15:07:20] INFO: Epoch: 10, Step: 10288, Loss: 0.6800313557575721
[16-10-2022 15:07:23] INFO: Epoch: 10, Step: 10296, Loss: 0.6798112441549802
[16-10-2022 15:07:26] INFO: Epoch: 10, Step: 10304, Loss: 0.679588663458661
[16-10-2022 15:07:29] INFO: Epoch: 10, Step: 10312, Loss: 0.6793481395919531
[16-10-2022 15:07:32] INFO: Epoch: 10, Step: 10320, Loss: 0.6792358399321969
[16-10-2022 15:07:34] INFO: Epoch: 10, Step: 10328, Loss: 0.6792080136016807
[16-10-2022 15:07:37] INFO: Epoch: 10, Step: 10336, Loss: 0.6790021391136462
[16-10-2022 15:07:40] INFO: Epoch: 10, Step: 10344, Loss: 0.6788777695037499
[16-10-2022 15:07:43] INFO: Epoch: 10, Step: 10352, Loss: 0.6786087094867385
[16-10-2022 15:07:46] INFO: Epoch: 10, Step: 10360, Loss: 0.6785746118258831
[16-10-2022 15:07:49] INFO: Epoch: 10, Step: 10368, Loss: 0.6783369349730476
[16-10-2022 15:07:52] INFO: Epoch: 10, Step: 10376, Loss: 0.6781062667578411
[16-10-2022 15:07:54] INFO: Epoch: 10, Step: 10384, Loss: 0.6780072194814772
[16-10-2022 15:07:57] INFO: Epoch: 10, Step: 10392, Loss: 0.6779331684430233
[16-10-2022 15:08:00] INFO: Epoch: 10, Step: 10400, Loss: 0.6776506972266435
[16-10-2022 15:08:03] INFO: Epoch: 10, Step: 10408, Loss: 0.6773895023474479
[16-10-2022 15:08:06] INFO: Epoch: 10, Step: 10416, Loss: 0.6772704252242949
[16-10-2022 15:08:09] INFO: Epoch: 10, Step: 10424, Loss: 0.6772483839297558
[16-10-2022 15:08:12] INFO: Epoch: 10, Step: 10432, Loss: 0.6770526704366358
[16-10-2022 15:08:14] INFO: Epoch: 10, Step: 10440, Loss: 0.6767486230420358
[16-10-2022 15:08:17] INFO: Epoch: 10, Step: 10448, Loss: 0.6765014245920099
[16-10-2022 15:08:20] INFO: Epoch: 10, Step: 10456, Loss: 0.6763277139437088
[16-10-2022 15:08:23] INFO: Epoch: 10, Step: 10464, Loss: 0.6761468585494506
[16-10-2022 15:08:26] INFO: Epoch: 10, Step: 10472, Loss: 0.6759120425927355
[16-10-2022 15:08:29] INFO: Epoch: 10, Step: 10480, Loss: 0.6757749105522923
[16-10-2022 15:08:31] INFO: Epoch: 10, Step: 10488, Loss: 0.6754539042471929
[16-10-2022 15:08:34] INFO: Epoch: 10, Step: 10496, Loss: 0.6752481477944929
[16-10-2022 15:08:37] INFO: Epoch: 10, Step: 10504, Loss: 0.6749828461190986
[16-10-2022 15:08:40] INFO: Epoch: 10, Step: 10512, Loss: 0.6748108756179247
[16-10-2022 15:08:43] INFO: Epoch: 10, Step: 10520, Loss: 0.6748555862380285
[16-10-2022 15:08:46] INFO: Epoch: 10, Step: 10528, Loss: 0.6747135203448551
[16-10-2022 15:08:49] INFO: Epoch: 10, Step: 10536, Loss: 0.674576557355593
[16-10-2022 15:08:52] INFO: Epoch: 10, Step: 10544, Loss: 0.6744710464834002
[16-10-2022 15:08:54] INFO: Epoch: 10, Step: 10552, Loss: 0.6743632591445385
[16-10-2022 15:08:57] INFO: Epoch: 10, Step: 10560, Loss: 0.6742408073934177
[16-10-2022 15:09:00] INFO: Epoch: 10, Step: 10568, Loss: 0.6741172395971655
[16-10-2022 15:09:03] INFO: Epoch: 10, Step: 10576, Loss: 0.6739366582518096
[16-10-2022 15:09:06] INFO: Epoch: 10, Step: 10584, Loss: 0.6737355823172518
[16-10-2022 15:09:09] INFO: Epoch: 10, Step: 10592, Loss: 0.6736501660919046
[16-10-2022 15:09:12] INFO: Epoch: 10, Step: 10600, Loss: 0.6734560102171706
[16-10-2022 15:09:14] INFO: Epoch: 10, Step: 10608, Loss: 0.6733172646113413
[16-10-2022 15:09:17] INFO: Epoch: 10, Step: 10616, Loss: 0.6730702770603774
[16-10-2022 15:09:20] INFO: Epoch: 10, Step: 10624, Loss: 0.6728719719808413
[16-10-2022 15:09:23] INFO: Epoch: 10, Step: 10632, Loss: 0.6726477127672967
[16-10-2022 15:09:26] INFO: Epoch: 10, Step: 10640, Loss: 0.67252691622257
[16-10-2022 15:09:29] INFO: Epoch: 10, Step: 10648, Loss: 0.6725618794254729
[16-10-2022 15:09:32] INFO: Epoch: 10, Step: 10656, Loss: 0.6722788589873057
[16-10-2022 15:09:34] INFO: Epoch: 10, Step: 10664, Loss: 0.6719916463244165
[16-10-2022 15:09:37] INFO: Epoch: 10, Step: 10672, Loss: 0.6717961968814348
[16-10-2022 15:09:40] INFO: Epoch: 10, Step: 10680, Loss: 0.6715401253907242
[16-10-2022 15:09:43] INFO: Epoch: 10, Step: 10688, Loss: 0.6714409186018976
[16-10-2022 15:09:46] INFO: Epoch: 10, Step: 10696, Loss: 0.671312145813234
[16-10-2022 15:09:49] INFO: Epoch: 10, Step: 10704, Loss: 0.6713719851729324
[16-10-2022 15:09:52] INFO: Epoch: 10, Step: 10712, Loss: 0.6711132124951842
[16-10-2022 15:09:54] INFO: Epoch: 10, Step: 10720, Loss: 0.6710523236970447
[16-10-2022 15:09:57] INFO: Epoch: 10, Step: 10728, Loss: 0.6708126446391312
[16-10-2022 15:10:00] INFO: Epoch: 10, Step: 10736, Loss: 0.6706621082282478
[16-10-2022 15:10:03] INFO: Epoch: 10, Step: 10744, Loss: 0.6704541309514832
[16-10-2022 15:10:06] INFO: Epoch: 10, Step: 10752, Loss: 0.6702249335347596
[16-10-2022 15:10:09] INFO: Epoch: 10, Step: 10760, Loss: 0.6700276802508681
[16-10-2022 15:10:12] INFO: Epoch: 10, Step: 10768, Loss: 0.6698848457358721
[16-10-2022 15:10:14] INFO: Epoch: 10, Step: 10776, Loss: 0.6698031725459502
[16-10-2022 15:10:17] INFO: Epoch: 10, Step: 10784, Loss: 0.6696126733402977
[16-10-2022 15:10:20] INFO: Epoch: 10, Step: 10792, Loss: 0.6696155675627594
[16-10-2022 15:10:23] INFO: Epoch: 10, Step: 10800, Loss: 0.6694306661385285
[16-10-2022 15:10:26] INFO: Epoch: 10, Step: 10808, Loss: 0.6692334197383778
[16-10-2022 15:10:29] INFO: Epoch: 10, Step: 10816, Loss: 0.6688943573576194
[16-10-2022 15:10:32] INFO: Epoch: 10, Step: 10824, Loss: 0.6689756895809286
[16-10-2022 15:10:34] INFO: Epoch: 10, Step: 10832, Loss: 0.6687470526614075
[16-10-2022 15:10:37] INFO: Epoch: 10, Step: 10840, Loss: 0.668529603279433
[16-10-2022 15:10:40] INFO: Epoch: 10, Step: 10848, Loss: 0.6682653521887539
[16-10-2022 15:10:43] INFO: Epoch: 10, Step: 10856, Loss: 0.6681831182432332
[16-10-2022 15:10:46] INFO: Epoch: 10, Step: 10864, Loss: 0.6680808052779362
[16-10-2022 15:10:49] INFO: Epoch: 10, Step: 10872, Loss: 0.6678431488459177
[16-10-2022 15:10:52] INFO: Epoch: 10, Step: 10880, Loss: 0.6677208682922854
[16-10-2022 15:10:54] INFO: Epoch: 10, Step: 10888, Loss: 0.6676414444413815
[16-10-2022 15:10:55] INFO: Start eval!
       F1 (micro): 59.21%
Precision (macro): 72.66%
   Recall (macro): 58.71%
       F1 (macro): 47.59%
[16-10-2022 15:11:15] INFO: Dev total acc: 0.5920651068158698
[16-10-2022 15:11:16] INFO: Saved best epoch 10, best f1 0.47590473583356147
[16-10-2022 15:11:18] INFO: Epoch: 11, Step: 10896, Loss: 0.667333490169093
[16-10-2022 15:11:21] INFO: Epoch: 11, Step: 10904, Loss: 0.6672232648728845
[16-10-2022 15:11:24] INFO: Epoch: 11, Step: 10912, Loss: 0.6670794378979136
[16-10-2022 15:11:27] INFO: Epoch: 11, Step: 10920, Loss: 0.6667977243153647
[16-10-2022 15:11:29] INFO: Epoch: 11, Step: 10928, Loss: 0.6668026888832427
[16-10-2022 15:11:32] INFO: Epoch: 11, Step: 10936, Loss: 0.6665857199783253
[16-10-2022 15:11:35] INFO: Epoch: 11, Step: 10944, Loss: 0.6664613596519814
[16-10-2022 15:11:38] INFO: Epoch: 11, Step: 10952, Loss: 0.666482790600831
[16-10-2022 15:11:41] INFO: Epoch: 11, Step: 10960, Loss: 0.666304961840432
[16-10-2022 15:11:44] INFO: Epoch: 11, Step: 10968, Loss: 0.66614844022458
[16-10-2022 15:11:47] INFO: Epoch: 11, Step: 10976, Loss: 0.6659391069246536
[16-10-2022 15:11:50] INFO: Epoch: 11, Step: 10984, Loss: 0.6658276931338016
[16-10-2022 15:11:52] INFO: Epoch: 11, Step: 10992, Loss: 0.6656003720808323
[16-10-2022 15:11:55] INFO: Epoch: 11, Step: 11000, Loss: 0.6654059285707842
[16-10-2022 15:11:58] INFO: Epoch: 11, Step: 11008, Loss: 0.6652675531002583
[16-10-2022 15:12:01] INFO: Epoch: 11, Step: 11016, Loss: 0.6651754372979171
[16-10-2022 15:12:04] INFO: Epoch: 11, Step: 11024, Loss: 0.6651719288859337
[16-10-2022 15:12:07] INFO: Epoch: 11, Step: 11032, Loss: 0.6649797919666987
[16-10-2022 15:12:10] INFO: Epoch: 11, Step: 11040, Loss: 0.6648112386542752
[16-10-2022 15:12:13] INFO: Epoch: 11, Step: 11048, Loss: 0.6646579975241448
[16-10-2022 15:12:15] INFO: Epoch: 11, Step: 11056, Loss: 0.6644443048406246
[16-10-2022 15:12:18] INFO: Epoch: 11, Step: 11064, Loss: 0.6642080517186141
[16-10-2022 15:12:21] INFO: Epoch: 11, Step: 11072, Loss: 0.6640753957831284
[16-10-2022 15:12:24] INFO: Epoch: 11, Step: 11080, Loss: 0.6638093935288827
[16-10-2022 15:12:27] INFO: Epoch: 11, Step: 11088, Loss: 0.6635286248504814
[16-10-2022 15:12:30] INFO: Epoch: 11, Step: 11096, Loss: 0.663282755903689
[16-10-2022 15:12:33] INFO: Epoch: 11, Step: 11104, Loss: 0.6630724888373509
[16-10-2022 15:12:36] INFO: Epoch: 11, Step: 11112, Loss: 0.6628698704846787
[16-10-2022 15:12:38] INFO: Epoch: 11, Step: 11120, Loss: 0.6627930990524203
[16-10-2022 15:12:41] INFO: Epoch: 11, Step: 11128, Loss: 0.6625308670263638
[16-10-2022 15:12:44] INFO: Epoch: 11, Step: 11136, Loss: 0.6622646392711865
[16-10-2022 15:12:47] INFO: Epoch: 11, Step: 11144, Loss: 0.6621115396848339
[16-10-2022 15:12:50] INFO: Epoch: 11, Step: 11152, Loss: 0.662033468582093
[16-10-2022 15:12:53] INFO: Epoch: 11, Step: 11160, Loss: 0.6617583435926802
[16-10-2022 15:12:56] INFO: Epoch: 11, Step: 11168, Loss: 0.6615447239929686
[16-10-2022 15:12:59] INFO: Epoch: 11, Step: 11176, Loss: 0.6613807443222106
[16-10-2022 15:13:01] INFO: Epoch: 11, Step: 11184, Loss: 0.6611466201316122
[16-10-2022 15:13:04] INFO: Epoch: 11, Step: 11192, Loss: 0.6609729784627442
[16-10-2022 15:13:07] INFO: Epoch: 11, Step: 11200, Loss: 0.6607398641412214
[16-10-2022 15:13:10] INFO: Epoch: 11, Step: 11208, Loss: 0.6605908246514862
[16-10-2022 15:13:13] INFO: Epoch: 11, Step: 11216, Loss: 0.6604640272843949
[16-10-2022 15:13:16] INFO: Epoch: 11, Step: 11224, Loss: 0.6602603402430245
[16-10-2022 15:13:19] INFO: Epoch: 11, Step: 11232, Loss: 0.6601231975240192
[16-10-2022 15:13:21] INFO: Epoch: 11, Step: 11240, Loss: 0.6600208929640531
[16-10-2022 15:13:24] INFO: Epoch: 11, Step: 11248, Loss: 0.6599656186609134
[16-10-2022 15:13:27] INFO: Epoch: 11, Step: 11256, Loss: 0.6597754784625465
[16-10-2022 15:13:30] INFO: Epoch: 11, Step: 11264, Loss: 0.6596313498094772
[16-10-2022 15:13:33] INFO: Epoch: 11, Step: 11272, Loss: 0.659366242643426
[16-10-2022 15:13:36] INFO: Epoch: 11, Step: 11280, Loss: 0.6591742467297085
[16-10-2022 15:13:39] INFO: Epoch: 11, Step: 11288, Loss: 0.6589153485335107
[16-10-2022 15:13:42] INFO: Epoch: 11, Step: 11296, Loss: 0.6586821734217372
[16-10-2022 15:13:44] INFO: Epoch: 11, Step: 11304, Loss: 0.6585386603736563
[16-10-2022 15:13:47] INFO: Epoch: 11, Step: 11312, Loss: 0.6583730471817794
[16-10-2022 15:13:50] INFO: Epoch: 11, Step: 11320, Loss: 0.6583344189947137
[16-10-2022 15:13:53] INFO: Epoch: 11, Step: 11328, Loss: 0.6580967220999394
[16-10-2022 15:13:56] INFO: Epoch: 11, Step: 11336, Loss: 0.6579745981330349
[16-10-2022 15:13:59] INFO: Epoch: 11, Step: 11344, Loss: 0.6577934951266033
[16-10-2022 15:14:02] INFO: Epoch: 11, Step: 11352, Loss: 0.657696095595525
[16-10-2022 15:14:04] INFO: Epoch: 11, Step: 11360, Loss: 0.6575847070083798
[16-10-2022 15:14:07] INFO: Epoch: 11, Step: 11368, Loss: 0.6575339877323291
[16-10-2022 15:14:10] INFO: Epoch: 11, Step: 11376, Loss: 0.6574352600395029
[16-10-2022 15:14:13] INFO: Epoch: 11, Step: 11384, Loss: 0.6573134911049012
[16-10-2022 15:14:16] INFO: Epoch: 11, Step: 11392, Loss: 0.6573208851901374
[16-10-2022 15:14:19] INFO: Epoch: 11, Step: 11400, Loss: 0.657021542614692
[16-10-2022 15:14:22] INFO: Epoch: 11, Step: 11408, Loss: 0.6568028214808913
[16-10-2022 15:14:24] INFO: Epoch: 11, Step: 11416, Loss: 0.6565921306026058
[16-10-2022 15:14:27] INFO: Epoch: 11, Step: 11424, Loss: 0.6565647032780442
[16-10-2022 15:14:30] INFO: Epoch: 11, Step: 11432, Loss: 0.6565232335497347
[16-10-2022 15:14:33] INFO: Epoch: 11, Step: 11440, Loss: 0.6563053914603121
[16-10-2022 15:14:36] INFO: Epoch: 11, Step: 11448, Loss: 0.6561363658934227
[16-10-2022 15:14:39] INFO: Epoch: 11, Step: 11456, Loss: 0.6559798224349885
[16-10-2022 15:14:42] INFO: Epoch: 11, Step: 11464, Loss: 0.6559296341288696
[16-10-2022 15:14:45] INFO: Epoch: 11, Step: 11472, Loss: 0.6555972067698399
[16-10-2022 15:14:47] INFO: Epoch: 11, Step: 11480, Loss: 0.6553691978637806
[16-10-2022 15:14:50] INFO: Epoch: 11, Step: 11488, Loss: 0.6553219996628218
[16-10-2022 15:14:53] INFO: Epoch: 11, Step: 11496, Loss: 0.6551314995801771
[16-10-2022 15:14:56] INFO: Epoch: 11, Step: 11504, Loss: 0.6549081576541935
[16-10-2022 15:14:59] INFO: Epoch: 11, Step: 11512, Loss: 0.6547481877476308
[16-10-2022 15:15:02] INFO: Epoch: 11, Step: 11520, Loss: 0.6545422305104053
[16-10-2022 15:15:05] INFO: Epoch: 11, Step: 11528, Loss: 0.6542400171942196
[16-10-2022 15:15:07] INFO: Epoch: 11, Step: 11536, Loss: 0.6540433929748151
[16-10-2022 15:15:10] INFO: Epoch: 11, Step: 11544, Loss: 0.6539583077092159
[16-10-2022 15:15:13] INFO: Epoch: 11, Step: 11552, Loss: 0.6537402450585019
[16-10-2022 15:15:16] INFO: Epoch: 11, Step: 11560, Loss: 0.6535991819346693
[16-10-2022 15:15:19] INFO: Epoch: 11, Step: 11568, Loss: 0.6534228506655901
[16-10-2022 15:15:22] INFO: Epoch: 11, Step: 11576, Loss: 0.6531510831664029
[16-10-2022 15:15:25] INFO: Epoch: 11, Step: 11584, Loss: 0.6529552405825574
[16-10-2022 15:15:27] INFO: Epoch: 11, Step: 11592, Loss: 0.652797874721099
[16-10-2022 15:15:30] INFO: Epoch: 11, Step: 11600, Loss: 0.6526473165370975
[16-10-2022 15:15:33] INFO: Epoch: 11, Step: 11608, Loss: 0.6524687602626371
[16-10-2022 15:15:36] INFO: Epoch: 11, Step: 11616, Loss: 0.6523697992569394
[16-10-2022 15:15:39] INFO: Epoch: 11, Step: 11624, Loss: 0.6521804431663009
[16-10-2022 15:15:42] INFO: Epoch: 11, Step: 11632, Loss: 0.6518830398582577
[16-10-2022 15:15:45] INFO: Epoch: 11, Step: 11640, Loss: 0.6517659091243515
[16-10-2022 15:15:47] INFO: Epoch: 11, Step: 11648, Loss: 0.6515407774845015
[16-10-2022 15:15:50] INFO: Epoch: 11, Step: 11656, Loss: 0.6514405367628199
[16-10-2022 15:15:53] INFO: Epoch: 11, Step: 11664, Loss: 0.6513785464949179
[16-10-2022 15:15:56] INFO: Epoch: 11, Step: 11672, Loss: 0.6513400186102896
[16-10-2022 15:15:59] INFO: Epoch: 11, Step: 11680, Loss: 0.6512725069669255
[16-10-2022 15:16:02] INFO: Epoch: 11, Step: 11688, Loss: 0.6511265822083288
[16-10-2022 15:16:05] INFO: Epoch: 11, Step: 11696, Loss: 0.6510487424184935
[16-10-2022 15:16:08] INFO: Epoch: 11, Step: 11704, Loss: 0.650900307501993
[16-10-2022 15:16:11] INFO: Epoch: 11, Step: 11712, Loss: 0.6507879234236588
[16-10-2022 15:16:13] INFO: Epoch: 11, Step: 11720, Loss: 0.6506272383177331
[16-10-2022 15:16:16] INFO: Epoch: 11, Step: 11728, Loss: 0.6504558828417378
[16-10-2022 15:16:19] INFO: Epoch: 11, Step: 11736, Loss: 0.6503398316676254
[16-10-2022 15:16:22] INFO: Epoch: 11, Step: 11744, Loss: 0.6502486383348987
[16-10-2022 15:16:25] INFO: Epoch: 11, Step: 11752, Loss: 0.6500666537087595
[16-10-2022 15:16:28] INFO: Epoch: 11, Step: 11760, Loss: 0.6498793610742343
[16-10-2022 15:16:31] INFO: Epoch: 11, Step: 11768, Loss: 0.6496691995573927
[16-10-2022 15:16:34] INFO: Epoch: 11, Step: 11776, Loss: 0.6496837502937075
[16-10-2022 15:16:36] INFO: Epoch: 11, Step: 11784, Loss: 0.6495265055929034
[16-10-2022 15:16:39] INFO: Epoch: 11, Step: 11792, Loss: 0.6494115598305867
[16-10-2022 15:16:42] INFO: Epoch: 11, Step: 11800, Loss: 0.6492574487080451
[16-10-2022 15:16:45] INFO: Epoch: 11, Step: 11808, Loss: 0.6491446146191993
[16-10-2022 15:16:48] INFO: Epoch: 11, Step: 11816, Loss: 0.6489391744407381
[16-10-2022 15:16:51] INFO: Epoch: 11, Step: 11824, Loss: 0.6487521272671318
[16-10-2022 15:16:53] INFO: Epoch: 11, Step: 11832, Loss: 0.648620762853141
[16-10-2022 15:16:56] INFO: Epoch: 11, Step: 11840, Loss: 0.6484420518217849
[16-10-2022 15:16:59] INFO: Epoch: 11, Step: 11848, Loss: 0.648353214843229
[16-10-2022 15:17:02] INFO: Epoch: 11, Step: 11856, Loss: 0.6481641307313
[16-10-2022 15:17:05] INFO: Epoch: 11, Step: 11864, Loss: 0.6480579101355008
[16-10-2022 15:17:08] INFO: Epoch: 11, Step: 11872, Loss: 0.6479357461908877
[16-10-2022 15:17:11] INFO: Epoch: 11, Step: 11880, Loss: 0.647715315332812
[16-10-2022 15:17:11] INFO: Start eval!
       F1 (micro): 60.33%
Precision (macro): 73.43%
   Recall (macro): 59.82%
       F1 (macro): 48.70%
[16-10-2022 15:17:30] INFO: Dev total acc: 0.6032553407934893
[16-10-2022 15:17:31] INFO: Saved best epoch 11, best f1 0.48695000014279227
[16-10-2022 15:17:34] INFO: Epoch: 12, Step: 11888, Loss: 0.6474337040507556
[16-10-2022 15:17:37] INFO: Epoch: 12, Step: 11896, Loss: 0.6472930969284046
[16-10-2022 15:17:40] INFO: Epoch: 12, Step: 11904, Loss: 0.6472363746127363
[16-10-2022 15:17:42] INFO: Epoch: 12, Step: 11912, Loss: 0.6470586495055607
[16-10-2022 15:17:45] INFO: Epoch: 12, Step: 11920, Loss: 0.6468487036461387
[16-10-2022 15:17:48] INFO: Epoch: 12, Step: 11928, Loss: 0.6466764399896194
[16-10-2022 15:17:51] INFO: Epoch: 12, Step: 11936, Loss: 0.6464275328536774
[16-10-2022 15:17:54] INFO: Epoch: 12, Step: 11944, Loss: 0.6461545392002024
[16-10-2022 15:17:57] INFO: Epoch: 12, Step: 11952, Loss: 0.6459484569035868
[16-10-2022 15:18:00] INFO: Epoch: 12, Step: 11960, Loss: 0.6456978012253298
[16-10-2022 15:18:02] INFO: Epoch: 12, Step: 11968, Loss: 0.645554592690056
[16-10-2022 15:18:05] INFO: Epoch: 12, Step: 11976, Loss: 0.6453695992700341
[16-10-2022 15:18:08] INFO: Epoch: 12, Step: 11984, Loss: 0.6452836561373042
[16-10-2022 15:18:11] INFO: Epoch: 12, Step: 11992, Loss: 0.6451779735644969
[16-10-2022 15:18:14] INFO: Epoch: 12, Step: 12000, Loss: 0.6449555234632829
[16-10-2022 15:18:17] INFO: Epoch: 12, Step: 12008, Loss: 0.644820785286131
[16-10-2022 15:18:20] INFO: Epoch: 12, Step: 12016, Loss: 0.6445850975561663
[16-10-2022 15:18:23] INFO: Epoch: 12, Step: 12024, Loss: 0.6443890938426958
[16-10-2022 15:18:25] INFO: Epoch: 12, Step: 12032, Loss: 0.6442878431825779
[16-10-2022 15:18:28] INFO: Epoch: 12, Step: 12040, Loss: 0.6442746311509767
[16-10-2022 15:18:31] INFO: Epoch: 12, Step: 12048, Loss: 0.6441196389474746
[16-10-2022 15:18:34] INFO: Epoch: 12, Step: 12056, Loss: 0.643923293860041
[16-10-2022 15:18:37] INFO: Epoch: 12, Step: 12064, Loss: 0.6437921815416628
[16-10-2022 15:18:40] INFO: Epoch: 12, Step: 12072, Loss: 0.6436004012004172
[16-10-2022 15:18:43] INFO: Epoch: 12, Step: 12080, Loss: 0.6435752767542231
[16-10-2022 15:18:46] INFO: Epoch: 12, Step: 12088, Loss: 0.6434189207993096
[16-10-2022 15:18:49] INFO: Epoch: 12, Step: 12096, Loss: 0.6431955121997832
[16-10-2022 15:18:51] INFO: Epoch: 12, Step: 12104, Loss: 0.6431540974442986
[16-10-2022 15:18:54] INFO: Epoch: 12, Step: 12112, Loss: 0.6429137446105057
[16-10-2022 15:18:57] INFO: Epoch: 12, Step: 12120, Loss: 0.6428842449152026
[16-10-2022 15:19:00] INFO: Epoch: 12, Step: 12128, Loss: 0.6427503221113627
[16-10-2022 15:19:03] INFO: Epoch: 12, Step: 12136, Loss: 0.6425802585025533
[16-10-2022 15:19:06] INFO: Epoch: 12, Step: 12144, Loss: 0.6423081489336987
[16-10-2022 15:19:09] INFO: Epoch: 12, Step: 12152, Loss: 0.642202050239651
[16-10-2022 15:19:12] INFO: Epoch: 12, Step: 12160, Loss: 0.6422027905793359
[16-10-2022 15:19:14] INFO: Epoch: 12, Step: 12168, Loss: 0.642026956277348
[16-10-2022 15:19:17] INFO: Epoch: 12, Step: 12176, Loss: 0.6417763693072821
[16-10-2022 15:19:20] INFO: Epoch: 12, Step: 12184, Loss: 0.6416049102729204
[16-10-2022 15:19:23] INFO: Epoch: 12, Step: 12192, Loss: 0.6414530819989046
[16-10-2022 15:19:26] INFO: Epoch: 12, Step: 12200, Loss: 0.6412578749036876
[16-10-2022 15:19:29] INFO: Epoch: 12, Step: 12208, Loss: 0.64121632578632
[16-10-2022 15:19:32] INFO: Epoch: 12, Step: 12216, Loss: 0.6411650662362935
[16-10-2022 15:19:35] INFO: Epoch: 12, Step: 12224, Loss: 0.6410346060149624
[16-10-2022 15:19:37] INFO: Epoch: 12, Step: 12232, Loss: 0.6408622374577282
[16-10-2022 15:19:40] INFO: Epoch: 12, Step: 12240, Loss: 0.6406690552565971
[16-10-2022 15:19:43] INFO: Epoch: 12, Step: 12248, Loss: 0.6405750130580655
[16-10-2022 15:19:46] INFO: Epoch: 12, Step: 12256, Loss: 0.6404622068927216
[16-10-2022 15:19:49] INFO: Epoch: 12, Step: 12264, Loss: 0.6404993704311243
[16-10-2022 15:19:52] INFO: Epoch: 12, Step: 12272, Loss: 0.6403461665196244
[16-10-2022 15:19:55] INFO: Epoch: 12, Step: 12280, Loss: 0.6401869338172693
[16-10-2022 15:19:57] INFO: Epoch: 12, Step: 12288, Loss: 0.63996338430207
[16-10-2022 15:20:00] INFO: Epoch: 12, Step: 12296, Loss: 0.6397608458416001
[16-10-2022 15:20:03] INFO: Epoch: 12, Step: 12304, Loss: 0.6395321438977404
[16-10-2022 15:20:06] INFO: Epoch: 12, Step: 12312, Loss: 0.6393916644316405
[16-10-2022 15:20:09] INFO: Epoch: 12, Step: 12320, Loss: 0.6391507902802575
[16-10-2022 15:20:12] INFO: Epoch: 12, Step: 12328, Loss: 0.6390267667683396
[16-10-2022 15:20:15] INFO: Epoch: 12, Step: 12336, Loss: 0.6388253547458448
[16-10-2022 15:20:18] INFO: Epoch: 12, Step: 12344, Loss: 0.6385773044035543
[16-10-2022 15:20:20] INFO: Epoch: 12, Step: 12352, Loss: 0.6385091102131405
[16-10-2022 15:20:23] INFO: Epoch: 12, Step: 12360, Loss: 0.6383409375671516
[16-10-2022 15:20:26] INFO: Epoch: 12, Step: 12368, Loss: 0.6380781495782885
[16-10-2022 15:20:29] INFO: Epoch: 12, Step: 12376, Loss: 0.6379997968946483
[16-10-2022 15:20:32] INFO: Epoch: 12, Step: 12384, Loss: 0.637770937521977
[16-10-2022 15:20:35] INFO: Epoch: 12, Step: 12392, Loss: 0.6377742521592951
[16-10-2022 15:20:37] INFO: Epoch: 12, Step: 12400, Loss: 0.6377300893037732
[16-10-2022 15:20:40] INFO: Epoch: 12, Step: 12408, Loss: 0.6376692744438568
[16-10-2022 15:20:43] INFO: Epoch: 12, Step: 12416, Loss: 0.6374491578668355
[16-10-2022 15:20:46] INFO: Epoch: 12, Step: 12424, Loss: 0.63735991455969
[16-10-2022 15:20:49] INFO: Epoch: 12, Step: 12432, Loss: 0.6372593161425324
[16-10-2022 15:20:52] INFO: Epoch: 12, Step: 12440, Loss: 0.6370347851698747
[16-10-2022 15:20:54] INFO: Epoch: 12, Step: 12448, Loss: 0.6369536973414573
[16-10-2022 15:20:57] INFO: Epoch: 12, Step: 12456, Loss: 0.6367605505035695
[16-10-2022 15:21:00] INFO: Epoch: 12, Step: 12464, Loss: 0.6366080697640881
[16-10-2022 15:21:03] INFO: Epoch: 12, Step: 12472, Loss: 0.636392760454642
[16-10-2022 15:21:06] INFO: Epoch: 12, Step: 12480, Loss: 0.636307503861226
[16-10-2022 15:21:09] INFO: Epoch: 12, Step: 12488, Loss: 0.6360982530798125
[16-10-2022 15:21:12] INFO: Epoch: 12, Step: 12496, Loss: 0.6359415660393527
[16-10-2022 15:21:14] INFO: Epoch: 12, Step: 12504, Loss: 0.6356253797198592
[16-10-2022 15:21:17] INFO: Epoch: 12, Step: 12512, Loss: 0.6354468479890156
[16-10-2022 15:21:20] INFO: Epoch: 12, Step: 12520, Loss: 0.6352779270738972
[16-10-2022 15:21:23] INFO: Epoch: 12, Step: 12528, Loss: 0.6350386305768723
[16-10-2022 15:21:26] INFO: Epoch: 12, Step: 12536, Loss: 0.6348225953584644
[16-10-2022 15:21:29] INFO: Epoch: 12, Step: 12544, Loss: 0.6347056659201711
[16-10-2022 15:21:32] INFO: Epoch: 12, Step: 12552, Loss: 0.6346464505311759
[16-10-2022 15:21:34] INFO: Epoch: 12, Step: 12560, Loss: 0.6344479078940135
[16-10-2022 15:21:37] INFO: Epoch: 12, Step: 12568, Loss: 0.6342597983354902
[16-10-2022 15:21:40] INFO: Epoch: 12, Step: 12576, Loss: 0.6340871084136144
[16-10-2022 15:21:43] INFO: Epoch: 12, Step: 12584, Loss: 0.6339647006554363
[16-10-2022 15:21:46] INFO: Epoch: 12, Step: 12592, Loss: 0.6337640684910458
[16-10-2022 15:21:49] INFO: Epoch: 12, Step: 12600, Loss: 0.6336340954814108
[16-10-2022 15:21:52] INFO: Epoch: 12, Step: 12608, Loss: 0.6334880864325153
[16-10-2022 15:21:54] INFO: Epoch: 12, Step: 12616, Loss: 0.63343602867937
[16-10-2022 15:21:57] INFO: Epoch: 12, Step: 12624, Loss: 0.6332490878526172
[16-10-2022 15:22:00] INFO: Epoch: 12, Step: 12632, Loss: 0.6331500928177239
[16-10-2022 15:22:03] INFO: Epoch: 12, Step: 12640, Loss: 0.6331136652707666
[16-10-2022 15:22:06] INFO: Epoch: 12, Step: 12648, Loss: 0.6330718463931851
[16-10-2022 15:22:09] INFO: Epoch: 12, Step: 12656, Loss: 0.6329404539555282
[16-10-2022 15:22:12] INFO: Epoch: 12, Step: 12664, Loss: 0.6327725758753184
[16-10-2022 15:22:15] INFO: Epoch: 12, Step: 12672, Loss: 0.6326083425297861
[16-10-2022 15:22:18] INFO: Epoch: 12, Step: 12680, Loss: 0.6324375690507531
[16-10-2022 15:22:20] INFO: Epoch: 12, Step: 12688, Loss: 0.6323381550654167
[16-10-2022 15:22:23] INFO: Epoch: 12, Step: 12696, Loss: 0.6322573790325015
[16-10-2022 15:22:26] INFO: Epoch: 12, Step: 12704, Loss: 0.6321228580219234
[16-10-2022 15:22:29] INFO: Epoch: 12, Step: 12712, Loss: 0.6319430018710753
[16-10-2022 15:22:32] INFO: Epoch: 12, Step: 12720, Loss: 0.631726882570728
[16-10-2022 15:22:35] INFO: Epoch: 12, Step: 12728, Loss: 0.6314924521641637
[16-10-2022 15:22:37] INFO: Epoch: 12, Step: 12736, Loss: 0.6313148324162029
[16-10-2022 15:22:40] INFO: Epoch: 12, Step: 12744, Loss: 0.6312304862876695
[16-10-2022 15:22:43] INFO: Epoch: 12, Step: 12752, Loss: 0.6309722055335808
[16-10-2022 15:22:46] INFO: Epoch: 12, Step: 12760, Loss: 0.6308765405850387
[16-10-2022 15:22:49] INFO: Epoch: 12, Step: 12768, Loss: 0.6309315279335717
[16-10-2022 15:22:52] INFO: Epoch: 12, Step: 12776, Loss: 0.6307933408584513
[16-10-2022 15:22:55] INFO: Epoch: 12, Step: 12784, Loss: 0.6306722608610036
[16-10-2022 15:22:58] INFO: Epoch: 12, Step: 12792, Loss: 0.6304890088154047
[16-10-2022 15:23:00] INFO: Epoch: 12, Step: 12800, Loss: 0.6303234544085049
[16-10-2022 15:23:03] INFO: Epoch: 12, Step: 12808, Loss: 0.6302092258043666
[16-10-2022 15:23:06] INFO: Epoch: 12, Step: 12816, Loss: 0.6301394045564025
[16-10-2022 15:23:09] INFO: Epoch: 12, Step: 12824, Loss: 0.6300410220817289
[16-10-2022 15:23:12] INFO: Epoch: 12, Step: 12832, Loss: 0.6298040457931
[16-10-2022 15:23:15] INFO: Epoch: 12, Step: 12840, Loss: 0.6297215364301909
[16-10-2022 15:23:18] INFO: Epoch: 12, Step: 12848, Loss: 0.6295860784437456
[16-10-2022 15:23:21] INFO: Epoch: 12, Step: 12856, Loss: 0.629384628541405
[16-10-2022 15:23:23] INFO: Epoch: 12, Step: 12864, Loss: 0.6291650097440196
[16-10-2022 15:23:26] INFO: Start eval!
       F1 (micro): 59.31%
Precision (macro): 72.86%
   Recall (macro): 58.81%
       F1 (macro): 47.79%
[16-10-2022 15:23:45] INFO: Dev total acc: 0.5930824008138352
[16-10-2022 15:23:46] INFO: Epoch: 13, Step: 12872, Loss: 0.6290385255892864
[16-10-2022 15:23:49] INFO: Epoch: 13, Step: 12880, Loss: 0.6288668029620632
[16-10-2022 15:23:52] INFO: Epoch: 13, Step: 12888, Loss: 0.6286522572097665
[16-10-2022 15:23:54] INFO: Epoch: 13, Step: 12896, Loss: 0.6285091275461978
[16-10-2022 15:23:57] INFO: Epoch: 13, Step: 12904, Loss: 0.6283544703018411
[16-10-2022 15:24:00] INFO: Epoch: 13, Step: 12912, Loss: 0.628206890718348
[16-10-2022 15:24:03] INFO: Epoch: 13, Step: 12920, Loss: 0.6279476046144168
[16-10-2022 15:24:06] INFO: Epoch: 13, Step: 12928, Loss: 0.6278351801145065
[16-10-2022 15:24:09] INFO: Epoch: 13, Step: 12936, Loss: 0.6276751157531693
[16-10-2022 15:24:12] INFO: Epoch: 13, Step: 12944, Loss: 0.6275406369179136
[16-10-2022 15:24:15] INFO: Epoch: 13, Step: 12952, Loss: 0.6274158079456195
[16-10-2022 15:24:18] INFO: Epoch: 13, Step: 12960, Loss: 0.6273563588627409
[16-10-2022 15:24:20] INFO: Epoch: 13, Step: 12968, Loss: 0.6271350158813465
[16-10-2022 15:24:23] INFO: Epoch: 13, Step: 12976, Loss: 0.6269443076153939
[16-10-2022 15:24:26] INFO: Epoch: 13, Step: 12984, Loss: 0.626827949225089
[16-10-2022 15:24:29] INFO: Epoch: 13, Step: 12992, Loss: 0.6266603207756511
[16-10-2022 15:24:32] INFO: Epoch: 13, Step: 13000, Loss: 0.626500871231642
[16-10-2022 15:24:35] INFO: Epoch: 13, Step: 13008, Loss: 0.626465181556913
[16-10-2022 15:24:38] INFO: Epoch: 13, Step: 13016, Loss: 0.6263042429840502
[16-10-2022 15:24:40] INFO: Epoch: 13, Step: 13024, Loss: 0.6260396274758094
[16-10-2022 15:24:43] INFO: Epoch: 13, Step: 13032, Loss: 0.6258976902098706
[16-10-2022 15:24:46] INFO: Epoch: 13, Step: 13040, Loss: 0.6257944739386612
[16-10-2022 15:24:49] INFO: Epoch: 13, Step: 13048, Loss: 0.6257058869745323
[16-10-2022 15:24:52] INFO: Epoch: 13, Step: 13056, Loss: 0.6255565410215744
[16-10-2022 15:24:55] INFO: Epoch: 13, Step: 13064, Loss: 0.6253540357167104
[16-10-2022 15:24:57] INFO: Epoch: 13, Step: 13072, Loss: 0.6252180976229533
[16-10-2022 15:25:00] INFO: Epoch: 13, Step: 13080, Loss: 0.6250302790960395
[16-10-2022 15:25:03] INFO: Epoch: 13, Step: 13088, Loss: 0.624866897364672
[16-10-2022 15:25:06] INFO: Epoch: 13, Step: 13096, Loss: 0.624728068344417
[16-10-2022 15:25:09] INFO: Epoch: 13, Step: 13104, Loss: 0.6245682013158032
[16-10-2022 15:25:12] INFO: Epoch: 13, Step: 13112, Loss: 0.6243890003304671
[16-10-2022 15:25:15] INFO: Epoch: 13, Step: 13120, Loss: 0.6241106544913805
[16-10-2022 15:25:18] INFO: Epoch: 13, Step: 13128, Loss: 0.6239719055476728
[16-10-2022 15:25:20] INFO: Epoch: 13, Step: 13136, Loss: 0.6237514038537953
[16-10-2022 15:25:23] INFO: Epoch: 13, Step: 13144, Loss: 0.6235440441365375
[16-10-2022 15:25:26] INFO: Epoch: 13, Step: 13152, Loss: 0.6234595056347394
[16-10-2022 15:25:29] INFO: Epoch: 13, Step: 13160, Loss: 0.6233901774598553
[16-10-2022 15:25:32] INFO: Epoch: 13, Step: 13168, Loss: 0.6232148970713284
[16-10-2022 15:25:35] INFO: Epoch: 13, Step: 13176, Loss: 0.6230619551846391
[16-10-2022 15:25:38] INFO: Epoch: 13, Step: 13184, Loss: 0.6229923580656253
[16-10-2022 15:25:41] INFO: Epoch: 13, Step: 13192, Loss: 0.6229175870976678
[16-10-2022 15:25:43] INFO: Epoch: 13, Step: 13200, Loss: 0.622794639487672
[16-10-2022 15:25:46] INFO: Epoch: 13, Step: 13208, Loss: 0.6226860880967443
[16-10-2022 15:25:49] INFO: Epoch: 13, Step: 13216, Loss: 0.6225637583657999
[16-10-2022 15:25:52] INFO: Epoch: 13, Step: 13224, Loss: 0.622505585735425
[16-10-2022 15:25:55] INFO: Epoch: 13, Step: 13232, Loss: 0.6223845507140513
[16-10-2022 15:25:58] INFO: Epoch: 13, Step: 13240, Loss: 0.6222154178741105
[16-10-2022 15:26:00] INFO: Epoch: 13, Step: 13248, Loss: 0.6221396110179793
[16-10-2022 15:26:03] INFO: Epoch: 13, Step: 13256, Loss: 0.6219253729611319
[16-10-2022 15:26:06] INFO: Epoch: 13, Step: 13264, Loss: 0.6217565353326804
[16-10-2022 15:26:09] INFO: Epoch: 13, Step: 13272, Loss: 0.6215468848406576
[16-10-2022 15:26:12] INFO: Epoch: 13, Step: 13280, Loss: 0.6214468121217307
[16-10-2022 15:26:15] INFO: Epoch: 13, Step: 13288, Loss: 0.6212675887954012
[16-10-2022 15:26:18] INFO: Epoch: 13, Step: 13296, Loss: 0.6211901105047742
[16-10-2022 15:26:21] INFO: Epoch: 13, Step: 13304, Loss: 0.6211905358328473
[16-10-2022 15:26:23] INFO: Epoch: 13, Step: 13312, Loss: 0.6210607593515923
[16-10-2022 15:26:26] INFO: Epoch: 13, Step: 13320, Loss: 0.6208568244381074
[16-10-2022 15:26:29] INFO: Epoch: 13, Step: 13328, Loss: 0.6207609566245599
[16-10-2022 15:26:32] INFO: Epoch: 13, Step: 13336, Loss: 0.6205525675720979
[16-10-2022 15:26:35] INFO: Epoch: 13, Step: 13344, Loss: 0.6204456404464073
[16-10-2022 15:26:38] INFO: Epoch: 13, Step: 13352, Loss: 0.6202538149526825
[16-10-2022 15:26:41] INFO: Epoch: 13, Step: 13360, Loss: 0.6200627268545811
[16-10-2022 15:26:43] INFO: Epoch: 13, Step: 13368, Loss: 0.6198883624867282
[16-10-2022 15:26:46] INFO: Epoch: 13, Step: 13376, Loss: 0.6197464760233099
[16-10-2022 15:26:49] INFO: Epoch: 13, Step: 13384, Loss: 0.6196116169820581
[16-10-2022 15:26:52] INFO: Epoch: 13, Step: 13392, Loss: 0.6194110517737845
[16-10-2022 15:26:55] INFO: Epoch: 13, Step: 13400, Loss: 0.6193348914893652
[16-10-2022 15:26:58] INFO: Epoch: 13, Step: 13408, Loss: 0.6192787181197663
[16-10-2022 15:27:01] INFO: Epoch: 13, Step: 13416, Loss: 0.6191581739326601
[16-10-2022 15:27:03] INFO: Epoch: 13, Step: 13424, Loss: 0.6190935236524572
[16-10-2022 15:27:06] INFO: Epoch: 13, Step: 13432, Loss: 0.6189654829735554
[16-10-2022 15:27:09] INFO: Epoch: 13, Step: 13440, Loss: 0.618838244986205
[16-10-2022 15:27:12] INFO: Epoch: 13, Step: 13448, Loss: 0.6186181416190499
[16-10-2022 15:27:15] INFO: Epoch: 13, Step: 13456, Loss: 0.6184585041748073
[16-10-2022 15:27:18] INFO: Epoch: 13, Step: 13464, Loss: 0.618307095813165
[16-10-2022 15:27:21] INFO: Epoch: 13, Step: 13472, Loss: 0.6181052175005999
[16-10-2022 15:27:24] INFO: Epoch: 13, Step: 13480, Loss: 0.6179899504731634
[16-10-2022 15:27:26] INFO: Epoch: 13, Step: 13488, Loss: 0.6179050151001905
[16-10-2022 15:27:29] INFO: Epoch: 13, Step: 13496, Loss: 0.6178319362349971
[16-10-2022 15:27:32] INFO: Epoch: 13, Step: 13504, Loss: 0.617874235971075
[16-10-2022 15:27:35] INFO: Epoch: 13, Step: 13512, Loss: 0.6176956581525879
[16-10-2022 15:27:38] INFO: Epoch: 13, Step: 13520, Loss: 0.6176328583176927
[16-10-2022 15:27:41] INFO: Epoch: 13, Step: 13528, Loss: 0.6173924551679221
[16-10-2022 15:27:44] INFO: Epoch: 13, Step: 13536, Loss: 0.6171761849583084
[16-10-2022 15:27:46] INFO: Epoch: 13, Step: 13544, Loss: 0.6170352098820331
[16-10-2022 15:27:49] INFO: Epoch: 13, Step: 13552, Loss: 0.6168307522501536
[16-10-2022 15:27:52] INFO: Epoch: 13, Step: 13560, Loss: 0.6166752797392168
[16-10-2022 15:27:55] INFO: Epoch: 13, Step: 13568, Loss: 0.6165738217486015
[16-10-2022 15:27:58] INFO: Epoch: 13, Step: 13576, Loss: 0.6163666972747315
[16-10-2022 15:28:01] INFO: Epoch: 13, Step: 13584, Loss: 0.6162876429530498
[16-10-2022 15:28:04] INFO: Epoch: 13, Step: 13592, Loss: 0.6162338593540075
[16-10-2022 15:28:07] INFO: Epoch: 13, Step: 13600, Loss: 0.6160801171990825
[16-10-2022 15:28:10] INFO: Epoch: 13, Step: 13608, Loss: 0.6159907073417142
[16-10-2022 15:28:12] INFO: Epoch: 13, Step: 13616, Loss: 0.6158976376669036
[16-10-2022 15:28:15] INFO: Epoch: 13, Step: 13624, Loss: 0.6158245285599495
[16-10-2022 15:28:18] INFO: Epoch: 13, Step: 13632, Loss: 0.6156457068943562
[16-10-2022 15:28:21] INFO: Epoch: 13, Step: 13640, Loss: 0.6154619682375452
[16-10-2022 15:28:24] INFO: Epoch: 13, Step: 13648, Loss: 0.6154186514057253
[16-10-2022 15:28:27] INFO: Epoch: 13, Step: 13656, Loss: 0.6153669130882631
[16-10-2022 15:28:30] INFO: Epoch: 13, Step: 13664, Loss: 0.615218424073871
[16-10-2022 15:28:32] INFO: Epoch: 13, Step: 13672, Loss: 0.6151734009418407
[16-10-2022 15:28:35] INFO: Epoch: 13, Step: 13680, Loss: 0.6150035784669734
[16-10-2022 15:28:38] INFO: Epoch: 13, Step: 13688, Loss: 0.6149108060744545
[16-10-2022 15:28:41] INFO: Epoch: 13, Step: 13696, Loss: 0.6147560398059052
[16-10-2022 15:28:44] INFO: Epoch: 13, Step: 13704, Loss: 0.6145860135967975
[16-10-2022 15:28:47] INFO: Epoch: 13, Step: 13712, Loss: 0.6144695418504913
[16-10-2022 15:28:50] INFO: Epoch: 13, Step: 13720, Loss: 0.6143509824868922
[16-10-2022 15:28:52] INFO: Epoch: 13, Step: 13728, Loss: 0.6142093313025966
[16-10-2022 15:28:55] INFO: Epoch: 13, Step: 13736, Loss: 0.6140401841588288
[16-10-2022 15:28:58] INFO: Epoch: 13, Step: 13744, Loss: 0.6139183888947527
[16-10-2022 15:29:01] INFO: Epoch: 13, Step: 13752, Loss: 0.6137958935932261
[16-10-2022 15:29:04] INFO: Epoch: 13, Step: 13760, Loss: 0.6136062725032951
[16-10-2022 15:29:07] INFO: Epoch: 13, Step: 13768, Loss: 0.6135841606302326
[16-10-2022 15:29:10] INFO: Epoch: 13, Step: 13776, Loss: 0.6133938659035032
[16-10-2022 15:29:13] INFO: Epoch: 13, Step: 13784, Loss: 0.6132401856983021
[16-10-2022 15:29:15] INFO: Epoch: 13, Step: 13792, Loss: 0.6130642657237952
[16-10-2022 15:29:18] INFO: Epoch: 13, Step: 13800, Loss: 0.6130211189834699
[16-10-2022 15:29:21] INFO: Epoch: 13, Step: 13808, Loss: 0.6128155626057188
[16-10-2022 15:29:24] INFO: Epoch: 13, Step: 13816, Loss: 0.6126998867152058
[16-10-2022 15:29:27] INFO: Epoch: 13, Step: 13824, Loss: 0.6126126960462718
[16-10-2022 15:29:30] INFO: Epoch: 13, Step: 13832, Loss: 0.6124291300454258
[16-10-2022 15:29:33] INFO: Epoch: 13, Step: 13840, Loss: 0.6123205744750272
[16-10-2022 15:29:35] INFO: Epoch: 13, Step: 13848, Loss: 0.612332882350752
[16-10-2022 15:29:38] INFO: Epoch: 13, Step: 13856, Loss: 0.6121463011361512
[16-10-2022 15:29:40] INFO: Start eval!
       F1 (micro): 59.82%
Precision (macro): 68.56%
   Recall (macro): 59.32%
       F1 (macro): 48.73%
[16-10-2022 15:30:00] INFO: Dev total acc: 0.5981688708036622
[16-10-2022 15:30:01] INFO: Saved best epoch 13, best f1 0.48730169548518654
[16-10-2022 15:30:02] INFO: Epoch: 14, Step: 13864, Loss: 0.6120952932189386
[16-10-2022 15:30:05] INFO: Epoch: 14, Step: 13872, Loss: 0.6120483229023319
[16-10-2022 15:30:08] INFO: Epoch: 14, Step: 13880, Loss: 0.6119511614596628
[16-10-2022 15:30:11] INFO: Epoch: 14, Step: 13888, Loss: 0.611872133283081
[16-10-2022 15:30:14] INFO: Epoch: 14, Step: 13896, Loss: 0.6117002843229383
[16-10-2022 15:30:16] INFO: Epoch: 14, Step: 13904, Loss: 0.6116245153268491
[16-10-2022 15:30:19] INFO: Epoch: 14, Step: 13912, Loss: 0.6115047673061823
[16-10-2022 15:30:22] INFO: Epoch: 14, Step: 13920, Loss: 0.6113558424270135
[16-10-2022 15:30:25] INFO: Epoch: 14, Step: 13928, Loss: 0.611255570891223
[16-10-2022 15:30:28] INFO: Epoch: 14, Step: 13936, Loss: 0.6111534364090113
[16-10-2022 15:30:31] INFO: Epoch: 14, Step: 13944, Loss: 0.6109570335039557
[16-10-2022 15:30:34] INFO: Epoch: 14, Step: 13952, Loss: 0.6107785607522105
[16-10-2022 15:30:36] INFO: Epoch: 14, Step: 13960, Loss: 0.6106310341211042
[16-10-2022 15:30:39] INFO: Epoch: 14, Step: 13968, Loss: 0.6104437405601485
[16-10-2022 15:30:42] INFO: Epoch: 14, Step: 13976, Loss: 0.6103138633919524
[16-10-2022 15:30:45] INFO: Epoch: 14, Step: 13984, Loss: 0.6101078608675938
[16-10-2022 15:30:48] INFO: Epoch: 14, Step: 13992, Loss: 0.610100179167045
[16-10-2022 15:30:51] INFO: Epoch: 14, Step: 14000, Loss: 0.6099471886448085
[16-10-2022 15:30:53] INFO: Epoch: 14, Step: 14008, Loss: 0.6098173512483676
[16-10-2022 15:30:56] INFO: Epoch: 14, Step: 14016, Loss: 0.6096049081584701
[16-10-2022 15:30:59] INFO: Epoch: 14, Step: 14024, Loss: 0.609476340219811
[16-10-2022 15:31:02] INFO: Epoch: 14, Step: 14032, Loss: 0.6094799786405278
[16-10-2022 15:31:05] INFO: Epoch: 14, Step: 14040, Loss: 0.6093122083722984
[16-10-2022 15:31:08] INFO: Epoch: 14, Step: 14048, Loss: 0.6092731060021651
[16-10-2022 15:31:11] INFO: Epoch: 14, Step: 14056, Loss: 0.6090972915126991
[16-10-2022 15:31:13] INFO: Epoch: 14, Step: 14064, Loss: 0.6089399939885606
[16-10-2022 15:31:16] INFO: Epoch: 14, Step: 14072, Loss: 0.6087393524205221
[16-10-2022 15:31:19] INFO: Epoch: 14, Step: 14080, Loss: 0.6086772353766773
[16-10-2022 15:31:22] INFO: Epoch: 14, Step: 14088, Loss: 0.608615614355096
[16-10-2022 15:31:25] INFO: Epoch: 14, Step: 14096, Loss: 0.6084758554874454
[16-10-2022 15:31:28] INFO: Epoch: 14, Step: 14104, Loss: 0.6083485106953489
[16-10-2022 15:31:30] INFO: Epoch: 14, Step: 14112, Loss: 0.6082543565924998
[16-10-2022 15:31:33] INFO: Epoch: 14, Step: 14120, Loss: 0.608078832122062
[16-10-2022 15:31:36] INFO: Epoch: 14, Step: 14128, Loss: 0.6079720358381742
[16-10-2022 15:31:39] INFO: Epoch: 14, Step: 14136, Loss: 0.6078330574904575
[16-10-2022 15:31:42] INFO: Epoch: 14, Step: 14144, Loss: 0.6076671455608107
[16-10-2022 15:31:45] INFO: Epoch: 14, Step: 14152, Loss: 0.6074613965576628
[16-10-2022 15:31:48] INFO: Epoch: 14, Step: 14160, Loss: 0.60736686116648
[16-10-2022 15:31:50] INFO: Epoch: 14, Step: 14168, Loss: 0.6071625011431487
[16-10-2022 15:31:53] INFO: Epoch: 14, Step: 14176, Loss: 0.6071882259090744
[16-10-2022 15:31:56] INFO: Epoch: 14, Step: 14184, Loss: 0.6070488263207904
[16-10-2022 15:31:59] INFO: Epoch: 14, Step: 14192, Loss: 0.6069417369167197
[16-10-2022 15:32:02] INFO: Epoch: 14, Step: 14200, Loss: 0.606809818853013
[16-10-2022 15:32:05] INFO: Epoch: 14, Step: 14208, Loss: 0.6065964164070289
[16-10-2022 15:32:07] INFO: Epoch: 14, Step: 14216, Loss: 0.6064401568268984
[16-10-2022 15:32:10] INFO: Epoch: 14, Step: 14224, Loss: 0.6062686821067167
[16-10-2022 15:32:13] INFO: Epoch: 14, Step: 14232, Loss: 0.6061073870119651
[16-10-2022 15:32:16] INFO: Epoch: 14, Step: 14240, Loss: 0.6058952392510643
[16-10-2022 15:32:19] INFO: Epoch: 14, Step: 14248, Loss: 0.605787460577974
[16-10-2022 15:32:22] INFO: Epoch: 14, Step: 14256, Loss: 0.6057008897491672
[16-10-2022 15:32:25] INFO: Epoch: 14, Step: 14264, Loss: 0.6055915312417453
[16-10-2022 15:32:27] INFO: Epoch: 14, Step: 14272, Loss: 0.6054440206068208
[16-10-2022 15:32:30] INFO: Epoch: 14, Step: 14280, Loss: 0.6053173427138772
[16-10-2022 15:32:33] INFO: Epoch: 14, Step: 14288, Loss: 0.6051965883775581
[16-10-2022 15:32:36] INFO: Epoch: 14, Step: 14296, Loss: 0.6050815463705104
[16-10-2022 15:32:39] INFO: Epoch: 14, Step: 14304, Loss: 0.6049425412064275
[16-10-2022 15:32:42] INFO: Epoch: 14, Step: 14312, Loss: 0.6047307509833207
[16-10-2022 15:32:44] INFO: Epoch: 14, Step: 14320, Loss: 0.6045514124664193
[16-10-2022 15:32:47] INFO: Epoch: 14, Step: 14328, Loss: 0.6043834456698716
[16-10-2022 15:32:50] INFO: Epoch: 14, Step: 14336, Loss: 0.6042789293465624
[16-10-2022 15:32:53] INFO: Epoch: 14, Step: 14344, Loss: 0.6042420177076977
[16-10-2022 15:32:56] INFO: Epoch: 14, Step: 14352, Loss: 0.6040800450621029
[16-10-2022 15:32:59] INFO: Epoch: 14, Step: 14360, Loss: 0.6039090403519146
[16-10-2022 15:33:01] INFO: Epoch: 14, Step: 14368, Loss: 0.6038105875893626
[16-10-2022 15:33:04] INFO: Epoch: 14, Step: 14376, Loss: 0.6036441172563882
[16-10-2022 15:33:07] INFO: Epoch: 14, Step: 14384, Loss: 0.6035200705274255
[16-10-2022 15:33:10] INFO: Epoch: 14, Step: 14392, Loss: 0.6033530367223631
[16-10-2022 15:33:13] INFO: Epoch: 14, Step: 14400, Loss: 0.603273435010994
[16-10-2022 15:33:16] INFO: Epoch: 14, Step: 14408, Loss: 0.6030755333291179
[16-10-2022 15:33:19] INFO: Epoch: 14, Step: 14416, Loss: 0.6029949000391637
[16-10-2022 15:33:22] INFO: Epoch: 14, Step: 14424, Loss: 0.6028118603033827
[16-10-2022 15:33:24] INFO: Epoch: 14, Step: 14432, Loss: 0.6027872259775127
[16-10-2022 15:33:27] INFO: Epoch: 14, Step: 14440, Loss: 0.6025991601884996
[16-10-2022 15:33:30] INFO: Epoch: 14, Step: 14448, Loss: 0.6025388449825532
[16-10-2022 15:33:33] INFO: Epoch: 14, Step: 14456, Loss: 0.6023506952963068
[16-10-2022 15:33:36] INFO: Epoch: 14, Step: 14464, Loss: 0.6023256034354435
[16-10-2022 15:33:39] INFO: Epoch: 14, Step: 14472, Loss: 0.6021565620953784
[16-10-2022 15:33:41] INFO: Epoch: 14, Step: 14480, Loss: 0.6020162468318216
[16-10-2022 15:33:44] INFO: Epoch: 14, Step: 14488, Loss: 0.6019239480484356
[16-10-2022 15:33:47] INFO: Epoch: 14, Step: 14496, Loss: 0.6018600573205127
[16-10-2022 15:33:50] INFO: Epoch: 14, Step: 14504, Loss: 0.6016987882003907
[16-10-2022 15:33:53] INFO: Epoch: 14, Step: 14512, Loss: 0.6015445643198106
[16-10-2022 15:33:56] INFO: Epoch: 14, Step: 14520, Loss: 0.6014373307524317
[16-10-2022 15:33:59] INFO: Epoch: 14, Step: 14528, Loss: 0.6013458267952848
[16-10-2022 15:34:01] INFO: Epoch: 14, Step: 14536, Loss: 0.6012061976822095
[16-10-2022 15:34:04] INFO: Epoch: 14, Step: 14544, Loss: 0.6010799695219287
[16-10-2022 15:34:07] INFO: Epoch: 14, Step: 14552, Loss: 0.6009453238249738
[16-10-2022 15:34:10] INFO: Epoch: 14, Step: 14560, Loss: 0.6009291029755324
[16-10-2022 15:34:13] INFO: Epoch: 14, Step: 14568, Loss: 0.600811303229082
[16-10-2022 15:34:16] INFO: Epoch: 14, Step: 14576, Loss: 0.6006204465488034
[16-10-2022 15:34:19] INFO: Epoch: 14, Step: 14584, Loss: 0.600579863016714
[16-10-2022 15:34:21] INFO: Epoch: 14, Step: 14592, Loss: 0.6003980567477688
[16-10-2022 15:34:24] INFO: Epoch: 14, Step: 14600, Loss: 0.6002204379219971
[16-10-2022 15:34:27] INFO: Epoch: 14, Step: 14608, Loss: 0.6000968240102579
[16-10-2022 15:34:30] INFO: Epoch: 14, Step: 14616, Loss: 0.6000160343372114
[16-10-2022 15:34:33] INFO: Epoch: 14, Step: 14624, Loss: 0.5999085172772444
[16-10-2022 15:34:36] INFO: Epoch: 14, Step: 14632, Loss: 0.5997771747428681
[16-10-2022 15:34:39] INFO: Epoch: 14, Step: 14640, Loss: 0.5996485453730125
[16-10-2022 15:34:41] INFO: Epoch: 14, Step: 14648, Loss: 0.5995087125605703
[16-10-2022 15:34:44] INFO: Epoch: 14, Step: 14656, Loss: 0.599391680766984
[16-10-2022 15:34:47] INFO: Epoch: 14, Step: 14664, Loss: 0.5992433333919887
[16-10-2022 15:34:50] INFO: Epoch: 14, Step: 14672, Loss: 0.599087414279435
[16-10-2022 15:34:53] INFO: Epoch: 14, Step: 14680, Loss: 0.5989723632650182
[16-10-2022 15:34:56] INFO: Epoch: 14, Step: 14688, Loss: 0.5988000503534296
[16-10-2022 15:34:59] INFO: Epoch: 14, Step: 14696, Loss: 0.5987350520651047
[16-10-2022 15:35:01] INFO: Epoch: 14, Step: 14704, Loss: 0.59868240883317
[16-10-2022 15:35:04] INFO: Epoch: 14, Step: 14712, Loss: 0.5986231306751167
[16-10-2022 15:35:07] INFO: Epoch: 14, Step: 14720, Loss: 0.598490601983534
[16-10-2022 15:35:10] INFO: Epoch: 14, Step: 14728, Loss: 0.598372142098744
[16-10-2022 15:35:13] INFO: Epoch: 14, Step: 14736, Loss: 0.5982523671802423
[16-10-2022 15:35:16] INFO: Epoch: 14, Step: 14744, Loss: 0.5980969308751747
[16-10-2022 15:35:19] INFO: Epoch: 14, Step: 14752, Loss: 0.5979562366256086
[16-10-2022 15:35:21] INFO: Epoch: 14, Step: 14760, Loss: 0.5979590922765748
[16-10-2022 15:35:24] INFO: Epoch: 14, Step: 14768, Loss: 0.59781173458838
[16-10-2022 15:35:27] INFO: Epoch: 14, Step: 14776, Loss: 0.5976447809238541
[16-10-2022 15:35:30] INFO: Epoch: 14, Step: 14784, Loss: 0.5975081972143911
[16-10-2022 15:35:33] INFO: Epoch: 14, Step: 14792, Loss: 0.5973375507294498
[16-10-2022 15:35:36] INFO: Epoch: 14, Step: 14800, Loss: 0.5971909477073449
[16-10-2022 15:35:39] INFO: Epoch: 14, Step: 14808, Loss: 0.5970335509119932
[16-10-2022 15:35:41] INFO: Epoch: 14, Step: 14816, Loss: 0.5968674268230614
[16-10-2022 15:35:44] INFO: Epoch: 14, Step: 14824, Loss: 0.5967290708589175
[16-10-2022 15:35:47] INFO: Epoch: 14, Step: 14832, Loss: 0.5966150452575809
[16-10-2022 15:35:50] INFO: Epoch: 14, Step: 14840, Loss: 0.5965162957132396
[16-10-2022 15:35:53] INFO: Epoch: 14, Step: 14848, Loss: 0.5963911198231178
[16-10-2022 15:35:54] INFO: Start eval!
       F1 (micro): 59.92%
Precision (macro): 68.42%
   Recall (macro): 59.43%
       F1 (macro): 48.72%
[16-10-2022 15:36:13] INFO: Dev total acc: 0.5991861648016277
[16-10-2022 15:36:15] INFO: Epoch: 15, Step: 14856, Loss: 0.5963215326421981
[16-10-2022 15:36:18] INFO: Epoch: 15, Step: 14864, Loss: 0.5962240122844175
[16-10-2022 15:36:21] INFO: Epoch: 15, Step: 14872, Loss: 0.5960794465517203
[16-10-2022 15:36:24] INFO: Epoch: 15, Step: 14880, Loss: 0.5958946467121934
[16-10-2022 15:36:26] INFO: Epoch: 15, Step: 14888, Loss: 0.5957434585168889
[16-10-2022 15:36:29] INFO: Epoch: 15, Step: 14896, Loss: 0.5956651309243065
[16-10-2022 15:36:32] INFO: Epoch: 15, Step: 14904, Loss: 0.5956093345539345
[16-10-2022 15:36:35] INFO: Epoch: 15, Step: 14912, Loss: 0.5954941499637603
[16-10-2022 15:36:38] INFO: Epoch: 15, Step: 14920, Loss: 0.5953987257045822
[16-10-2022 15:36:41] INFO: Epoch: 15, Step: 14928, Loss: 0.5952211376619032
[16-10-2022 15:36:44] INFO: Epoch: 15, Step: 14936, Loss: 0.595216957652716
[16-10-2022 15:36:46] INFO: Epoch: 15, Step: 14944, Loss: 0.5950097312719056
[16-10-2022 15:36:49] INFO: Epoch: 15, Step: 14952, Loss: 0.5949210454971486
[16-10-2022 15:36:52] INFO: Epoch: 15, Step: 14960, Loss: 0.5948253475697414
[16-10-2022 15:36:55] INFO: Epoch: 15, Step: 14968, Loss: 0.5946256543307122
[16-10-2022 15:36:58] INFO: Epoch: 15, Step: 14976, Loss: 0.5944566114235553
[16-10-2022 15:37:01] INFO: Epoch: 15, Step: 14984, Loss: 0.5943540080743398
[16-10-2022 15:37:04] INFO: Epoch: 15, Step: 14992, Loss: 0.5942876648054516
[16-10-2022 15:37:07] INFO: Epoch: 15, Step: 15000, Loss: 0.5941423656856071
[16-10-2022 15:37:09] INFO: Epoch: 15, Step: 15008, Loss: 0.5940298577318881
[16-10-2022 15:37:12] INFO: Epoch: 15, Step: 15016, Loss: 0.5939821133863472
[16-10-2022 15:37:15] INFO: Epoch: 15, Step: 15024, Loss: 0.5938114269484873
[16-10-2022 15:37:18] INFO: Epoch: 15, Step: 15032, Loss: 0.5937135950193859
[16-10-2022 15:37:21] INFO: Epoch: 15, Step: 15040, Loss: 0.5935146272895869
[16-10-2022 15:37:24] INFO: Epoch: 15, Step: 15048, Loss: 0.5934355873337332
[16-10-2022 15:37:26] INFO: Epoch: 15, Step: 15056, Loss: 0.5933391242664195
[16-10-2022 15:37:29] INFO: Epoch: 15, Step: 15064, Loss: 0.5933638550420315
[16-10-2022 15:37:32] INFO: Epoch: 15, Step: 15072, Loss: 0.5932054973193623
[16-10-2022 15:37:35] INFO: Epoch: 15, Step: 15080, Loss: 0.5930691178191494
[16-10-2022 15:37:38] INFO: Epoch: 15, Step: 15088, Loss: 0.5929884264366169
[16-10-2022 15:37:41] INFO: Epoch: 15, Step: 15096, Loss: 0.5929183042605785
[16-10-2022 15:37:43] INFO: Epoch: 15, Step: 15104, Loss: 0.5927399643272669
[16-10-2022 15:37:46] INFO: Epoch: 15, Step: 15112, Loss: 0.5925551529548809
[16-10-2022 15:37:49] INFO: Epoch: 15, Step: 15120, Loss: 0.5925475297293741
[16-10-2022 15:37:52] INFO: Epoch: 15, Step: 15128, Loss: 0.5924094474674039
[16-10-2022 15:37:55] INFO: Epoch: 15, Step: 15136, Loss: 0.5922939588121892
[16-10-2022 15:37:58] INFO: Epoch: 15, Step: 15144, Loss: 0.5921267330325792
[16-10-2022 15:38:00] INFO: Epoch: 15, Step: 15152, Loss: 0.5920434986524444
[16-10-2022 15:38:03] INFO: Epoch: 15, Step: 15160, Loss: 0.591869929053956
[16-10-2022 15:38:06] INFO: Epoch: 15, Step: 15168, Loss: 0.5918339685461326
[16-10-2022 15:38:09] INFO: Epoch: 15, Step: 15176, Loss: 0.5916807001012855
[16-10-2022 15:38:12] INFO: Epoch: 15, Step: 15184, Loss: 0.5916126535266287
[16-10-2022 15:38:15] INFO: Epoch: 15, Step: 15192, Loss: 0.591533035476878
[16-10-2022 15:38:18] INFO: Epoch: 15, Step: 15200, Loss: 0.591351182694601
[16-10-2022 15:38:20] INFO: Epoch: 15, Step: 15208, Loss: 0.5911811561632887
[16-10-2022 15:38:23] INFO: Epoch: 15, Step: 15216, Loss: 0.5910007563908365
[16-10-2022 15:38:26] INFO: Epoch: 15, Step: 15224, Loss: 0.5908996085770952
[16-10-2022 15:38:29] INFO: Epoch: 15, Step: 15232, Loss: 0.5907868755367016
[16-10-2022 15:38:32] INFO: Epoch: 15, Step: 15240, Loss: 0.5906909071828174
[16-10-2022 15:38:35] INFO: Epoch: 15, Step: 15248, Loss: 0.5906070976426283
[16-10-2022 15:38:38] INFO: Epoch: 15, Step: 15256, Loss: 0.5904142211943986
[16-10-2022 15:38:40] INFO: Epoch: 15, Step: 15264, Loss: 0.5902048576324526
[16-10-2022 15:38:43] INFO: Epoch: 15, Step: 15272, Loss: 0.5900497598814618
[16-10-2022 15:38:46] INFO: Epoch: 15, Step: 15280, Loss: 0.5899279551609854
[16-10-2022 15:38:49] INFO: Epoch: 15, Step: 15288, Loss: 0.589800809168426
[16-10-2022 15:38:52] INFO: Epoch: 15, Step: 15296, Loss: 0.5896902338418551
[16-10-2022 15:38:55] INFO: Epoch: 15, Step: 15304, Loss: 0.5895690426636504
[16-10-2022 15:38:58] INFO: Epoch: 15, Step: 15312, Loss: 0.5894550984363387
[16-10-2022 15:39:01] INFO: Epoch: 15, Step: 15320, Loss: 0.589251181226005
[16-10-2022 15:39:03] INFO: Epoch: 15, Step: 15328, Loss: 0.589135889905959
[16-10-2022 15:39:06] INFO: Epoch: 15, Step: 15336, Loss: 0.5889866935088308
[16-10-2022 15:39:09] INFO: Epoch: 15, Step: 15344, Loss: 0.5888394318240413
[16-10-2022 15:39:12] INFO: Epoch: 15, Step: 15352, Loss: 0.588733386996228
[16-10-2022 15:39:15] INFO: Epoch: 15, Step: 15360, Loss: 0.5886683201412526
[16-10-2022 15:39:18] INFO: Epoch: 15, Step: 15368, Loss: 0.5885267151061074
[16-10-2022 15:39:20] INFO: Epoch: 15, Step: 15376, Loss: 0.5883495460388481
[16-10-2022 15:39:23] INFO: Epoch: 15, Step: 15384, Loss: 0.5882695913615139
[16-10-2022 15:39:26] INFO: Epoch: 15, Step: 15392, Loss: 0.5880950843894095
[16-10-2022 15:39:29] INFO: Epoch: 15, Step: 15400, Loss: 0.5879450885196834
[16-10-2022 15:39:32] INFO: Epoch: 15, Step: 15408, Loss: 0.5878129527625616
[16-10-2022 15:39:35] INFO: Epoch: 15, Step: 15416, Loss: 0.5876490480924335
[16-10-2022 15:39:38] INFO: Epoch: 15, Step: 15424, Loss: 0.5875845310279253
[16-10-2022 15:39:40] INFO: Epoch: 15, Step: 15432, Loss: 0.587435722225551
[16-10-2022 15:39:43] INFO: Epoch: 15, Step: 15440, Loss: 0.5873897409389917
[16-10-2022 15:39:46] INFO: Epoch: 15, Step: 15448, Loss: 0.5873231371630327
[16-10-2022 15:39:49] INFO: Epoch: 15, Step: 15456, Loss: 0.5871253620652921
[16-10-2022 15:39:52] INFO: Epoch: 15, Step: 15464, Loss: 0.5870520006185972
[16-10-2022 15:39:55] INFO: Epoch: 15, Step: 15472, Loss: 0.5869499611381332
[16-10-2022 15:39:57] INFO: Epoch: 15, Step: 15480, Loss: 0.5868616429400663
[16-10-2022 15:40:00] INFO: Epoch: 15, Step: 15488, Loss: 0.5866502087307405
[16-10-2022 15:40:03] INFO: Epoch: 15, Step: 15496, Loss: 0.5865701393848917
[16-10-2022 15:40:06] INFO: Epoch: 15, Step: 15504, Loss: 0.5865093323275289
[16-10-2022 15:40:09] INFO: Epoch: 15, Step: 15512, Loss: 0.5863225896818332
[16-10-2022 15:40:12] INFO: Epoch: 15, Step: 15520, Loss: 0.5862215035518239
[16-10-2022 15:40:15] INFO: Epoch: 15, Step: 15528, Loss: 0.5860729586615697
[16-10-2022 15:40:18] INFO: Epoch: 15, Step: 15536, Loss: 0.5859780646426639
[16-10-2022 15:40:20] INFO: Epoch: 15, Step: 15544, Loss: 0.5858983012351074
[16-10-2022 15:40:23] INFO: Epoch: 15, Step: 15552, Loss: 0.5858070940072045
[16-10-2022 15:40:26] INFO: Epoch: 15, Step: 15560, Loss: 0.5856988603811866
[16-10-2022 15:40:29] INFO: Epoch: 15, Step: 15568, Loss: 0.5855876229794885
[16-10-2022 15:40:32] INFO: Epoch: 15, Step: 15576, Loss: 0.58549833555195
[16-10-2022 15:40:35] INFO: Epoch: 15, Step: 15584, Loss: 0.5853509165155913
[16-10-2022 15:40:37] INFO: Epoch: 15, Step: 15592, Loss: 0.5852880135745818
[16-10-2022 15:40:40] INFO: Epoch: 15, Step: 15600, Loss: 0.5851142835354434
[16-10-2022 15:40:43] INFO: Epoch: 15, Step: 15608, Loss: 0.5849665986614657
[16-10-2022 15:40:46] INFO: Epoch: 15, Step: 15616, Loss: 0.5849335562799473
[16-10-2022 15:40:49] INFO: Epoch: 15, Step: 15624, Loss: 0.5848722662247434
[16-10-2022 15:40:52] INFO: Epoch: 15, Step: 15632, Loss: 0.5847459903917303
[16-10-2022 15:40:55] INFO: Epoch: 15, Step: 15640, Loss: 0.5846329158153005
[16-10-2022 15:40:57] INFO: Epoch: 15, Step: 15648, Loss: 0.5845054755437833
[16-10-2022 15:41:00] INFO: Epoch: 15, Step: 15656, Loss: 0.5844072304798389
[16-10-2022 15:41:03] INFO: Epoch: 15, Step: 15664, Loss: 0.5843727283157929
[16-10-2022 15:41:06] INFO: Epoch: 15, Step: 15672, Loss: 0.58416447107219
[16-10-2022 15:41:09] INFO: Epoch: 15, Step: 15680, Loss: 0.5840109868830461
[16-10-2022 15:41:12] INFO: Epoch: 15, Step: 15688, Loss: 0.583970805542707
[16-10-2022 15:41:15] INFO: Epoch: 15, Step: 15696, Loss: 0.5838394377368317
[16-10-2022 15:41:17] INFO: Epoch: 15, Step: 15704, Loss: 0.5837407929782998
[16-10-2022 15:41:20] INFO: Epoch: 15, Step: 15712, Loss: 0.5835799802310032
[16-10-2022 15:41:23] INFO: Epoch: 15, Step: 15720, Loss: 0.583554010625943
[16-10-2022 15:41:26] INFO: Epoch: 15, Step: 15728, Loss: 0.5835155093022089
[16-10-2022 15:41:29] INFO: Epoch: 15, Step: 15736, Loss: 0.5834566309861603
[16-10-2022 15:41:32] INFO: Epoch: 15, Step: 15744, Loss: 0.5834005045679984
[16-10-2022 15:41:35] INFO: Epoch: 15, Step: 15752, Loss: 0.5832505189204035
[16-10-2022 15:41:37] INFO: Epoch: 15, Step: 15760, Loss: 0.583107964132402
[16-10-2022 15:41:40] INFO: Epoch: 15, Step: 15768, Loss: 0.5829948533037258
[16-10-2022 15:41:43] INFO: Epoch: 15, Step: 15776, Loss: 0.5828512549536393
[16-10-2022 15:41:46] INFO: Epoch: 15, Step: 15784, Loss: 0.5827851332214347
[16-10-2022 15:41:49] INFO: Epoch: 15, Step: 15792, Loss: 0.5826890224613592
[16-10-2022 15:41:52] INFO: Epoch: 15, Step: 15800, Loss: 0.5825259140244722
[16-10-2022 15:41:55] INFO: Epoch: 15, Step: 15808, Loss: 0.5823947008525311
[16-10-2022 15:41:57] INFO: Epoch: 15, Step: 15816, Loss: 0.5822056212550154
[16-10-2022 15:42:00] INFO: Epoch: 15, Step: 15824, Loss: 0.5821386920380067
[16-10-2022 15:42:03] INFO: Epoch: 15, Step: 15832, Loss: 0.5819947079735649
[16-10-2022 15:42:06] INFO: Epoch: 15, Step: 15840, Loss: 0.5818591384271283
[16-10-2022 15:42:06] INFO: Start eval!
       F1 (micro): 59.72%
Precision (macro): 68.39%
   Recall (macro): 59.22%
       F1 (macro): 48.61%
[16-10-2022 15:42:25] INFO: Dev total acc: 0.5971515768056969
